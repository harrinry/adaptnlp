---

title: Token Tagging and Classification


keywords: fastai
sidebar: home_sidebar

summary: "AdaptiveModels for using Transformers and Flair for token tagging and classification"
description: "AdaptiveModels for using Transformers and Flair for token tagging and classification"
nb_path: "nbs/05_token_classification.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/05_token_classification.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/mnt/d/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() &gt; 0
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>The history saving thread hit an unexpected error (OperationalError(&#39;disk I/O error&#39;)).History will not be written to the database.
</pre>
</div>
</div>

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="TransformersTokenTagger" class="doc_header"><code>class</code> <code>TransformersTokenTagger</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/token_classification.py#L39" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>TransformersTokenTagger</code>(<strong><code>tokenizer</code></strong>:<code>PreTrainedTokenizer</code>, <strong><code>model</code></strong>:<code>PreTrainedModel</code>) :: <a href="/adaptnlp/model.html#AdaptiveModel"><code>AdaptiveModel</code></a></p>
</blockquote>
<p>Adaptive model for Transformer's Token Tagger Model</p>
<p>Usage:</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">tagger</span> <span class="o">=</span> <span class="n">TransformersTokenTagger</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;dbmdz/bert-large-cased-finetuned-conll03-english&quot;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">tagger</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s2">&quot;Example text&quot;</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</pre></div>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong>tokenizer</strong> - A tokenizer object from Huggingface's transformers (TODO) and tokenizers</li>
<li><strong>model</strong> - A transformers token tagger model</li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="FlairTokenTagger" class="doc_header"><code>class</code> <code>FlairTokenTagger</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/token_classification.py#L258" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>FlairTokenTagger</code>(<strong><code>model_name_or_path</code></strong>:<code>str</code>) :: <a href="/adaptnlp/model.html#AdaptiveModel"><code>AdaptiveModel</code></a></p>
</blockquote>
<p>Adaptive Model for Flair's Token Tagger...very basic</p>
<p>Usage:</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">tagger</span> <span class="o">=</span> <span class="n">FlairTokenTagger</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;flair/chunk-english-fast&quot;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">tagger</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s2">&quot;Example text&quot;</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</pre></div>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong>model_name_or_path</strong> - A key string of one of Flair's pre-trained Token tagger Model</li>
</ul>
<p>To find a list of available models, see <a href="https://huggingface.co/models?filter=flair">here</a></p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="EasyTokenTagger" class="doc_header"><code>class</code> <code>EasyTokenTagger</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/token_classification.py#L324" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>EasyTokenTagger</code>()</p>
</blockquote>
<p>Token level classification models</p>
<p>Usage:</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">tagger</span> <span class="o">=</span> <span class="n">adaptnlp</span><span class="o">.</span><span class="n">EasyTokenTagger</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">tagger</span><span class="o">.</span><span class="n">tag_text</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s2">&quot;text you want to tag&quot;</span><span class="p">,</span> <span class="n">model_name_or_path</span><span class="o">=</span><span class="s2">&quot;ner-ontonotes&quot;</span><span class="p">)</span>
</pre></div>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

</div>
 

