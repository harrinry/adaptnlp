---

title: Token Tagging and Classification


keywords: fastai
sidebar: home_sidebar

summary: "AdaptiveModels for using Transformers and Flair for token tagging and classification"
description: "AdaptiveModels for using Transformers and Flair for token tagging and classification"
nb_path: "nbs/05_token_classification.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/05_token_classification.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="TransformersTokenTagger" class="doc_header"><code>class</code> <code>TransformersTokenTagger</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/token_classification.py#L39" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>TransformersTokenTagger</code>(<strong><code>tokenizer</code></strong>:<code>PreTrainedTokenizer</code>, <strong><code>model</code></strong>:<code>PreTrainedModel</code>) :: <a href="/adaptnlp/model.html#AdaptiveModel"><code>AdaptiveModel</code></a></p>
</blockquote>
<p>Adaptive model for Transformer's Token Tagger Model</p>
<p>Usage:</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">tagger</span> <span class="o">=</span> <span class="n">TransformersTokenTagger</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;dbmdz/bert-large-cased-finetuned-conll03-english&quot;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">tagger</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s2">&quot;Example text&quot;</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</pre></div>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong>tokenizer</strong> - A tokenizer object from Huggingface's transformers (TODO) and tokenizers</li>
<li><strong>model</strong> - A transformers token tagger model</li>
</ul>
<p><strong>Usage Examples:</strong></p>
<p><b><a href=https://nbviewer.jupyter.org/github/novetta/adaptnlp/tree/master/nbs/05_token_classification.ipynb>Source</a></b></p>
<div class="highlight"><pre><span></span><span class="c1">#hide</span>
<span class="n">tagger</span> <span class="o">=</span> <span class="n">TransformersTokenTagger</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;dbmdz/bert-large-cased-finetuned-conll03-english&quot;</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">tagger</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s1">&#39;Novetta Solutions is the best. Albert Einstein used to be employed at Novetta Solutions. The Wright brothers loved to visit the JBF headquarters, and they would have a chat with Albert.&#39;</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">baseline</span> <span class="o">=</span> <span class="p">[[{</span><span class="s1">&#39;entity_group&#39;</span><span class="p">:</span> <span class="s1">&#39;I-ORG&#39;</span><span class="p">,</span>
   <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.998292068640391</span><span class="p">,</span>
   <span class="s1">&#39;word&#39;</span><span class="p">:</span> <span class="s1">&#39;Novetta Solutions&#39;</span><span class="p">,</span>
   <span class="s1">&#39;offsets&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">)},</span>
  <span class="p">{</span><span class="s1">&#39;entity_group&#39;</span><span class="p">:</span> <span class="s1">&#39;I-PER&#39;</span><span class="p">,</span>
   <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.9985582232475281</span><span class="p">,</span>
   <span class="s1">&#39;word&#39;</span><span class="p">:</span> <span class="s1">&#39;Albert Einstein&#39;</span><span class="p">,</span>
   <span class="s1">&#39;offsets&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">)},</span>
  <span class="p">{</span><span class="s1">&#39;entity_group&#39;</span><span class="p">:</span> <span class="s1">&#39;I-ORG&#39;</span><span class="p">,</span>
   <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.9970489343007406</span><span class="p">,</span>
   <span class="s1">&#39;word&#39;</span><span class="p">:</span> <span class="s1">&#39;Novetta Solutions&#39;</span><span class="p">,</span>
   <span class="s1">&#39;offsets&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">17</span><span class="p">)},</span>
  <span class="p">{</span><span class="s1">&#39;entity_group&#39;</span><span class="p">:</span> <span class="s1">&#39;I-PER&#39;</span><span class="p">,</span>
   <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.9961656928062439</span><span class="p">,</span>
   <span class="s1">&#39;word&#39;</span><span class="p">:</span> <span class="s1">&#39;Wright&#39;</span><span class="p">,</span>
   <span class="s1">&#39;offsets&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">19</span><span class="p">,</span> <span class="mi">20</span><span class="p">)},</span>
  <span class="p">{</span><span class="s1">&#39;entity_group&#39;</span><span class="p">:</span> <span class="s1">&#39;I-ORG&#39;</span><span class="p">,</span>
   <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.9933501183986664</span><span class="p">,</span>
   <span class="s1">&#39;word&#39;</span><span class="p">:</span> <span class="s1">&#39;JBF&#39;</span><span class="p">,</span>
   <span class="s1">&#39;offsets&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">27</span><span class="p">)}]]</span>

<span class="k">for</span> <span class="n">base</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">baseline</span><span class="p">,</span> <span class="n">pred</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">base_items</span><span class="p">,</span> <span class="n">p_items</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">base</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
        <span class="n">test_eq</span><span class="p">(</span><span class="n">base_items</span><span class="p">[</span><span class="s1">&#39;entity_group&#39;</span><span class="p">],</span> <span class="n">p_items</span><span class="p">[</span><span class="s1">&#39;entity_group&#39;</span><span class="p">])</span>
        <span class="n">test_close</span><span class="p">(</span><span class="n">base_items</span><span class="p">[</span><span class="s1">&#39;score&#39;</span><span class="p">],</span> <span class="n">p_items</span><span class="p">[</span><span class="s1">&#39;score&#39;</span><span class="p">],</span> <span class="mf">1e-3</span><span class="p">)</span>
        <span class="n">test_eq</span><span class="p">(</span><span class="n">base_items</span><span class="p">[</span><span class="s1">&#39;word&#39;</span><span class="p">],</span> <span class="n">p_items</span><span class="p">[</span><span class="s1">&#39;word&#39;</span><span class="p">])</span>
        <span class="n">test_eq</span><span class="p">(</span><span class="n">base_items</span><span class="p">[</span><span class="s1">&#39;offsets&#39;</span><span class="p">],</span> <span class="n">p_items</span><span class="p">[</span><span class="s1">&#39;offsets&#39;</span><span class="p">])</span>
</pre></div>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="TransformersTokenTagger.load" class="doc_header"><code>TransformersTokenTagger.load</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/token_classification.py#L62" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>TransformersTokenTagger.load</code>(<strong><code>model_name_or_path</code></strong>:<code>str</code>)</p>
</blockquote>
<p>Class method for loading and constructing this tagger</p>
<ul>
<li><strong>model_name_or_path</strong> - A key string of one of Transformer's pre-trained Token Tagger Model or a <a href="/adaptnlp/model_hub.html#HFModelResult"><code>HFModelResult</code></a></li>
</ul>
<p>Note: To search for valid models, you should use the AdaptNLP <a href="/adaptnlp/model_hub.html"><code>model_hub</code></a> API</p>
<p><strong>Usage Examples:</strong></p>
<p><b><a href=https://nbviewer.jupyter.org/github/novetta/adaptnlp/tree/master/nbs/05_token_classification.ipynb>Source</a></b></p>
<div class="highlight"><pre><span></span><span class="c1">#hide</span>
<span class="n">tagger</span> <span class="o">=</span> <span class="n">TransformersTokenTagger</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;dbmdz/bert-large-cased-finetuned-conll03-english&quot;</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">tagger</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s1">&#39;Novetta Solutions is the best. Albert Einstein used to be employed at Novetta Solutions. The Wright brothers loved to visit the JBF headquarters, and they would have a chat with Albert.&#39;</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">baseline</span> <span class="o">=</span> <span class="p">[[{</span><span class="s1">&#39;entity_group&#39;</span><span class="p">:</span> <span class="s1">&#39;I-ORG&#39;</span><span class="p">,</span>
   <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.998292068640391</span><span class="p">,</span>
   <span class="s1">&#39;word&#39;</span><span class="p">:</span> <span class="s1">&#39;Novetta Solutions&#39;</span><span class="p">,</span>
   <span class="s1">&#39;offsets&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">)},</span>
  <span class="p">{</span><span class="s1">&#39;entity_group&#39;</span><span class="p">:</span> <span class="s1">&#39;I-PER&#39;</span><span class="p">,</span>
   <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.9985582232475281</span><span class="p">,</span>
   <span class="s1">&#39;word&#39;</span><span class="p">:</span> <span class="s1">&#39;Albert Einstein&#39;</span><span class="p">,</span>
   <span class="s1">&#39;offsets&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">)},</span>
  <span class="p">{</span><span class="s1">&#39;entity_group&#39;</span><span class="p">:</span> <span class="s1">&#39;I-ORG&#39;</span><span class="p">,</span>
   <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.9970489343007406</span><span class="p">,</span>
   <span class="s1">&#39;word&#39;</span><span class="p">:</span> <span class="s1">&#39;Novetta Solutions&#39;</span><span class="p">,</span>
   <span class="s1">&#39;offsets&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">17</span><span class="p">)},</span>
  <span class="p">{</span><span class="s1">&#39;entity_group&#39;</span><span class="p">:</span> <span class="s1">&#39;I-PER&#39;</span><span class="p">,</span>
   <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.9961656928062439</span><span class="p">,</span>
   <span class="s1">&#39;word&#39;</span><span class="p">:</span> <span class="s1">&#39;Wright&#39;</span><span class="p">,</span>
   <span class="s1">&#39;offsets&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">19</span><span class="p">,</span> <span class="mi">20</span><span class="p">)},</span>
  <span class="p">{</span><span class="s1">&#39;entity_group&#39;</span><span class="p">:</span> <span class="s1">&#39;I-ORG&#39;</span><span class="p">,</span>
   <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.9933501183986664</span><span class="p">,</span>
   <span class="s1">&#39;word&#39;</span><span class="p">:</span> <span class="s1">&#39;JBF&#39;</span><span class="p">,</span>
   <span class="s1">&#39;offsets&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">27</span><span class="p">)}]]</span>

<span class="k">for</span> <span class="n">base</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">baseline</span><span class="p">,</span> <span class="n">pred</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">base_items</span><span class="p">,</span> <span class="n">p_items</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">base</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
        <span class="n">test_eq</span><span class="p">(</span><span class="n">base_items</span><span class="p">[</span><span class="s1">&#39;entity_group&#39;</span><span class="p">],</span> <span class="n">p_items</span><span class="p">[</span><span class="s1">&#39;entity_group&#39;</span><span class="p">])</span>
        <span class="n">test_close</span><span class="p">(</span><span class="n">base_items</span><span class="p">[</span><span class="s1">&#39;score&#39;</span><span class="p">],</span> <span class="n">p_items</span><span class="p">[</span><span class="s1">&#39;score&#39;</span><span class="p">],</span> <span class="mf">1e-3</span><span class="p">)</span>
        <span class="n">test_eq</span><span class="p">(</span><span class="n">base_items</span><span class="p">[</span><span class="s1">&#39;word&#39;</span><span class="p">],</span> <span class="n">p_items</span><span class="p">[</span><span class="s1">&#39;word&#39;</span><span class="p">])</span>
        <span class="n">test_eq</span><span class="p">(</span><span class="n">base_items</span><span class="p">[</span><span class="s1">&#39;offsets&#39;</span><span class="p">],</span> <span class="n">p_items</span><span class="p">[</span><span class="s1">&#39;offsets&#39;</span><span class="p">])</span>
</pre></div>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="TransformersTokenTagger.predict" class="doc_header"><code>TransformersTokenTagger.predict</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/token_classification.py#L76" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>TransformersTokenTagger.predict</code>(<strong><code>text</code></strong>:<code>Union</code>[<code>List</code>[<code>str</code>], <code>str</code>], <strong><code>mini_batch_size</code></strong>:<code>int</code>=<em><code>32</code></em>, <strong><code>grouped_entities</code></strong>:<code>bool</code>=<em><code>True</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Predict method for running inference using the pre-trained token tagger model.
Returns a list of lists of tagged entities.</p>
<ul>
<li><strong>text</strong> - String, list of strings, sentences, or list of sentences to run inference on</li>
<li><strong>mini_batch_size</strong> - Mini batch size</li>
<li><strong>grouped_entities</strong> - Set True to get whole entity span strings (Default True)</li>
<li><strong>&ast;&ast;kwargs</strong>(Optional) - Optional arguments for the Transformers tagger</li>
</ul>
<p><strong>Usage Examples:</strong></p>
<p><b><a href=https://nbviewer.jupyter.org/github/novetta/adaptnlp/tree/master/nbs/05_token_classification.ipynb>Source</a></b></p>
<div class="highlight"><pre><span></span><span class="c1">#hide</span>
<span class="n">tagger</span> <span class="o">=</span> <span class="n">TransformersTokenTagger</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;dbmdz/bert-large-cased-finetuned-conll03-english&quot;</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">tagger</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s1">&#39;Novetta Solutions is the best. Albert Einstein used to be employed at Novetta Solutions. The Wright brothers loved to visit the JBF headquarters, and they would have a chat with Albert.&#39;</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">baseline</span> <span class="o">=</span> <span class="p">[[{</span><span class="s1">&#39;entity_group&#39;</span><span class="p">:</span> <span class="s1">&#39;I-ORG&#39;</span><span class="p">,</span>
   <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.998292068640391</span><span class="p">,</span>
   <span class="s1">&#39;word&#39;</span><span class="p">:</span> <span class="s1">&#39;Novetta Solutions&#39;</span><span class="p">,</span>
   <span class="s1">&#39;offsets&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">)},</span>
  <span class="p">{</span><span class="s1">&#39;entity_group&#39;</span><span class="p">:</span> <span class="s1">&#39;I-PER&#39;</span><span class="p">,</span>
   <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.9985582232475281</span><span class="p">,</span>
   <span class="s1">&#39;word&#39;</span><span class="p">:</span> <span class="s1">&#39;Albert Einstein&#39;</span><span class="p">,</span>
   <span class="s1">&#39;offsets&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">)},</span>
  <span class="p">{</span><span class="s1">&#39;entity_group&#39;</span><span class="p">:</span> <span class="s1">&#39;I-ORG&#39;</span><span class="p">,</span>
   <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.9970489343007406</span><span class="p">,</span>
   <span class="s1">&#39;word&#39;</span><span class="p">:</span> <span class="s1">&#39;Novetta Solutions&#39;</span><span class="p">,</span>
   <span class="s1">&#39;offsets&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">17</span><span class="p">)},</span>
  <span class="p">{</span><span class="s1">&#39;entity_group&#39;</span><span class="p">:</span> <span class="s1">&#39;I-PER&#39;</span><span class="p">,</span>
   <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.9961656928062439</span><span class="p">,</span>
   <span class="s1">&#39;word&#39;</span><span class="p">:</span> <span class="s1">&#39;Wright&#39;</span><span class="p">,</span>
   <span class="s1">&#39;offsets&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">19</span><span class="p">,</span> <span class="mi">20</span><span class="p">)},</span>
  <span class="p">{</span><span class="s1">&#39;entity_group&#39;</span><span class="p">:</span> <span class="s1">&#39;I-ORG&#39;</span><span class="p">,</span>
   <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.9933501183986664</span><span class="p">,</span>
   <span class="s1">&#39;word&#39;</span><span class="p">:</span> <span class="s1">&#39;JBF&#39;</span><span class="p">,</span>
   <span class="s1">&#39;offsets&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">27</span><span class="p">)}]]</span>

<span class="k">for</span> <span class="n">base</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">baseline</span><span class="p">,</span> <span class="n">pred</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">base_items</span><span class="p">,</span> <span class="n">p_items</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">base</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
        <span class="n">test_eq</span><span class="p">(</span><span class="n">base_items</span><span class="p">[</span><span class="s1">&#39;entity_group&#39;</span><span class="p">],</span> <span class="n">p_items</span><span class="p">[</span><span class="s1">&#39;entity_group&#39;</span><span class="p">])</span>
        <span class="n">test_close</span><span class="p">(</span><span class="n">base_items</span><span class="p">[</span><span class="s1">&#39;score&#39;</span><span class="p">],</span> <span class="n">p_items</span><span class="p">[</span><span class="s1">&#39;score&#39;</span><span class="p">],</span> <span class="mf">1e-3</span><span class="p">)</span>
        <span class="n">test_eq</span><span class="p">(</span><span class="n">base_items</span><span class="p">[</span><span class="s1">&#39;word&#39;</span><span class="p">],</span> <span class="n">p_items</span><span class="p">[</span><span class="s1">&#39;word&#39;</span><span class="p">])</span>
        <span class="n">test_eq</span><span class="p">(</span><span class="n">base_items</span><span class="p">[</span><span class="s1">&#39;offsets&#39;</span><span class="p">],</span> <span class="n">p_items</span><span class="p">[</span><span class="s1">&#39;offsets&#39;</span><span class="p">])</span>
</pre></div>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="FlairTokenTagger" class="doc_header"><code>class</code> <code>FlairTokenTagger</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/token_classification.py#L258" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>FlairTokenTagger</code>(<strong><code>model_name_or_path</code></strong>:<code>str</code>) :: <a href="/adaptnlp/model.html#AdaptiveModel"><code>AdaptiveModel</code></a></p>
</blockquote>
<p>Adaptive Model for Flair's Token Tagger...very basic</p>
<p>Usage:</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">tagger</span> <span class="o">=</span> <span class="n">FlairTokenTagger</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;flair/chunk-english-fast&quot;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">tagger</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s2">&quot;Example text&quot;</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</pre></div>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong>model_name_or_path</strong> - A key string of one of Flair's pre-trained Token tagger Model</li>
</ul>
<p>To find a list of available models, see <a href="https://huggingface.co/models?filter=flair">here</a></p>
<p><strong>Usage Examples:</strong></p>
<p><b><a href=https://nbviewer.jupyter.org/github/novetta/adaptnlp/tree/master/nbs/05_token_classification.ipynb>Source</a></b></p>
<div class="highlight"><pre><span></span><span class="c1">#hide</span>
<span class="n">tagger</span> <span class="o">=</span> <span class="n">FlairTokenTagger</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;flair/chunk-english-fast&quot;</span><span class="p">)</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">tagger</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s2">&quot;Example text&quot;</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">preds</span><span class="o">.</span><span class="n">tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s1">&#39;Example&#39;</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">preds</span><span class="o">.</span><span class="n">tokens</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s1">&#39;text&#39;</span><span class="p">)</span>
</pre></div>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="FlairTokenTagger.load" class="doc_header"><code>FlairTokenTagger.load</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/token_classification.py#L277" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>FlairTokenTagger.load</code>(<strong><code>model_name_or_path</code></strong>:<code>str</code>)</p>
</blockquote>
<p>Class method for loading a constructing this tagger</p>
<ul>
<li><strong>model_name_or_path</strong> - A key string of one of Flair's pre-trained Token tagger Model</li>
</ul>
<p>To find a list of available models, see <a href="https://huggingface.co/models?filter=flair">here</a></p>
<p><strong>Usage Examples:</strong></p>
<p><b><a href=https://nbviewer.jupyter.org/github/novetta/adaptnlp/tree/master/nbs/05_token_classification.ipynb>Source</a></b></p>
<div class="highlight"><pre><span></span><span class="c1">#hide</span>
<span class="n">tagger</span> <span class="o">=</span> <span class="n">FlairTokenTagger</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;flair/chunk-english-fast&quot;</span><span class="p">)</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">tagger</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s2">&quot;Example text&quot;</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">preds</span><span class="o">.</span><span class="n">tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s1">&#39;Example&#39;</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">preds</span><span class="o">.</span><span class="n">tokens</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s1">&#39;text&#39;</span><span class="p">)</span>
</pre></div>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="FlairTokenTagger.predict" class="doc_header"><code>FlairTokenTagger.predict</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/token_classification.py#L288" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>FlairTokenTagger.predict</code>(<strong><code>text</code></strong>:<code>Union</code>[<code>List</code>[<code>Sentence</code>], <code>Sentence</code>, <code>List</code>[<code>str</code>], <code>str</code>], <strong><code>mini_batch_size</code></strong>:<code>int</code>=<em><code>32</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Predict method for running inference using the pre-trained token tagger model</p>
<ul>
<li><strong>text</strong> - String, list of strings, sentences, or list of sentences to run inference on</li>
<li><strong>mini_batch_size</strong> - Mini batch size</li>
<li><strong>&ast;&ast;kwargs</strong>(Optional) - Optional arguments for the Flair tagger</li>
</ul>
<p><strong>Usage Examples:</strong></p>
<p><b><a href=https://nbviewer.jupyter.org/github/novetta/adaptnlp/tree/master/nbs/05_token_classification.ipynb>Source</a></b></p>
<div class="highlight"><pre><span></span><span class="c1">#hide</span>
<span class="n">tagger</span> <span class="o">=</span> <span class="n">FlairTokenTagger</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;flair/chunk-english-fast&quot;</span><span class="p">)</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">tagger</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s2">&quot;Example text&quot;</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">preds</span><span class="o">.</span><span class="n">tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s1">&#39;Example&#39;</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">preds</span><span class="o">.</span><span class="n">tokens</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s1">&#39;text&#39;</span><span class="p">)</span>
</pre></div>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="EasyTokenTagger" class="doc_header"><code>class</code> <code>EasyTokenTagger</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/token_classification.py#L324" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>EasyTokenTagger</code>()</p>
</blockquote>
<p>Token level classification models</p>
<p>Usage:</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">tagger</span> <span class="o">=</span> <span class="n">adaptnlp</span><span class="o">.</span><span class="n">EasyTokenTagger</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">tagger</span><span class="o">.</span><span class="n">tag_text</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s2">&quot;text you want to tag&quot;</span><span class="p">,</span> <span class="n">model_name_or_path</span><span class="o">=</span><span class="s2">&quot;ner-ontonotes&quot;</span><span class="p">)</span>
</pre></div>
<p><strong>Usage Examples:</strong></p>
<p><b><a href=https://nbviewer.jupyter.org/github/novetta/adaptnlp/tree/master/nbs/05a_tutorial.token_tagging.ipynb>Source</a></b></p>
<div class="highlight"><pre><span></span><span class="n">example_text</span> <span class="o">=</span> <span class="s1">&#39;&#39;&#39;Novetta Solutions is the best. Albert Einstein used to be employed at Novetta Solutions. </span>
<span class="s1">The Wright brothers loved to visit the JBF headquarters, and they would have a chat with Albert.&#39;&#39;&#39;</span>
<span class="n">tagger</span> <span class="o">=</span> <span class="n">EasyTokenTagger</span><span class="p">()</span>
</pre></div>
<p><b><a href=https://nbviewer.jupyter.org/github/novetta/adaptnlp/tree/master/nbs/05a_tutorial.token_tagging.ipynb>Source</a></b></p>
<div class="highlight"><pre><span></span><span class="n">tagger</span> <span class="o">=</span> <span class="n">EasyTokenTagger</span><span class="p">()</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">tagger</span><span class="o">.</span><span class="n">tag_text</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">example_text</span><span class="p">,</span> <span class="n">model_name_or_path</span><span class="o">=</span><span class="s2">&quot;ner-ontonotes&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">tagger</span><span class="o">.</span><span class="n">tag_text</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">example_text</span><span class="p">,</span> <span class="n">model_name_or_path</span><span class="o">=</span><span class="s2">&quot;pos&quot;</span><span class="p">)</span>
<span class="n">sentences</span> <span class="o">=</span> <span class="n">tagger</span><span class="o">.</span><span class="n">tag_all</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">example_text</span><span class="p">)</span>
</pre></div>
<p><b><a href=https://nbviewer.jupyter.org/github/novetta/adaptnlp/tree/master/nbs/05_token_classification.ipynb>Source</a></b></p>
<div class="highlight"><pre><span></span><span class="c1">#hide</span>
<span class="n">tagger</span> <span class="o">=</span> <span class="n">EasyTokenTagger</span><span class="p">()</span>
<span class="n">example_text</span> <span class="o">=</span> <span class="s1">&#39;&#39;&#39;Novetta Solutions is the best. Albert Einstein used to be employed at Novetta Solutions. </span>
<span class="s1">The Wright brothers loved to visit the JBF headquarters, and they would have a chat with Albert.&#39;&#39;&#39;</span>
<span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Jack walked through the park on a Sunday.&quot;</span><span class="p">,</span> <span class="s2">&quot;Sunday was a nice and breezy afternoon.&quot;</span><span class="p">,</span> <span class="s2">&quot;Jack was going to meet Jill for dinner.&quot;</span><span class="p">]</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">tagger</span><span class="o">.</span><span class="n">tag_text</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">example_text</span><span class="p">,</span> <span class="n">model_name_or_path</span><span class="o">=</span><span class="s2">&quot;ner-ontonotes&quot;</span><span class="p">)</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">tagger</span><span class="o">.</span><span class="n">tag_text</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">example_text</span><span class="p">,</span> <span class="n">model_name_or_path</span><span class="o">=</span><span class="s2">&quot;pos&quot;</span><span class="p">)</span>
<span class="c1">#hide</span>
<span class="n">tags</span> <span class="o">=</span> <span class="n">tagger</span><span class="o">.</span><span class="n">tag_all</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span>
<span class="n">_types</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">&quot;PERSON&quot;</span><span class="p">,</span> <span class="s2">&quot;DATE&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;DATE&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;PERSON&quot;</span><span class="p">,</span> <span class="s2">&quot;PERSON&quot;</span><span class="p">]]</span>

<span class="k">for</span> <span class="n">sentence</span><span class="p">,</span> <span class="n">lbls</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">tags</span><span class="p">,</span> <span class="n">_types</span><span class="p">):</span>
    <span class="n">spans</span> <span class="o">=</span> <span class="n">sentence</span><span class="o">.</span><span class="n">get_spans</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">span</span><span class="p">,</span> <span class="n">lbl</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">spans</span><span class="p">,</span> <span class="n">lbls</span><span class="p">):</span>
        <span class="n">test_eq</span><span class="p">(</span><span class="n">span</span><span class="o">.</span><span class="n">tag</span><span class="p">,</span> <span class="n">lbl</span><span class="p">)</span>
</pre></div>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="EasyTokenTagger.tag_text" class="doc_header"><code>EasyTokenTagger.tag_text</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/token_classification.py#L338" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>EasyTokenTagger.tag_text</code>(<strong><code>text</code></strong>:<code>Union</code>[<code>List</code>[<code>Sentence</code>], <code>Sentence</code>, <code>List</code>[<code>str</code>], <code>str</code>], <strong><code>model_name_or_path</code></strong>:<code>Union</code>[<code>str</code>, <a href="/adaptnlp/model_hub.html#FlairModelResult"><code>FlairModelResult</code></a>, <a href="/adaptnlp/model_hub.html#HFModelResult"><code>HFModelResult</code></a>]=<em><code>'ner-ontonotes'</code></em>, <strong><code>mini_batch_size</code></strong>:<code>int</code>=<em><code>32</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Tags tokens with labels the token classification models have been trained on</p>
<ul>
<li><strong>text</strong> - Text input, it can be a string or any of Flair's <code>Sentence</code> input formats</li>
<li><strong>model_name_or_path</strong> - The hosted model name key or model path</li>
<li><strong>mini_batch_size</strong> - The mini batch size for running inference</li>
<li><strong>&ast;&ast;kwargs</strong> - Keyword arguments for Flair's <code>SequenceTagger.predict()</code> method
<strong>return</strong> - A list of Flair's <code>Sentence</code>'s</li>
</ul>
<p><strong>Usage Examples:</strong></p>
<p><b><a href=https://nbviewer.jupyter.org/github/novetta/adaptnlp/tree/master/nbs/05a_tutorial.token_tagging.ipynb>Source</a></b></p>
<div class="highlight"><pre><span></span><span class="n">tagger</span> <span class="o">=</span> <span class="n">EasyTokenTagger</span><span class="p">()</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">tagger</span><span class="o">.</span><span class="n">tag_text</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">example_text</span><span class="p">,</span> <span class="n">model_name_or_path</span><span class="o">=</span><span class="s2">&quot;ner-ontonotes&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">tagger</span><span class="o">.</span><span class="n">tag_text</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">example_text</span><span class="p">,</span> <span class="n">model_name_or_path</span><span class="o">=</span><span class="s2">&quot;pos&quot;</span><span class="p">)</span>
</pre></div>
<p><b><a href=https://nbviewer.jupyter.org/github/novetta/adaptnlp/tree/master/nbs/05_token_classification.ipynb>Source</a></b></p>
<div class="highlight"><pre><span></span><span class="c1">#hide</span>
<span class="n">tagger</span> <span class="o">=</span> <span class="n">EasyTokenTagger</span><span class="p">()</span>
<span class="n">example_text</span> <span class="o">=</span> <span class="s1">&#39;&#39;&#39;Novetta Solutions is the best. Albert Einstein used to be employed at Novetta Solutions. </span>
<span class="s1">The Wright brothers loved to visit the JBF headquarters, and they would have a chat with Albert.&#39;&#39;&#39;</span>
<span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Jack walked through the park on a Sunday.&quot;</span><span class="p">,</span> <span class="s2">&quot;Sunday was a nice and breezy afternoon.&quot;</span><span class="p">,</span> <span class="s2">&quot;Jack was going to meet Jill for dinner.&quot;</span><span class="p">]</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">tagger</span><span class="o">.</span><span class="n">tag_text</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">example_text</span><span class="p">,</span> <span class="n">model_name_or_path</span><span class="o">=</span><span class="s2">&quot;ner-ontonotes&quot;</span><span class="p">)</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">tagger</span><span class="o">.</span><span class="n">tag_text</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">example_text</span><span class="p">,</span> <span class="n">model_name_or_path</span><span class="o">=</span><span class="s2">&quot;pos&quot;</span><span class="p">)</span>
</pre></div>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="EasyTokenTagger.tag_all" class="doc_header"><code>EasyTokenTagger.tag_all</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/token_classification.py#L398" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>EasyTokenTagger.tag_all</code>(<strong><code>text</code></strong>:<code>Union</code>[<code>List</code>[<code>Sentence</code>], <code>Sentence</code>, <code>List</code>[<code>str</code>], <code>str</code>], <strong><code>mini_batch_size</code></strong>:<code>int</code>=<em><code>32</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Tags tokens with all labels from all token classification models</p>
<ul>
<li><strong>text</strong> - Text input, it can be a string or any of Flair's <code>Sentence</code> input formats</li>
<li><strong>mini_batch_size</strong> - The mini batch size for running inference</li>
<li><strong>&ast;&ast;kwargs</strong> - Keyword arguments for Flair's <code>SequenceTagger.predict()</code> method
<strong>return</strong> A list of Flair's <code>Sentence</code>'s</li>
</ul>
<p><strong>Usage Examples:</strong></p>
<p><b><a href=https://nbviewer.jupyter.org/github/novetta/adaptnlp/tree/master/nbs/05_token_classification.ipynb>Source</a></b></p>
<div class="highlight"><pre><span></span><span class="c1">#hide</span>
<span class="n">tagger</span> <span class="o">=</span> <span class="n">EasyTokenTagger</span><span class="p">()</span>
<span class="n">example_text</span> <span class="o">=</span> <span class="s1">&#39;&#39;&#39;Novetta Solutions is the best. Albert Einstein used to be employed at Novetta Solutions. </span>
<span class="s1">The Wright brothers loved to visit the JBF headquarters, and they would have a chat with Albert.&#39;&#39;&#39;</span>
<span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Jack walked through the park on a Sunday.&quot;</span><span class="p">,</span> <span class="s2">&quot;Sunday was a nice and breezy afternoon.&quot;</span><span class="p">,</span> <span class="s2">&quot;Jack was going to meet Jill for dinner.&quot;</span><span class="p">]</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">tagger</span><span class="o">.</span><span class="n">tag_text</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">example_text</span><span class="p">,</span> <span class="n">model_name_or_path</span><span class="o">=</span><span class="s2">&quot;ner-ontonotes&quot;</span><span class="p">)</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">tagger</span><span class="o">.</span><span class="n">tag_text</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">example_text</span><span class="p">,</span> <span class="n">model_name_or_path</span><span class="o">=</span><span class="s2">&quot;pos&quot;</span><span class="p">)</span>
<span class="c1">#hide</span>
<span class="n">tags</span> <span class="o">=</span> <span class="n">tagger</span><span class="o">.</span><span class="n">tag_all</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span>
<span class="n">_types</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">&quot;PERSON&quot;</span><span class="p">,</span> <span class="s2">&quot;DATE&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;DATE&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;PERSON&quot;</span><span class="p">,</span> <span class="s2">&quot;PERSON&quot;</span><span class="p">]]</span>

<span class="k">for</span> <span class="n">sentence</span><span class="p">,</span> <span class="n">lbls</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">tags</span><span class="p">,</span> <span class="n">_types</span><span class="p">):</span>
    <span class="n">spans</span> <span class="o">=</span> <span class="n">sentence</span><span class="o">.</span><span class="n">get_spans</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">span</span><span class="p">,</span> <span class="n">lbl</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">spans</span><span class="p">,</span> <span class="n">lbls</span><span class="p">):</span>
        <span class="n">test_eq</span><span class="p">(</span><span class="n">span</span><span class="o">.</span><span class="n">tag</span><span class="p">,</span> <span class="n">lbl</span><span class="p">)</span>
</pre></div>
<p><b><a href=https://nbviewer.jupyter.org/github/novetta/adaptnlp/tree/master/nbs/05a_tutorial.token_tagging.ipynb>Source</a></b></p>
<div class="highlight"><pre><span></span><span class="n">tagger</span> <span class="o">=</span> <span class="n">EasyTokenTagger</span><span class="p">()</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">tagger</span><span class="o">.</span><span class="n">tag_text</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">example_text</span><span class="p">,</span> <span class="n">model_name_or_path</span><span class="o">=</span><span class="s2">&quot;ner-ontonotes&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">tagger</span><span class="o">.</span><span class="n">tag_text</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">example_text</span><span class="p">,</span> <span class="n">model_name_or_path</span><span class="o">=</span><span class="s2">&quot;pos&quot;</span><span class="p">)</span>
<span class="n">sentences</span> <span class="o">=</span> <span class="n">tagger</span><span class="o">.</span><span class="n">tag_all</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">example_text</span><span class="p">)</span>
</pre></div>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

