---

title: Token Tagging and Classification


keywords: fastai
sidebar: home_sidebar

summary: "AdaptiveModels for using Transformers and Flair for token tagging and classification"
description: "AdaptiveModels for using Transformers and Flair for token tagging and classification"
nb_path: "nbs/05_token_classification.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/05_token_classification.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="TokenClassificationResult" class="doc_header"><code>class</code> <code>TokenClassificationResult</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/inference/token_classification.py#L41" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>TokenClassificationResult</code>(<strong><code>inputs</code></strong>:<code>str</code>, <strong><code>tokenized_inputs</code></strong>:<code>tensor</code>, <strong><code>tagged_entities</code></strong>:<code>dict</code>)</p>
</blockquote>
<p>A result class for Token Tagging tasks</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>inputs</code></strong> : <em><code>&lt;class 'str'&gt;</code></em> <p>Original text inputs</p></li>
</ul>
<ul>
<li><strong><code>tokenized_inputs</code></strong> : <em><code>&lt;built-in method tensor of type object at 0x7f3cfa198ec0&gt;</code></em>   <p>Tokenized inputs</p></li>
</ul>
<ul>
<li><strong><code>tagged_entities</code></strong> : <em><code>&lt;class 'dict'&gt;</code></em></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="TokenClassificationResult.to_dict" class="doc_header"><code>TokenClassificationResult.to_dict</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/inference/token_classification.py#L53" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>TokenClassificationResult.to_dict</code>(<strong><code>detail_level</code></strong>:<code>DetailLevel</code>=<em><code>'low'</code></em>)</p>
</blockquote>
<p>Convert <code>self</code> to a dictionary</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>detail_level</code></strong> : <em><code>&lt;class 'fastcore.basics.DetailLevel'&gt;</code></em>, <em>optional</em>   <p>A level of detail to return</p></li>
</ul>
<p><strong>Returns</strong>:</p>
<ul>
<li><em><code>&lt;class 'dict'&gt;</code></em></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="TransformersTokenTagger" class="doc_header"><code>class</code> <code>TransformersTokenTagger</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/inference/token_classification.py#L76" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>TransformersTokenTagger</code>(<strong><code>tokenizer</code></strong>:<code>PreTrainedTokenizer</code>, <strong><code>model</code></strong>:<code>PreTrainedModel</code>) :: <a href="/adaptnlp/model.html#AdaptiveModel"><code>AdaptiveModel</code></a></p>
</blockquote>
<p>Adaptive model for Transformer's Token Tagger Model</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>tokenizer</code></strong> : <em><code>&lt;class 'transformers.tokenization_utils.PreTrainedTokenizer'&gt;</code></em>  <p>A tokenizer object from Huggingface's transformers (TODO) and tokenizers</p></li>
</ul>
<ul>
<li><strong><code>model</code></strong> : <em><code>&lt;class 'transformers.modeling_utils.PreTrainedModel'&gt;</code></em>  <p>A transformers token tagger model</p></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="TransformersTokenTagger.load" class="doc_header"><code>TransformersTokenTagger.load</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/inference/token_classification.py#L90" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>TransformersTokenTagger.load</code>(<strong><code>model_name_or_path</code></strong>:<code>str</code>)</p>
</blockquote>
<p>Class method for loading and constructing this tagger</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>model_name_or_path</code></strong> : <em><code>&lt;class 'str'&gt;</code></em> <p>A key string of one of Transformer's pre-trained Token Tagger Model or a `HFModelResult`</p></li>
</ul>
<p><strong>Returns</strong>:</p>
<ul>
<li><em><code>&lt;class 'adaptnlp.model.AdaptiveModel'&gt;</code></em></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="TransformersTokenTagger.predict" class="doc_header"><code>TransformersTokenTagger.predict</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/inference/token_classification.py#L102" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>TransformersTokenTagger.predict</code>(<strong><code>text</code></strong>:<code>Union</code>[<code>List</code>[<code>str</code>], <code>str</code>], <strong><code>mini_batch_size</code></strong>:<code>int</code>=<em><code>32</code></em>, <strong><code>grouped_entities</code></strong>:<code>bool</code>=<em><code>True</code></em>, <strong><code>detail_level</code></strong>:<code>DetailLevel</code>=<em><code>'low'</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Predict method for running inference using the pre-trained token tagger model</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>text</code></strong> : <em><code>typing.Union[typing.List[str], str]</code></em> <p>Sentences to run inference on</p></li>
</ul>
<ul>
<li><strong><code>mini_batch_size</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em>    <p>Mini batch size</p></li>
</ul>
<ul>
<li><strong><code>grouped_entities</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em>  <p>Return whole entity span strings</p></li>
</ul>
<ul>
<li><strong><code>detail_level</code></strong> : <em><code>&lt;class 'fastcore.basics.DetailLevel'&gt;</code></em>, <em>optional</em>   <p>A level of detail to return</p></li>
</ul>
<ul>
<li><strong><code>kwargs</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em></li>
</ul>
<p><strong>Returns</strong>:</p>
<ul>
<li><em><code>typing.List[typing.List[typing.Dict]]</code></em>    <p>Returns a list of lists of tagged entities</p></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="FlairTokenTagger" class="doc_header"><code>class</code> <code>FlairTokenTagger</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/inference/token_classification.py#L270" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>FlairTokenTagger</code>(<strong><code>model_name_or_path</code></strong>:<code>str</code>) :: <a href="/adaptnlp/model.html#AdaptiveModel"><code>AdaptiveModel</code></a></p>
</blockquote>
<p>Adaptive Model for Flair's Token Tagger</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>model_name_or_path</code></strong> : <em><code>&lt;class 'str'&gt;</code></em> <p>A key string of one of Flair's pre-trained Token tagger Model, [link](https://huggingface.co/models?filter=flair)</p></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="FlairTokenTagger.load" class="doc_header"><code>FlairTokenTagger.load</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/inference/token_classification.py#L279" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>FlairTokenTagger.load</code>(<strong><code>model_name_or_path</code></strong>:<code>str</code>)</p>
</blockquote>
<p>Class method for loading a constructing this tagger</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>model_name_or_path</code></strong> : <em><code>&lt;class 'str'&gt;</code></em> <p>A key string of one of Flair's pre-trained Token tagger Model, [link](https://huggingface.co/models?filter=flair)</p></li>
</ul>
<p><strong>Returns</strong>:</p>
<ul>
<li><em><code>&lt;class 'adaptnlp.model.AdaptiveModel'&gt;</code></em></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="FlairTokenTagger.predict" class="doc_header"><code>FlairTokenTagger.predict</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/inference/token_classification.py#L288" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>FlairTokenTagger.predict</code>(<strong><code>text</code></strong>:<code>Union</code>[<code>List</code>[<code>Sentence</code>], <code>Sentence</code>, <code>List</code>[<code>str</code>], <code>str</code>], <strong><code>mini_batch_size</code></strong>:<code>int</code>=<em><code>32</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Predict method for running inference using the pre-trained token tagger model</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>text</code></strong> : <em><code>typing.Union[typing.List[flair.data.Sentence], flair.data.Sentence, typing.List[str], str]</code></em>  <p>Sentences to run inference on</p></li>
</ul>
<ul>
<li><strong><code>mini_batch_size</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em>    <p>Mini batch size</p></li>
</ul>
<ul>
<li><strong><code>kwargs</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em></li>
</ul>
<p><strong>Returns</strong>:</p>
<ul>
<li><em><code>typing.List[flair.data.Sentence]</code></em> <p>A list of predicted sentences</p></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="EasyTokenTagger" class="doc_header"><code>class</code> <code>EasyTokenTagger</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/inference/token_classification.py#L308" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>EasyTokenTagger</code>()</p>
</blockquote>
<p>Token level classification models</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="EasyTokenTagger.tag_text" class="doc_header"><code>EasyTokenTagger.tag_text</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/inference/token_classification.py#L314" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>EasyTokenTagger.tag_text</code>(<strong><code>text</code></strong>:<code>Union</code>[<code>List</code>[<code>Sentence</code>], <code>Sentence</code>, <code>List</code>[<code>str</code>], <code>str</code>], <strong><code>model_name_or_path</code></strong>:<code>Union</code>[<code>str</code>, <a href="/adaptnlp/model_hub.html#FlairModelResult"><code>FlairModelResult</code></a>, <a href="/adaptnlp/model_hub.html#HFModelResult"><code>HFModelResult</code></a>]=<em><code>'ner-ontonotes'</code></em>, <strong><code>mini_batch_size</code></strong>:<code>int</code>=<em><code>32</code></em>, <strong><code>detail_level</code></strong>:<code>DetailLevel</code>=<em><code>'low'</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Tags tokens with labels the token classification models have been trained on</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>text</code></strong> : <em><code>typing.Union[typing.List[flair.data.Sentence], flair.data.Sentence, typing.List[str], str]</code></em>  <p>Text input, it can be a string or any of Flair's `Sentence` input formats</p></li>
</ul>
<ul>
<li><strong><code>model_name_or_path</code></strong> : <em><code>typing.Union[str, adaptnlp.model_hub.FlairModelResult, adaptnlp.model_hub.HFModelResult]</code></em>, <em>optional</em>  <p>The hosted model name key or model path</p></li>
</ul>
<ul>
<li><strong><code>mini_batch_size</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em>    <p>The mini batch size for running inference</p></li>
</ul>
<ul>
<li><strong><code>detail_level</code></strong> : <em><code>&lt;class 'fastcore.basics.DetailLevel'&gt;</code></em>, <em>optional</em>   <p>The level fo detail to return on a TransformerTagger</p></li>
</ul>
<ul>
<li><strong><code>kwargs</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em></li>
</ul>
<p><strong>Returns</strong>:</p>
<ul>
<li><em><code>typing.List[flair.data.Sentence]</code></em> <p>A list of Flair's `Sentence`'s</p></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="EasyTokenTagger.tag_all" class="doc_header"><code>EasyTokenTagger.tag_all</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/inference/token_classification.py#L375" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>EasyTokenTagger.tag_all</code>(<strong><code>text</code></strong>:<code>Union</code>[<code>List</code>[<code>Sentence</code>], <code>Sentence</code>, <code>List</code>[<code>str</code>], <code>str</code>], <strong><code>mini_batch_size</code></strong>:<code>int</code>=<em><code>32</code></em>, <strong><code>detail_level</code></strong>:<code>DetailLevel</code>=<em><code>'low'</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Tags tokens with all labels from all token classification models</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>text</code></strong> : <em><code>typing.Union[typing.List[flair.data.Sentence], flair.data.Sentence, typing.List[str], str]</code></em>  <p>Text input, it can be a string or any of Flair's `Sentence` input formats</p></li>
</ul>
<ul>
<li><strong><code>mini_batch_size</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em>    <p>The mini batch size for running inference</p></li>
</ul>
<ul>
<li><strong><code>detail_level</code></strong> : <em><code>&lt;class 'fastcore.basics.DetailLevel'&gt;</code></em>, <em>optional</em>   <p>The level of detail for a TransformersTagger to return</p></li>
</ul>
<ul>
<li><strong><code>kwargs</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em></li>
</ul>
<p><strong>Returns</strong>:</p>
<ul>
<li><em><code>typing.List[flair.data.Sentence]</code></em> <p>A list of Flair's `Sentence`'s</p></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

