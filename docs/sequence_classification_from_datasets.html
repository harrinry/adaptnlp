---

title: Tutorial&#58; Fine-Tuning Sequence Classification on HuggingFace `Datasets` with MRPC


keywords: fastai
sidebar: home_sidebar

summary: "Tuning a Sequence Classification model on the Microsoft MRPC dataset"
description: "Tuning a Sequence Classification model on the Microsoft MRPC dataset"
nb_path: "nbs/training_api_tutorials/sequence_classification/sequence_classification_from_datasets.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/training_api_tutorials/sequence_classification/sequence_classification_from_datasets.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Introduction">Introduction<a class="anchor-link" href="#Introduction"> </a></h2><p>In this tutorial we will be showing an end-to-end example of fine-tuning a Transformer for sequence classification on a custom dataset in HuggingFace <code>Dataset</code> format.</p>
<p>By the end of this you should be able to:</p>
<ol>
<li>Build a dataset with the <a href="/adaptnlp/training.core.html#TaskDatasets"><code>TaskDatasets</code></a> class, and their DataLoaders</li>
<li>Build a <a href="/adaptnlp/training.sequence_classification.html#SequenceClassificationTuner"><code>SequenceClassificationTuner</code></a> quickly, find a good learning rate, and train with the One-Cycle Policy</li>
<li>Save that model away, to be used with deployment or other HuggingFace libraries</li>
<li>Apply inference using both the <code>Tuner</code> available function as well as with the <a href="/adaptnlp/sequence_classification.html#EasySequenceClassifier"><code>EasySequenceClassifier</code></a> class within AdaptNLP</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Installing-the-Library">Installing the Library<a class="anchor-link" href="#Installing-the-Library"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This tutorial utilizies the latest AdaptNLP version, as well as parts of the <code>fastai</code> library. Please run the below code to install them:</p>
<div class="highlight"><pre><span></span><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">adaptnlp</span> <span class="o">-</span><span class="n">U</span>
</pre></div>
<p>(or <code>pip3</code>)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Getting-the-Dataset">Getting the Dataset<a class="anchor-link" href="#Getting-the-Dataset"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>First we need a dataset. We will use <code>dataset</code>'s <code>load_dataset</code> function to quickly generate a raw dataset straight from HuggingFace:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">raw_datasets</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;glue&quot;</span><span class="p">,</span> <span class="s2">&quot;mrpc&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>

Downloading and preparing dataset glue/mrpc (download: 1.43 MiB, generated: 1.43 MiB, post-processed: Unknown size, total: 2.85 MiB) to /root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...



Dataset glue downloaded and prepared to /root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We now have a raw <code>datasets</code> dataset, which we can index into:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">raw_datasets</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;idx&#39;: 0,
 &#39;label&#39;: 1,
 &#39;sentence1&#39;: &#39;Amrozi accused his brother , whom he called &#34; the witness &#34; , of deliberately distorting his evidence .&#39;,
 &#39;sentence2&#39;: &#39;Referring to him as only &#34; the witness &#34; , Amrozi accused his brother of deliberately distorting his evidence .&#39;}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now that we have the data downloaded, let's decide on a model to use.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Picking-a-Model-with-the-Hub">Picking a Model with the Hub<a class="anchor-link" href="#Picking-a-Model-with-the-Hub"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>AdaptNLP has a <a href="/adaptnlp/model_hub.html#HFModelHub"><code>HFModelHub</code></a> class that allows you to communicate with the HuggingFace Hub and pick a model from it, as well as a namespace <code>HF_TASKS</code> class with a list of valid tasks we can search by.</p>
<p>Let's try and find one suitable for sequence classification.</p>
<p>First we need to import the class and generate an instance of it:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">HFModelHub</span><span class="p">,</span> <span class="n">HF_TASKS</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hub</span> <span class="o">=</span> <span class="n">HFModelHub</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next we can search for a model:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">models</span> <span class="o">=</span> <span class="n">hub</span><span class="o">.</span><span class="n">search_model_by_task</span><span class="p">(</span><span class="n">HF_TASKS</span><span class="o">.</span><span class="n">TEXT_CLASSIFICATION</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's look at a few:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">models</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[Model Name: distilbert-base-uncased-finetuned-sst-2-english, Tasks: [text-classification],
 Model Name: roberta-base-openai-detector, Tasks: [text-classification],
 Model Name: roberta-large-mnli, Tasks: [text-classification],
 Model Name: roberta-large-openai-detector, Tasks: [text-classification]]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>These are models specifically tagged with the <code>text-classification</code> tag, so you may not see a few models you would expect such as <code>bert_base_cased</code>.</p>
<p>Let's search for that one for this problem:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">models</span> <span class="o">=</span> <span class="n">hub</span><span class="o">.</span><span class="n">search_model_by_name</span><span class="p">(</span><span class="s1">&#39;bert-base-uncased&#39;</span><span class="p">,</span> <span class="n">user_uploaded</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">models</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[Model Name: bert-base-uncased, Tasks: [fill-mask],
 Model Name: distilbert-base-uncased-distilled-squad, Tasks: [question-answering],
 Model Name: distilbert-base-uncased-finetuned-sst-2-english, Tasks: [text-classification],
 Model Name: distilbert-base-uncased, Tasks: [fill-mask],
 Model Name: GD/bert-base-uncased-gh, Tasks: []]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We want the first one.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now that we have picked a model, let's use the data API to prepare our data</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include note.html content='It should be mentioned that this is optional, you can always just pass in the string name of a model such as "bert-base-cased"' %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Building-TaskDatasets">Building <a href="/adaptnlp/training.core.html#TaskDatasets"><code>TaskDatasets</code></a><a class="anchor-link" href="#Building-TaskDatasets"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>All of the task-specific high-level data API's (such as <a href="/adaptnlp/training.sequence_classification.html#SequenceClassificationDatasets"><code>SequenceClassificationDatasets</code></a>) all wrap around the <a href="/adaptnlp/training.core.html#TaskDatasets"><code>TaskDatasets</code></a> class, which is a small wrapper around <code>datasets</code> highly efficient <code>Dataset</code> class.</p>
<p>This integration was valuable because it provides a fast and memory-efficient way to use large datasets with minimal effort.</p>
<p>First let's import the class:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">TaskDatasets</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The <a href="/adaptnlp/training.core.html#TaskDatasets"><code>TaskDatasets</code></a> class has no class constructors outside the normal one. The reason for this is it takes in raw <code>Datasets</code> and other tokenizer arguments to build from:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="TaskDatasets" class="doc_header"><code>class</code> <code>TaskDatasets</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/core.py#L164" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>TaskDatasets</code>(<strong><code>train_dset</code></strong>, <strong><code>valid_dset</code></strong>, <strong><code>tokenizer_name</code></strong>:<code>str</code>=<em><code>None</code></em>, <strong><code>tokenize</code></strong>:<code>bool</code>=<em><code>True</code></em>, <strong><code>tokenize_func</code></strong>:<code>callable</code>=<em><code>None</code></em>, <strong><code>tokenize_kwargs</code></strong>:<code>dict</code>=<em><code>{}</code></em>, <strong><code>auto_kwargs</code></strong>:<code>dict</code>=<em><code>{}</code></em>, <strong><code>remove_cols</code></strong>:<code>Union</code>[<code>str</code>, <code>List</code>[<code>str</code>]]=<em><code>None</code></em>)</p>
</blockquote>
<p>A set of datasets for a particular task, with a simple API.</p>
<p>Note: This is the base API, <code>items</code> should be a set of regular text and model-ready labels,
      including label or one-hot encoding being applied.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>train_dset</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em>  <p>A train `Dataset` object</p></li>
</ul>
<ul>
<li><strong><code>valid_dset</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em>  <p>A validation `Dataset` object</p></li>
</ul>
<ul>
<li><strong><code>tokenizer_name</code></strong> : <em><code>&lt;class 'str'&gt;</code></em>, <em>optional</em> <p>The string name of a `HuggingFace` tokenizer or model. If `None`, will not tokenize the dataset.</p></li>
</ul>
<ul>
<li><strong><code>tokenize</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em>  <p>Whether to tokenize the dataset immediatly</p></li>
</ul>
<ul>
<li><strong><code>tokenize_func</code></strong> : <em><code>&lt;built-in function callable&gt;</code></em>, <em>optional</em>   <p>A function to tokenize an item with</p></li>
</ul>
<ul>
<li><strong><code>tokenize_kwargs</code></strong> : <em><code>&lt;class 'dict'&gt;</code></em>, <em>optional</em>   <p>Some kwargs for when we call the tokenizer</p></li>
</ul>
<ul>
<li><strong><code>auto_kwargs</code></strong> : <em><code>&lt;class 'dict'&gt;</code></em>, <em>optional</em>   <p>Some kwargs when calling `AutoTokenizer.from_pretrained`</p></li>
</ul>
<ul>
<li><strong><code>remove_cols</code></strong> : <em><code>typing.Union[str, typing.List[str]]</code></em>, <em>optional</em>  <p>What columns to remove</p></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Anything you would normally pass to the tokenizer call (such as <code>max_length</code>, <code>padding</code>) should go in <code>tokenize_kwargs</code>, and anything going to the <code>AutoTokenizer.from_pretrained</code> constructor should be passed to the <code>auto_kwargs</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Custom-Tokenization-Function-and-Finishing-our-TaskDatasets">Custom Tokenization Function and Finishing our <a href="/adaptnlp/training.core.html#TaskDatasets"><code>TaskDatasets</code></a><a class="anchor-link" href="#Custom-Tokenization-Function-and-Finishing-our-TaskDatasets"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You may notice there is an extra step here: We need to pass in a <code>tokenize_func</code>. In the other tutorials we used a very basic tokenizing function, and this has a default for that as well.</p>
<p>However given our dataset, we need to implement our own tokenization function.</p>
<p>To do so, your function must take in an <code>item</code>, a <code>tokenizer</code>, and <code>tokenize_kwargs</code>. It should be noted that <strong>you do not have to declare any of these</strong>. All of them are attributes that the <a href="/adaptnlp/training.core.html#TaskDatasets"><code>TaskDatasets</code></a> has access to, and will be passed to this function implicitly.</p>
<p>What you need to declare is <em>how</em> you want the tokenizer applied.</p>
<p>In our case we have two separate sentences that need to be tokenized at once. These texts live in that dictionary we saw earlier at the keys <code>sentence1</code> and <code>sentence2</code>.</p>
<p>Let's write that function:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">tok_func</span><span class="p">(</span>
    <span class="n">item</span><span class="p">,</span> <span class="c1"># A single item in the dataset</span>
    <span class="n">tokenizer</span><span class="p">,</span> <span class="c1"># The implicit tokenizer that `TaskDatasets` has access to</span>
    <span class="n">tokenize_kwargs</span><span class="p">,</span> <span class="c1"># Key word arguments passed into the constructor of `TaskDatasets`</span>
<span class="p">):</span>
    <span class="s2">&quot;A basic tokenization function for two items&quot;</span>
    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span>
        <span class="n">item</span><span class="p">[</span><span class="s1">&#39;sentence1&#39;</span><span class="p">],</span>
        <span class="n">item</span><span class="p">[</span><span class="s1">&#39;sentence2&#39;</span><span class="p">],</span>
        <span class="o">**</span><span class="n">tokenize_kwargs</span>
    <span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Along with building our own tokenize function, we need to tell <code>Datasets</code> what columns to drop when we pull an item from our dataset.</p>
<p>These are synonymous with <code>Datasets</code> <code>remove_cols</code>.</p>
<p>In our problem this includes the <code>sentence1</code>, <code>sentence2</code>, and <code>idx</code> keys, as our tokenized input gets put into a <code>text</code> key:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">remove_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;sentence1&#39;</span><span class="p">,</span> <span class="s1">&#39;sentence2&#39;</span><span class="p">,</span> <span class="s1">&#39;idx&#39;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally we'll declare some arguments for our tokenize function, specifically ensuring our max length is reasonable and that we should pad our samples to that length:
{% include note.html content='These vary problem to problem. You should look at your specific model and dataset to judge what a proper max length and padding should be. AdaptNLP does its best to use a decent default, but it may not work for every problem' %}</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tokenize_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;max_length&#39;</span><span class="p">:</span><span class="mi">64</span><span class="p">,</span> <span class="s1">&#39;padding&#39;</span><span class="p">:</span><span class="kc">True</span><span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's build our <a href="/adaptnlp/training.core.html#TaskDatasets"><code>TaskDatasets</code></a> now, passing in everything we built:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dsets</span> <span class="o">=</span> <span class="n">TaskDatasets</span><span class="p">(</span>
    <span class="n">train_dset</span> <span class="o">=</span> <span class="n">raw_datasets</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">],</span> <span class="c1"># Our training `Dataset`</span>
    <span class="n">valid_dset</span> <span class="o">=</span> <span class="n">raw_datasets</span><span class="p">[</span><span class="s1">&#39;validation&#39;</span><span class="p">],</span> <span class="c1"># Our validation `Dataset`</span>
    <span class="n">tokenizer_name</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="c1"># The name of our model</span>
    <span class="n">tokenize_kwargs</span> <span class="o">=</span> <span class="n">tokenize_kwargs</span><span class="p">,</span> <span class="c1"># The tokenizer kwargs</span>
    <span class="n">tokenize_func</span> <span class="o">=</span> <span class="n">tok_func</span><span class="p">,</span> <span class="c1"># The tokenization function</span>
    <span class="n">remove_cols</span> <span class="o">=</span> <span class="n">remove_cols</span> <span class="c1"># The columns to remove after tokenizing our input</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>





</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You may be wondering why we use the <a href="/adaptnlp/training.core.html#TaskDatasets"><code>TaskDatasets</code></a> class, this is a convience wrapper around much of the functions and tasks you need to call when using <code>datasets</code>'s <code>Dataset</code> class, and there are a few special behaviors to quickly build working <a href="/adaptnlp/training.core.html#AdaptiveDataLoaders"><code>AdaptiveDataLoaders</code></a> as well.</p>
<p>Let's build these <a href="/adaptnlp/training.core.html#AdaptiveDataLoaders"><code>AdaptiveDataLoaders</code></a>, which are just fastai's <code>DataLoaders</code> class, but it overrides a few functions to have it work nicely with HuggingFace's <code>Dataset</code> class</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="TaskDatasets.dataloaders" class="doc_header"><code>TaskDatasets.dataloaders</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/core.py#L243" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>TaskDatasets.dataloaders</code>(<strong><code>batch_size</code></strong>:<code>int</code>=<em><code>8</code></em>, <strong><code>shuffle_train</code></strong>:<code>bool</code>=<em><code>True</code></em>, <strong><code>collate_fn</code></strong>:<code>callable</code>=<em><code>None</code></em>, <strong><code>path</code></strong>=<em><code>'.'</code></em>, <strong><code>device</code></strong>=<em><code>None</code></em>)</p>
</blockquote>
<p>Creates <code>DataLoaders</code> from the dataset</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>batch_size</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em> <p>A batch size</p></li>
</ul>
<ul>
<li><strong><code>shuffle_train</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em> <p>Whether to shuffle the training dataset</p></li>
</ul>
<ul>
<li><strong><code>collate_fn</code></strong> : <em><code>&lt;built-in function callable&gt;</code></em>, <em>optional</em>  <p>A custom collation function</p></li>
</ul>
<ul>
<li><p><strong><code>path</code></strong> : <em><code>&lt;class 'str'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>device</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em></p>
</li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To build our <code>DataLoaders</code>, can call <code>.dataloaders</code>, specifying our batch size and a collate function to use. In our case we will collate with the <code>DataCollatorWithPadding</code> class out of <code>transformers</code>:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">DataCollatorWithPadding</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="n">collate_fn</span><span class="o">=</span><span class="n">DataCollatorWithPadding</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">dsets</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally, let's view a batch of data with the <code>show_batch</code> function:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Input</th>
      <th>Label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>" as a responsible leader we feel it necessary to make these changes because online chat services are increasingly being misused, " microsoft told the bbc. " as a responsible leader we felt it necessary to make these changes because online chat services are increasingly being misused, " stated gillian kent, director at msn uk.</td>
      <td>tensor(1)</td>
    </tr>
    <tr>
      <th>1</th>
      <td>they used discarded skin from consenting patients who had undergone surgery and exposed it to uva light at intensities similar to that of sunlight. sanders and colleagues at raft exposed skin samples removed from consenting patients during surgery to uva light at intensities similar to that of sunlight.</td>
      <td>tensor(1)</td>
    </tr>
    <tr>
      <th>2</th>
      <td>the yield on the 3 5 / 8 percent february 2013 note dropped 2 basis points to 3. 66 percent. the yield on the 3 percent note maturing in 2008 fell 22 basis points to 2. 61 percent.</td>
      <td>tensor(1)</td>
    </tr>
    <tr>
      <th>3</th>
      <td>during the flight, engineers misjudged the extent of the damage, and even during that period they lamented that the liftoff photography was poor. during the flight, engineers underestimated the extent of the damage, and even then lamented that the liftoff photography was so poor.</td>
      <td>tensor(1)</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Since this isn't a pre-built <code>*TaskDatasets</code> object, the <code>show_batch</code> looks a little plain, but it gets across exactly what you would need to see.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next let's build a <code>Tuner</code> and train our model</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Building-a-Tuner">Building a <code>Tuner</code><a class="anchor-link" href="#Building-a-Tuner"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next we need to build a compatible <code>Tuner</code> for our problem. These tuners contain good defaults for our problem space, including loss functions and metrics.</p>
<p>First let's import the <a href="/adaptnlp/training.sequence_classification.html#SequenceClassificationTuner"><code>SequenceClassificationTuner</code></a> and view it's documentation</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">SequenceClassificationTuner</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="SequenceClassificationTuner" class="doc_header"><code>class</code> <code>SequenceClassificationTuner</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/sequence_classification.py#L222" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>SequenceClassificationTuner</code>(<strong><code>dls</code></strong>:<code>DataLoaders</code>, <strong><code>model_name</code></strong>:<code>str</code>, <strong><code>tokenizer</code></strong>=<em><code>None</code></em>, <strong><code>loss_func</code></strong>=<em><code>CrossEntropyLoss()</code></em>, <strong><code>metrics</code></strong>=<em><code>[&lt;function accuracy at 0x7f18c87c2940&gt;, &lt;fastai.metrics.AccumMetric object at 0x7f18c85f3250&gt;]</code></em>, <strong><code>opt_func</code></strong>=<em><code>Adam</code></em>, <strong><code>additional_cbs</code></strong>=<em><code>None</code></em>, <strong><code>expose_fastai_api</code></strong>=<em><code>False</code></em>, <strong><code>num_classes</code></strong>:<code>int</code>=<em><code>None</code></em>, <strong>**<code>kwargs</code></strong>) :: <a href="/adaptnlp/training.core.html#AdaptiveTuner"><code>AdaptiveTuner</code></a></p>
</blockquote>
<p>An <a href="/adaptnlp/training.core.html#AdaptiveTuner"><code>AdaptiveTuner</code></a> with good defaults for Sequence Classification tasks</p>
<p><strong>Valid kwargs and defaults:</strong></p>
<ul>
<li><code>lr</code>:float = 0.001</li>
<li><code>splitter</code>:function = <code>trainable_params</code></li>
<li><code>cbs</code>:list = None</li>
<li><code>path</code>:Path = None</li>
<li><code>model_dir</code>:Path = 'models'</li>
<li><code>wd</code>:float = None</li>
<li><code>wd_bn_bias</code>:bool = False</li>
<li><code>train_bn</code>:bool = True</li>
<li><code>moms</code>: tuple(float) = (0.95, 0.85, 0.95)</li>
</ul>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>dls</code></strong> : <em><code>&lt;class 'fastai.data.core.DataLoaders'&gt;</code></em>   <p>A set of DataLoaders</p></li>
</ul>
<ul>
<li><strong><code>model_name</code></strong> : <em><code>&lt;class 'str'&gt;</code></em> <p>A HuggingFace model</p></li>
</ul>
<ul>
<li><strong><code>tokenizer</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em> <p>A HuggingFace tokenizer</p></li>
</ul>
<ul>
<li><strong><code>loss_func</code></strong> : <em><code>&lt;class 'fastai.losses.CrossEntropyLossFlat'&gt;</code></em>, <em>optional</em>   <p>A loss function</p></li>
</ul>
<ul>
<li><strong><code>metrics</code></strong> : <em><code>&lt;class 'list'&gt;</code></em>, <em>optional</em>   <p>Metrics to monitor the training with</p></li>
</ul>
<ul>
<li><strong><code>opt_func</code></strong> : <em><code>&lt;class 'function'&gt;</code></em>, <em>optional</em>  <p>A fastai or torch Optimizer</p></li>
</ul>
<ul>
<li><strong><code>additional_cbs</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em>    <p>Additional Callbacks to have always tied to the Tuner,</p></li>
</ul>
<ul>
<li><strong><code>expose_fastai_api</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em> <p>Whether to expose the fastai API</p></li>
</ul>
<ul>
<li><strong><code>num_classes</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em>    <p>The number of classes</p></li>
</ul>
<ul>
<li><strong><code>kwargs</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next we'll pass in our <code>DataLoaders</code>, the name of our model, and since we are using raw <code>Datasets</code>, the number of classes we have. In our case this is two.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include note.html content='If you are not using the data API (<a href="/adaptnlp/training.core.html#TaskDatasets"><code>TaskDatasets</code></a>, <a href="/adaptnlp/training.sequence_classification.html#SequenceClassificationDatasets"><code>SequenceClassificationDatasets</code></a>, etc), you need to pass in the tokenizer to the constructor as well with <code>tokenizer=tokenizer</code>' %}</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span> <span class="o">=</span> <span class="n">SequenceClassificationTuner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: [&#39;cls.seq_relationship.bias&#39;, &#39;cls.predictions.transform.dense.weight&#39;, &#39;cls.predictions.transform.LayerNorm.bias&#39;, &#39;cls.predictions.bias&#39;, &#39;cls.predictions.decoder.weight&#39;, &#39;cls.seq_relationship.weight&#39;, &#39;cls.predictions.transform.LayerNorm.weight&#39;, &#39;cls.predictions.transform.dense.bias&#39;]
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: [&#39;classifier.weight&#39;, &#39;classifier.bias&#39;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>By default we can see that it used <code>CrossEntropyLoss</code> as our loss function, and both <code>accuracy</code> and <code>F1Score</code> as our metrics:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span><span class="o">.</span><span class="n">loss_func</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>FlattenedLoss of CrossEntropyLoss()</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="p">[</span><span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">tuner</span><span class="o">.</span><span class="n">metrics</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>accuracy
f1_score
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It is also possible to define your own metrics, these stem from <a href="https://docs.fast.ai/metrics">fastai</a>.</p>
<p>To do so, write a function that takes an input and an output, and performs an operation. For example, we will write our own <code>accuracy</code> metric:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">ourAccuracy</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">out</span><span class="p">):</span>
    <span class="s2">&quot;A simplified accuracy metric that doesn&#39;t flatten&quot;</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">inp</span> <span class="o">==</span> <span class="n">targ</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And then we pass it into the constructor:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span> <span class="o">=</span> <span class="n">SequenceClassificationTuner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">ourAccuracy</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: [&#39;cls.seq_relationship.bias&#39;, &#39;cls.predictions.transform.dense.weight&#39;, &#39;cls.predictions.transform.LayerNorm.bias&#39;, &#39;cls.predictions.bias&#39;, &#39;cls.predictions.decoder.weight&#39;, &#39;cls.seq_relationship.weight&#39;, &#39;cls.predictions.transform.LayerNorm.weight&#39;, &#39;cls.predictions.transform.dense.bias&#39;]
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: [&#39;classifier.weight&#39;, &#39;classifier.bias&#39;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If we look at the metrics, you can see that now it is just <code>ourAccuracy</code>:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span><span class="o">.</span><span class="n">metrics</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&#39;ourAccuracy&#39;</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For this tutorial, we will revert it back to the defaults:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span> <span class="o">=</span> <span class="n">SequenceClassificationTuner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: [&#39;cls.seq_relationship.bias&#39;, &#39;cls.predictions.transform.dense.weight&#39;, &#39;cls.predictions.transform.LayerNorm.bias&#39;, &#39;cls.predictions.bias&#39;, &#39;cls.predictions.decoder.weight&#39;, &#39;cls.seq_relationship.weight&#39;, &#39;cls.predictions.transform.LayerNorm.weight&#39;, &#39;cls.predictions.transform.dense.bias&#39;]
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: [&#39;classifier.weight&#39;, &#39;classifier.bias&#39;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally we just need to train our model!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Fine-Tuning">Fine-Tuning<a class="anchor-link" href="#Fine-Tuning"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To fine-tune, AdaptNLP's tuner class provides only a few functions to work with. The important ones are the <code>tune</code> and <code>lr_find</code> class.</p>
<p>As the <code>Tuner</code> uses <code>fastai</code> under the hood, <code>lr_find</code> calls fastai's Learning Rate Finder to help us pick a learning rate. Let's do that now:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="AdaptiveTuner.lr_find" class="doc_header"><code>AdaptiveTuner.lr_find</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/core.py#L385" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>AdaptiveTuner.lr_find</code>(<strong><code>start_lr</code></strong>=<em><code>1e-07</code></em>, <strong><code>end_lr</code></strong>=<em><code>10</code></em>, <strong><code>num_it</code></strong>=<em><code>100</code></em>, <strong><code>stop_div</code></strong>=<em><code>True</code></em>, <strong><code>show_plot</code></strong>=<em><code>True</code></em>, <strong><code>suggest_funcs</code></strong>=<em><code>valley</code></em>)</p>
</blockquote>
<p>Runs fastai's <code>LR Finder</code></p>
<p><strong>Parameters:</strong></p>
<ul>
<li><p><strong><code>start_lr</code></strong> : <em><code>&lt;class 'float'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>end_lr</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>num_it</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>stop_div</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>show_plot</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>suggest_funcs</code></strong> : <em><code>&lt;class 'function'&gt;</code></em>, <em>optional</em></p>
</li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/opt/venv/lib/python3.8/site-packages/fastai/callback/schedule.py:270: UserWarning: color is redundantly defined by the &#39;color&#39; keyword argument and the fmt string &#34;ro&#34; (-&gt; color=&#39;r&#39;). The keyword argument will take precedence.
  ax.plot(val, idx, &#39;ro&#39;, label=nm, c=color)
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>SuggestedLRs(valley=0.0003981071640737355)</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It recommends a learning rate of around 2e-4, however a steeper slope can be found around 5e-5 so we will use that.
{% include note.html content='Reading the LR Finder is somewhat of an art. The <code>valley</code> method is one of the most reliable ones, but also try and figure out an intuition towards finding a learning rate as you go as well.' %}</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr</span> <span class="o">=</span> <span class="mf">5e-5</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's look at the documentation for <code>tune</code>:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="AdaptiveTuner.tune" class="doc_header"><code>AdaptiveTuner.tune</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/core.py#L371" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>AdaptiveTuner.tune</code>(<strong><code>epochs</code></strong>:<code>int</code>, <strong><code>lr</code></strong>:<code>float</code>=<em><code>None</code></em>, <strong><code>strategy</code></strong>:<code>Strategy</code>=<em><code>'fit_one_cycle'</code></em>, <strong><code>callbacks</code></strong>:<code>list</code>=<em><code>[]</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Fine tune <code>self.model</code> for <code>epochs</code> with an <code>lr</code> and <code>strategy</code></p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>epochs</code></strong> : <em><code>&lt;class 'int'&gt;</code></em> <p>Number of iterations to train for</p></li>
</ul>
<ul>
<li><strong><code>lr</code></strong> : <em><code>&lt;class 'float'&gt;</code></em>, <em>optional</em>   <p>If None, finds a new learning rate and uses suggestion_method</p></li>
</ul>
<ul>
<li><strong><code>strategy</code></strong> : <em><code>&lt;class 'fastcore.basics.Strategy'&gt;</code></em>, <em>optional</em>  <p>A fitting method</p></li>
</ul>
<ul>
<li><strong><code>callbacks</code></strong> : <em><code>&lt;class 'list'&gt;</code></em>, <em>optional</em> <p>Extra fastai Callbacks</p></li>
</ul>
<ul>
<li><strong><code>kwargs</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can pass in a number of epochs, a learning rate, a strategy, and additional fastai callbacks to call.</p>
<p>Valid strategies live in the <code>Strategy</code> namespace class, and consist of:</p>
<ul>
<li>OneCycle (Also called the <a href="https://docs.fast.ai/callback.schedule.html#Learner.fit_one_cycle">One-Cycle Policy</a>)</li>
<li><a href="https://docs.fast.ai/callback.schedule.html#Learner.fit_flat_cos">CosineAnnealing</a></li>
<li><a href="https://docs.fast.ai/callback.schedule.html#Learner.fit_sgdr">SGDR</a></li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">Strategy</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this tutorial we will train with the One-Cycle policy, as currently it is one of the best schedulers to use.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span><span class="o">.</span><span class="n">tune</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="n">Strategy</span><span class="o">.</span><span class="n">OneCycle</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>f1_score</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.627173</td>
      <td>0.579103</td>
      <td>0.710784</td>
      <td>0.818462</td>
      <td>01:19</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.405690</td>
      <td>0.391377</td>
      <td>0.848039</td>
      <td>0.889286</td>
      <td>01:20</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.252534</td>
      <td>0.415499</td>
      <td>0.830882</td>
      <td>0.882051</td>
      <td>01:20</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Saving-Model">Saving Model<a class="anchor-link" href="#Saving-Model"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now that we have a trained model, let's save those weights away.</p>
<p>Calling <code>tuner.save</code> will save both the model and the tokenizer in the same format as how HuggingFace does:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="AdaptiveTuner.save" class="doc_header"><code>AdaptiveTuner.save</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/core.py#L393" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>AdaptiveTuner.save</code>(<strong><code>save_directory</code></strong>)</p>
</blockquote>
<p>Save a pretrained model to a <code>save_directory</code></p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>save_directory</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em>  <p>A folder to save our model to</p></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;good_model&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&#39;good_model&#39;</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Performing-Inference">Performing Inference<a class="anchor-link" href="#Performing-Inference"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There are two ways to get predictions, the first is with the <code>.predict</code> method in our <code>tuner</code>. This is great for if you just finished training and want to see how your model performs on some new data!
The other method is with AdaptNLP's inference API, which we will show afterwards</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="In-Tuner">In Tuner<a class="anchor-link" href="#In-Tuner"> </a></h3><p>First let's write a sentence to test with</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sentence</span> <span class="o">=</span> <span class="s1">&#39;Amrozi accused his brother , whom he called &quot; the witness &quot; , of deliberately distorting his evidence . Referring to him as only &quot; the witness &quot; , Amrozi accused his brother of deliberately distorting his evidence .&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And then predict with it:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="SequenceClassificationTuner.predict" class="doc_header"><code>SequenceClassificationTuner.predict</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/sequence_classification.py#L272" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>SequenceClassificationTuner.predict</code>(<strong><code>text</code></strong>:<code>Union</code>[<code>List</code>[<code>str</code>], <code>str</code>], <strong><code>bs</code></strong>:<code>int</code>=<em><code>64</code></em>, <strong><code>detail_level</code></strong>:<code>DetailLevel</code>=<em><code>'low'</code></em>, <strong><code>class_names</code></strong>:<code>list</code>=<em><code>None</code></em>)</p>
</blockquote>
<p>Predict some <code>text</code> for sequence classification with the currently loaded model</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>text</code></strong> : <em><code>typing.Union[typing.List[str], str]</code></em> <p>Some text or list of texts to do inference with</p></li>
</ul>
<ul>
<li><strong><code>bs</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em> <p>A batch size to use for multiple texts</p></li>
</ul>
<ul>
<li><strong><code>detail_level</code></strong> : <em><code>&lt;class 'fastcore.basics.DetailLevel'&gt;</code></em>, <em>optional</em>   <p>A detail level to return on the predictions</p></li>
</ul>
<ul>
<li><strong><code>class_names</code></strong> : <em><code>&lt;class 'list'&gt;</code></em>, <em>optional</em>   <p>A list of labels</p></li>
</ul>
<p><strong>Returns</strong>:</p>
<ul>
<li><em><code>&lt;class 'dict'&gt;</code></em>   <p>A dictionary of filtered predictions</p></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;sentences&#39;: [&#39;Amrozi accused his brother , whom he called &#34; the witness &#34; , of deliberately distorting his evidence . Referring to him as only &#34; the witness &#34; , Amrozi accused his brother of deliberately distorting his evidence .&#39;],
 &#39;predictions&#39;: [&#39;LABEL_0&#39;],
 &#39;probs&#39;: tensor([[0.6317, 0.3683]])}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You'll notice it says <code>LABEL_1</code>. We did not build with the <code>Datasets</code> wrapper API's, so currently they do not have a vocabulary to work off of.</p>
<p>Let's pass in a vocabulary of <code>not_equivalent</code> and <code>equivalent</code> to work with:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;not_equivalent&#39;</span><span class="p">,</span> <span class="s1">&#39;equivalent&#39;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="n">names</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;sentences&#39;: [&#39;Amrozi accused his brother , whom he called &#34; the witness &#34; , of deliberately distorting his evidence . Referring to him as only &#34; the witness &#34; , Amrozi accused his brother of deliberately distorting his evidence .&#39;],
 &#39;predictions&#39;: [&#39;not_equivalent&#39;],
 &#39;probs&#39;: tensor([[0.6317, 0.3683]])}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You can see it gave us much more readable results!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="With-the-Inference-API">With the Inference API<a class="anchor-link" href="#With-the-Inference-API"> </a></h3><p>Next we will use the <a href="/adaptnlp/sequence_classification.html#EasySequenceClassifier"><code>EasySequenceClassifier</code></a> class, which AdaptNLP offers:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">EasySequenceClassifier</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We simply construct the class:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">classifier</span> <span class="o">=</span> <span class="n">EasySequenceClassifier</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And call the <code>tag_text</code> method, passing in the sentence, the location of our saved model, and some names for our classes.</p>
<p>Similarly here, we can pass in our own vocabulary to use. Let's do that:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">classifier</span><span class="o">.</span><span class="n">tag_text</span><span class="p">(</span>
    <span class="n">sentence</span><span class="p">,</span>
    <span class="n">model_name_or_path</span><span class="o">=</span><span class="s1">&#39;good_model&#39;</span><span class="p">,</span>
    <span class="n">class_names</span><span class="o">=</span><span class="n">names</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>2021-08-02 19:42:29,864 loading file good_model
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;sentences&#39;: [&#39;Amrozi accused his brother , whom he called &#34; the witness &#34; , of deliberately distorting his evidence . Referring to him as only &#34; the witness &#34; , Amrozi accused his brother of deliberately distorting his evidence .&#39;],
 &#39;predictions&#39;: [&#39;not_equivalent&#39;],
 &#39;probs&#39;: tensor([[0.6317, 0.3683]])}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And we got the exact same output and probabilities!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There are also different levels of predictions we can return (which is also the same with our earlier <code>predict</code> call).</p>
<p>These live in a namespace <code>DetailLevel</code> class, with a few examples below:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">DetailLevel</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">DetailLevel</span><span class="o">.</span><span class="n">Low</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&#39;low&#39;</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>While some Easy modules will not return different items at each level, most will return only a few specific outputs at the Low level, and everything possible at the High level:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">classifier</span><span class="o">.</span><span class="n">tag_text</span><span class="p">(</span>
    <span class="n">sentence</span><span class="p">,</span>
    <span class="n">model_name_or_path</span> <span class="o">=</span> <span class="s1">&#39;good_model&#39;</span><span class="p">,</span>
    <span class="n">detail_level</span><span class="o">=</span><span class="n">DetailLevel</span><span class="o">.</span><span class="n">Low</span><span class="p">,</span>
    <span class="n">class_names</span><span class="o">=</span><span class="n">names</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;sentences&#39;: [&#39;Amrozi accused his brother , whom he called &#34; the witness &#34; , of deliberately distorting his evidence . Referring to him as only &#34; the witness &#34; , Amrozi accused his brother of deliberately distorting his evidence .&#39;],
 &#39;predictions&#39;: [&#39;not_equivalent&#39;],
 &#39;probs&#39;: tensor([[0.6317, 0.3683]])}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">classifier</span><span class="o">.</span><span class="n">tag_text</span><span class="p">(</span>
    <span class="n">sentence</span><span class="p">,</span>
    <span class="n">model_name_or_path</span> <span class="o">=</span> <span class="s1">&#39;good_model&#39;</span><span class="p">,</span>
    <span class="n">detail_level</span><span class="o">=</span><span class="n">DetailLevel</span><span class="o">.</span><span class="n">Medium</span><span class="p">,</span>
    <span class="n">class_names</span><span class="o">=</span><span class="n">names</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;sentences&#39;: [&#39;Amrozi accused his brother , whom he called &#34; the witness &#34; , of deliberately distorting his evidence . Referring to him as only &#34; the witness &#34; , Amrozi accused his brother of deliberately distorting his evidence .&#39;],
 &#39;predictions&#39;: [&#39;not_equivalent&#39;],
 &#39;probs&#39;: tensor([[0.6317, 0.3683]]),
 &#39;pairings&#39;: OrderedDict([(&#39;Amrozi accused his brother , whom he called &#34; the witness &#34; , of deliberately distorting his evidence . Referring to him as only &#34; the witness &#34; , Amrozi accused his brother of deliberately distorting his evidence .&#39;,
               tensor([0.6317, 0.3683]))]),
 &#39;classes&#39;: [&#39;LABEL_0&#39;, &#39;LABEL_1&#39;]}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">classifier</span><span class="o">.</span><span class="n">tag_text</span><span class="p">(</span>
    <span class="n">sentence</span><span class="p">,</span>
    <span class="n">model_name_or_path</span> <span class="o">=</span> <span class="s1">&#39;good_model&#39;</span><span class="p">,</span>
    <span class="n">detail_level</span><span class="o">=</span><span class="n">DetailLevel</span><span class="o">.</span><span class="n">High</span><span class="p">,</span>
    <span class="n">class_names</span><span class="o">=</span><span class="n">names</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;sentences&#39;: [Sentence: &#34;Amrozi accused his brother , whom he called &#34; the witness &#34; , of deliberately distorting his evidence . Referring to him as only &#34; the witness &#34; , Amrozi accused his brother of deliberately distorting his evidence .&#34;   [− Tokens: 39  − Sentence-Labels: {&#39;sc&#39;: [LABEL_0 (0.6317), LABEL_1 (0.3683)]}]],
 &#39;predictions&#39;: [&#39;not_equivalent&#39;],
 &#39;probs&#39;: tensor([[0.6317, 0.3683]]),
 &#39;pairings&#39;: OrderedDict([(&#39;Amrozi accused his brother , whom he called &#34; the witness &#34; , of deliberately distorting his evidence . Referring to him as only &#34; the witness &#34; , Amrozi accused his brother of deliberately distorting his evidence .&#39;,
               tensor([0.6317, 0.3683]))]),
 &#39;classes&#39;: [&#39;LABEL_0&#39;, &#39;LABEL_1&#39;]}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

