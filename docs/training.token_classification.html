---

title: Token Classification Tuning


keywords: fastai
sidebar: home_sidebar

summary: "Data and Tuning API for Token Classification Tasks"
description: "Data and Tuning API for Token Classification Tasks"
nb_path: "nbs/17_training.token_classification.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/17_training.token_classification.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Datasets">Datasets<a class="anchor-link" href="#Datasets"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="encode_tags" class="doc_header"><code>encode_tags</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/token_classification.py#L29" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>encode_tags</code>(<strong><code>tags</code></strong>, <strong><code>encodings</code></strong>)</p>
</blockquote>
<p><strong>Parameters:</strong></p>
<ul>
<li><p><strong><code>tags</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em></p>
</li>
<li><p><strong><code>encodings</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em></p>
</li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="TokenClassificationDatasets" class="doc_header"><code>class</code> <code>TokenClassificationDatasets</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/token_classification.py#L60" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>TokenClassificationDatasets</code>(<strong><code>train_dset</code></strong>:<code>Dataset</code>, <strong><code>valid_dset</code></strong>:<code>Dataset</code>, <strong><code>tokenizer_name</code></strong>:<code>str</code>, <strong><code>tokenize</code></strong>:<code>bool</code>, <strong><code>tokenize_kwargs</code></strong>:<code>dict</code>, <strong><code>auto_kwargs</code></strong>:<code>dict</code>, <strong><code>remove_columns</code></strong>:<code>list</code>, <strong><code>entity_mapping</code></strong>:<code>dict</code>) :: <a href="/adaptnlp/training.core.html#TaskDatasets"><code>TaskDatasets</code></a></p>
</blockquote>
<p>A set of datasets designed for token classification</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>train_dset</code></strong> : <em><code>&lt;class 'datasets.arrow_dataset.Dataset'&gt;</code></em>  <p>A training dataset</p></li>
</ul>
<ul>
<li><strong><code>valid_dset</code></strong> : <em><code>&lt;class 'datasets.arrow_dataset.Dataset'&gt;</code></em>  <p>A validation dataset</p></li>
</ul>
<ul>
<li><strong><code>tokenizer_name</code></strong> : <em><code>&lt;class 'str'&gt;</code></em> <p>The name of a tokenizer</p></li>
</ul>
<ul>
<li><strong><code>tokenize</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>  <p>Whether to tokenize immediately</p></li>
</ul>
<ul>
<li><strong><code>tokenize_kwargs</code></strong> : <em><code>&lt;class 'dict'&gt;</code></em>   <p>kwargs for the tokenize function</p></li>
</ul>
<ul>
<li><strong><code>auto_kwargs</code></strong> : <em><code>&lt;class 'dict'&gt;</code></em>   <p>AutoTokenizer.from_pretrained kwargs</p></li>
</ul>
<ul>
<li><strong><code>remove_columns</code></strong> : <em><code>&lt;class 'list'&gt;</code></em>    <p>The columns to remove when tokenizing</p></li>
</ul>
<ul>
<li><strong><code>entity_mapping</code></strong> : <em><code>&lt;class 'dict'&gt;</code></em>    <p>A mapping of entity names to encoded labels</p></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="TokenClassificationDatasets.from_dfs" class="doc_header"><code>TokenClassificationDatasets.from_dfs</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/token_classification.py#L89" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>TokenClassificationDatasets.from_dfs</code>(<strong><code>train_df</code></strong>:<code>DataFrame</code>, <strong><code>token_col</code></strong>:<code>str</code>, <strong><code>tag_col</code></strong>:<code>str</code>, <strong><code>entity_mapping</code></strong>:<code>dict</code>, <strong><code>tokenizer_name</code></strong>:<code>str</code>, <strong><code>tokenize</code></strong>:<code>bool</code>=<em><code>True</code></em>, <strong><code>valid_df</code></strong>=<em><code>None</code></em>, <strong><code>split_func</code></strong>=<em><code>None</code></em>, <strong><code>split_pct</code></strong>=<em><code>0.2</code></em>, <strong><code>tokenize_kwargs</code></strong>:<code>dict</code>=<em><code>{}</code></em>, <strong><code>auto_kwargs</code></strong>:<code>dict</code>=<em><code>{}</code></em>)</p>
</blockquote>
<p>Builds <a href="/adaptnlp/training.token_classification.html#TokenClassificationDatasets"><code>TokenClassificationDatasets</code></a> from a <code>DataFrame</code> or set of <code>DataFrames</code></p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>train_df</code></strong> : <em><code>&lt;class 'pandas.core.frame.DataFrame'&gt;</code></em>   <p>A training dataframe</p></li>
</ul>
<ul>
<li><strong><code>token_col</code></strong> : <em><code>&lt;class 'str'&gt;</code></em>  <p>The name of the token column</p></li>
</ul>
<ul>
<li><strong><code>tag_col</code></strong> : <em><code>&lt;class 'str'&gt;</code></em>    <p>The name of the tag column</p></li>
</ul>
<ul>
<li><strong><code>entity_mapping</code></strong> : <em><code>&lt;class 'dict'&gt;</code></em>    <p>A mapping of entity names to encoded labels</p></li>
</ul>
<ul>
<li><strong><code>tokenizer_name</code></strong> : <em><code>&lt;class 'str'&gt;</code></em> <p>The name of the tokenizer</p></li>
</ul>
<ul>
<li><strong><code>tokenize</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em>  <p>Whether to tokenize immediately</p></li>
</ul>
<ul>
<li><strong><code>valid_df</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em>  <p>An optional validation dataframe</p></li>
</ul>
<ul>
<li><strong><code>split_func</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em>    <p>Optionally a splitting function similar to RandomSplitter</p></li>
</ul>
<ul>
<li><strong><code>split_pct</code></strong> : <em><code>&lt;class 'float'&gt;</code></em>, <em>optional</em>    <p>What % to split the train_df</p></li>
</ul>
<ul>
<li><strong><code>tokenize_kwargs</code></strong> : <em><code>&lt;class 'dict'&gt;</code></em>, <em>optional</em>   <p>kwargs for the tokenize function</p></li>
</ul>
<ul>
<li><strong><code>auto_kwargs</code></strong> : <em><code>&lt;class 'dict'&gt;</code></em>, <em>optional</em>   <p>kwargs for the AutoTokenizer.from_pretrained constructor</p></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="TokenClassificationDatasets.from_csvs" class="doc_header"><code>TokenClassificationDatasets.from_csvs</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/token_classification.py#L130" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>TokenClassificationDatasets.from_csvs</code>(<strong><code>train_csv</code></strong>:<code>Path</code>, <strong><code>token_col</code></strong>:<code>str</code>, <strong><code>tag_col</code></strong>:<code>str</code>, <strong><code>entity_mapping</code></strong>:<code>dict</code>, <strong><code>tokenizer_name</code></strong>:<code>str</code>, <strong><code>tokenize</code></strong>:<code>bool</code>=<em><code>True</code></em>, <strong><code>valid_csv</code></strong>:<code>Path</code>=<em><code>None</code></em>, <strong><code>split_func</code></strong>=<em><code>None</code></em>, <strong><code>split_pct</code></strong>=<em><code>0.2</code></em>, <strong><code>tokenize_kwargs</code></strong>:<code>dict</code>=<em><code>{}</code></em>, <strong><code>auto_kwargs</code></strong>:<code>dict</code>=<em><code>{}</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Builds <a href="/adaptnlp/training.sequence_classification.html#SequenceClassificationDatasets"><code>SequenceClassificationDatasets</code></a> from a single csv or set of csvs. A convience constructor for <code>from_dfs</code></p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>train_csv</code></strong> : <em><code>&lt;class 'pathlib.Path'&gt;</code></em> <p>A training csv file</p></li>
</ul>
<ul>
<li><strong><code>token_col</code></strong> : <em><code>&lt;class 'str'&gt;</code></em>  <p>The name of the token column</p></li>
</ul>
<ul>
<li><strong><code>tag_col</code></strong> : <em><code>&lt;class 'str'&gt;</code></em>    <p>The name of the tag column</p></li>
</ul>
<ul>
<li><strong><code>entity_mapping</code></strong> : <em><code>&lt;class 'dict'&gt;</code></em>    <p>A mapping of entity names to encoded labels</p></li>
</ul>
<ul>
<li><strong><code>tokenizer_name</code></strong> : <em><code>&lt;class 'str'&gt;</code></em> <p>The name of the tokenizer</p></li>
</ul>
<ul>
<li><strong><code>tokenize</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em>  <p>Whether to tokenize immediately</p></li>
</ul>
<ul>
<li><strong><code>valid_csv</code></strong> : <em><code>&lt;class 'pathlib.Path'&gt;</code></em>, <em>optional</em> <p>An optional validation csv</p></li>
</ul>
<ul>
<li><strong><code>split_func</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em>    <p>Optionally a splitting function similar to RandomSplitter</p></li>
</ul>
<ul>
<li><strong><code>split_pct</code></strong> : <em><code>&lt;class 'float'&gt;</code></em>, <em>optional</em>    <p>What % to split the train df</p></li>
</ul>
<ul>
<li><strong><code>tokenize_kwargs</code></strong> : <em><code>&lt;class 'dict'&gt;</code></em>, <em>optional</em>   <p>kwargs for the tokenize function</p></li>
</ul>
<ul>
<li><strong><code>auto_kwargs</code></strong> : <em><code>&lt;class 'dict'&gt;</code></em>, <em>optional</em>   <p>kwargs for the AutoTokenizer.from_pretrained constructor</p></li>
</ul>
<ul>
<li><strong><code>kwargs</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>When passing in kwargs if anything should go to the <code>tokenize</code> function they should go to <code>tokenize_kwargs</code>, and if it should go to the <code>Auto</code> class constructor, they should go to <code>auto_kwargs</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Token-Classification-Tuner">Token Classification Tuner<a class="anchor-link" href="#Token-Classification-Tuner"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="SeqEvalMetrics" class="doc_header"><code>class</code> <code>SeqEvalMetrics</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/token_classification.py#L179" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>SeqEvalMetrics</code>(<strong><code>entity_mapping</code></strong>:<code>dict</code>)</p>
</blockquote>
<p>Multi-label classification metrics for NER, using seqeval metric from HuggingFace</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>entity_mapping</code></strong> : <em><code>&lt;class 'dict'&gt;</code></em>    <p>A mapping of entity names to encoded labels</p></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h3 id="NERMetric" class="doc_header"><code>class</code> <code>NERMetric</code><a href="" class="source_link" style="float:right">[source]</a></h3><blockquote><p><code>NERMetric</code>(<strong>*<code>args</code></strong>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Class for all valid NER metrics usable during fine-tuning with typo-proofing</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><p><strong><code>args</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em></p>
</li>
<li><p><strong><code>kwargs</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em></p>
</li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Supported metrics:
* Accuracy
* F1
* Precision
* Recall
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="TokenClassificationTuner" class="doc_header"><code>class</code> <code>TokenClassificationTuner</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/token_classification.py#L254" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>TokenClassificationTuner</code>(<strong><code>dls</code></strong>:<code>DataLoaders</code>, <strong><code>model_name</code></strong>:<code>str</code>, <strong><code>tokenizer</code></strong>=<em><code>None</code></em>, <strong><code>loss_func</code></strong>=<em><code>CrossEntropyLoss()</code></em>, <strong><code>metrics</code></strong>:<code>List</code>[<code>NERMetric</code>]=<em><code>['accuracy', 'f1']</code></em>, <strong><code>opt_func</code></strong>=<em><code>Adam</code></em>, <strong><code>additional_cbs</code></strong>=<em><code>None</code></em>, <strong><code>expose_fastai_api</code></strong>=<em><code>False</code></em>, <strong><code>num_classes</code></strong>:<code>int</code>=<em><code>None</code></em>, <strong><code>entity_mapping</code></strong>:<code>dict</code>=<em><code>None</code></em>, <strong>**<code>kwargs</code></strong>) :: <a href="/adaptnlp/training.core.html#AdaptiveTuner"><code>AdaptiveTuner</code></a></p>
</blockquote>
<p>An <a href="/adaptnlp/training.core.html#AdaptiveTuner"><code>AdaptiveTuner</code></a> with good defaults for Token Classification tasks</p>
<p><strong>Valid kwargs and defaults:</strong></p>
<ul>
<li><code>lr</code>:float = 0.001</li>
<li><code>splitter</code>:function = <code>trainable_params</code></li>
<li><code>cbs</code>:list = None</li>
<li><code>path</code>:Path = None</li>
<li><code>model_dir</code>:Path = 'models'</li>
<li><code>wd</code>:float = None</li>
<li><code>wd_bn_bias</code>:bool = False</li>
<li><code>train_bn</code>:bool = True</li>
<li><code>moms</code>: tuple(float) = (0.95, 0.85, 0.95)</li>
</ul>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>dls</code></strong> : <em><code>&lt;class 'fastai.data.core.DataLoaders'&gt;</code></em>   <p>A set of DataLoaders</p></li>
</ul>
<ul>
<li><strong><code>model_name</code></strong> : <em><code>&lt;class 'str'&gt;</code></em> <p>A HuggingFace model</p></li>
</ul>
<ul>
<li><strong><code>tokenizer</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em> <p>A HuggingFace tokenizer</p></li>
</ul>
<ul>
<li><strong><code>loss_func</code></strong> : <em><code>&lt;class 'fastai.losses.CrossEntropyLossFlat'&gt;</code></em>, <em>optional</em>   <p>A loss function</p></li>
</ul>
<ul>
<li><strong><code>metrics</code></strong> : <em><code>typing.List[fastcore.basics.NERMetric]</code></em>, <em>optional</em>   <p>Metrics to monitor the training with</p></li>
</ul>
<ul>
<li><strong><code>opt_func</code></strong> : <em><code>&lt;class 'function'&gt;</code></em>, <em>optional</em>  <p>A fastai or torch Optimizer</p></li>
</ul>
<ul>
<li><strong><code>additional_cbs</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em>    <p>Additional Callbacks to have always tied to the Tuner</p></li>
</ul>
<ul>
<li><strong><code>expose_fastai_api</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em> <p>Whether to expose the fastai API</p></li>
</ul>
<ul>
<li><strong><code>num_classes</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em>    <p>The number of classes</p></li>
</ul>
<ul>
<li><strong><code>entity_mapping</code></strong> : <em><code>&lt;class 'dict'&gt;</code></em>, <em>optional</em>    <p>A mapping of entity names to encoded labels</p></li>
</ul>
<ul>
<li><strong><code>kwargs</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="TokenClassificationTuner.predict" class="doc_header"><code>TokenClassificationTuner.predict</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/token_classification.py#L317" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>TokenClassificationTuner.predict</code>(<strong><code>text</code></strong>:<code>Union</code>[<code>List</code>[<code>str</code>], <code>str</code>], <strong><code>bs</code></strong>:<code>int</code>=<em><code>64</code></em>, <strong><code>grouped_entities</code></strong>:<code>bool</code>=<em><code>True</code></em>, <strong><code>detail_level</code></strong>:<code>DetailLevel</code>=<em><code>'low'</code></em>)</p>
</blockquote>
<p>Predict some <code>text</code> for token classification with the currently loaded model</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>text</code></strong> : <em><code>typing.Union[typing.List[str], str]</code></em> <p>Some text or list of texts to do inference with</p></li>
</ul>
<ul>
<li><strong><code>bs</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em> <p>A batch size to use for multiple texts</p></li>
</ul>
<ul>
<li><strong><code>grouped_entities</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em>  <p>Return whole entity span strings</p></li>
</ul>
<ul>
<li><strong><code>detail_level</code></strong> : <em><code>&lt;class 'fastcore.basics.DetailLevel'&gt;</code></em>, <em>optional</em>   <p>A detail level to return on the predictions</p></li>
</ul>
<p><strong>Returns</strong>:</p>
<ul>
<li><em><code>&lt;class 'dict'&gt;</code></em>   <p>A dictionary of filtered predictions</p></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

