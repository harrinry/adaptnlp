---

title: Summarization


keywords: fastai
sidebar: home_sidebar

summary: "Performing summarization within the AdaptNLP library"
description: "Performing summarization within the AdaptNLP library"
nb_path: "nbs/07_summarization.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/07_summarization.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="TransformersSummarizer" class="doc_header"><code>class</code> <code>TransformersSummarizer</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/inference/summarization.py#L36" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>TransformersSummarizer</code>(<strong><code>tokenizer</code></strong>:<code>PreTrainedTokenizer</code>, <strong><code>model</code></strong>:<code>PreTrainedModel</code>) :: <a href="/adaptnlp/model.html#AdaptiveModel"><code>AdaptiveModel</code></a></p>
</blockquote>
<p>Adaptive model for Transformer's Conditional Generation or Language Models (Transformer's T5 and Bart conditiional generation models have a language modeling head)</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>tokenizer</code></strong> : <em><code>&lt;class 'transformers.tokenization_utils.PreTrainedTokenizer'&gt;</code></em>  <p>A tokenizer object from Huggingface's transformers (TODO)and tokenizers</p></li>
</ul>
<ul>
<li><strong><code>model</code></strong> : <em><code>&lt;class 'transformers.modeling_utils.PreTrainedModel'&gt;</code></em>  <p>A transformers Conditional Generation (Bart or T5) or Language model</p></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="TransformersSummarizer.load" class="doc_header"><code>TransformersSummarizer.load</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/inference/summarization.py#L53" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>TransformersSummarizer.load</code>(<strong><code>model_name_or_path</code></strong>:<code>str</code>)</p>
</blockquote>
<p>Class method for loading and constructing this classifier</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>model_name_or_path</code></strong> : <em><code>&lt;class 'str'&gt;</code></em> <p>A key string of one of Transformer's pre-trained Summarizer Model</p></li>
</ul>
<p><strong>Returns</strong>:</p>
<ul>
<li><em><code>&lt;class 'adaptnlp.model.AdaptiveModel'&gt;</code></em></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="TransformersSummarizer.predict" class="doc_header"><code>TransformersSummarizer.predict</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/inference/summarization.py#L64" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>TransformersSummarizer.predict</code>(<strong><code>text</code></strong>:<code>Union</code>[<code>List</code>[<code>str</code>], <code>str</code>], <strong><code>mini_batch_size</code></strong>:<code>int</code>=<em><code>32</code></em>, <strong><code>num_beams</code></strong>:<code>int</code>=<em><code>4</code></em>, <strong><code>min_length</code></strong>:<code>int</code>=<em><code>0</code></em>, <strong><code>max_length</code></strong>:<code>int</code>=<em><code>128</code></em>, <strong><code>early_stopping</code></strong>:<code>bool</code>=<em><code>True</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Predict method for running inference using the pre-trained sequence classifier model</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>text</code></strong> : <em><code>typing.Union[typing.List[str], str]</code></em> <p>Sentences to run inference on</p></li>
</ul>
<ul>
<li><strong><code>mini_batch_size</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em>    <p>Mini batch size</p></li>
</ul>
<ul>
<li><strong><code>num_beams</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em>  <p>Number of beams for beam search. Must be between 1 and infinity. 1 means no beam search.</p></li>
</ul>
<ul>
<li><strong><code>min_length</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em> <p>The min length of the sequence to be generated</p></li>
</ul>
<ul>
<li><strong><code>max_length</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em> <p>The max length of the sequence to be generated. Between min_length and infinity</p></li>
</ul>
<ul>
<li><strong><code>early_stopping</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em>    <p>If set to True beam search is stopped when at least num_beams sentences finished per batch</p></li>
</ul>
<ul>
<li><strong><code>kwargs</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em></li>
</ul>
<p><strong>Returns</strong>:</p>
<ul>
<li><em><code>typing.List[str]</code></em> <p>A list of predicted summarizations</p></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="EasySummarizer" class="doc_header"><code>class</code> <code>EasySummarizer</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/inference/summarization.py#L140" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>EasySummarizer</code>()</p>
</blockquote>
<p>Summarization Module</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="EasySummarizer.summarize" class="doc_header"><code>EasySummarizer.summarize</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/inference/summarization.py#L145" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>EasySummarizer.summarize</code>(<strong><code>text</code></strong>:<code>Union</code>[<code>List</code>[<code>str</code>], <code>str</code>], <strong><code>model_name_or_path</code></strong>:<code>Union</code>[<code>str</code>, <a href="/adaptnlp/model_hub.html#HFModelResult"><code>HFModelResult</code></a>]=<em><code>'t5-small'</code></em>, <strong><code>mini_batch_size</code></strong>:<code>int</code>=<em><code>32</code></em>, <strong><code>num_beams</code></strong>:<code>int</code>=<em><code>4</code></em>, <strong><code>min_length</code></strong>:<code>int</code>=<em><code>0</code></em>, <strong><code>max_length</code></strong>:<code>int</code>=<em><code>128</code></em>, <strong><code>early_stopping</code></strong>:<code>bool</code>=<em><code>True</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Predict method for running inference using the pre-trained sequence classifier model</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>text</code></strong> : <em><code>typing.Union[typing.List[str], str]</code></em> <p>Sentences to run inference on</p></li>
</ul>
<ul>
<li><strong><code>model_name_or_path</code></strong> : <em><code>typing.Union[str, adaptnlp.model_hub.HFModelResult]</code></em>, <em>optional</em>   <p>A model id or path to a pre-trained model repository or custom trained model directory</p></li>
</ul>
<ul>
<li><strong><code>mini_batch_size</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em>    <p>Mini batch size</p></li>
</ul>
<ul>
<li><strong><code>num_beams</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em>  <p>Number of beams for beam search. Must be between 1 and infinity. 1 means no beam search</p></li>
</ul>
<ul>
<li><strong><code>min_length</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em> <p>The max length of the sequence to be generated. Between min_length and infinity</p></li>
</ul>
<ul>
<li><strong><code>max_length</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em> <p>The max length of the sequence to be generated. Between min_length and infinity</p></li>
</ul>
<ul>
<li><strong><code>early_stopping</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em>    <p>If set to True beam search is stopped when at least num_beams sentences finished per batch</p></li>
</ul>
<ul>
<li><strong><code>kwargs</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em></li>
</ul>
<p><strong>Returns</strong>:</p>
<ul>
<li><em><code>typing.List[str]</code></em> <p>A list of predicted summaries</p></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

