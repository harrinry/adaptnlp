---

title: Sequence Classification


keywords: fastai
sidebar: home_sidebar

summary: "Sequence Classification API for Transformers and Flair"
description: "Sequence Classification API for Transformers and Flair"
nb_path: "nbs/06_sequence_classification.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/06_sequence_classification.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="TransformersSequenceClassifier" class="doc_header"><code>class</code> <code>TransformersSequenceClassifier</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/sequence_classification.py#L46" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>TransformersSequenceClassifier</code>(<strong><code>tokenizer</code></strong>:<code>PreTrainedTokenizer</code>, <strong><code>model</code></strong>:<code>PreTrainedModel</code>) :: <a href="/adaptnlp/model.html#AdaptiveModel"><code>AdaptiveModel</code></a></p>
</blockquote>
<p>Adaptive model for Transformer's Sequence Classification Model</p>
<p>Usage:</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">classifier</span> <span class="o">=</span> <span class="n">TransformersSequenceClassifier</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;transformers-sc-model&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s1">&#39;Example text&#39;</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</pre></div>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong>tokenizer</strong> - A tokenizer object from Huggingface's transformers (TODO)and tokenizers</li>
<li><strong>model</strong> - A transformers Sequence Classsifciation model</li>
</ul>
<p><strong>Usage Examples:</strong></p>
<details>
<summary markdown="span">Click Me to Show Code Examples</summary><b><a href=https://nbviewer.jupyter.org/github/novetta/adaptnlp/tree/master/nbs/06_sequence_classification.ipynb>Source</a></b>
```python
#hide
example_text = "This didn't work at all"

classifier = TransformersSequenceClassifier.load("nlptown/bert-base-multilingual-uncased-sentiment")

sentences = classifier.predict(text=example_text,mini_batch_size=1,
)
```
</details>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="TransformersSequenceClassifier.load" class="doc_header"><code>TransformersSequenceClassifier.load</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/sequence_classification.py#L74" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>TransformersSequenceClassifier.load</code>(<strong><code>model_name_or_path</code></strong>:<code>Union</code>[<a href="/adaptnlp/model_hub.html#HFModelResult"><code>HFModelResult</code></a>, <code>str</code>])</p>
</blockquote>
<p>Class method for loading and constructing this classifier</p>
<ul>
<li><strong>model_name_or_path</strong> - A key string of one of Transformer's pre-trained Sequence Classifier Model or a <a href="/adaptnlp/model_hub.html#HFModelResult"><code>HFModelResult</code></a></li>
</ul>
<p><strong>Usage Examples:</strong></p>
<details>
<summary markdown="span">Click Me to Show Code Examples</summary><b><a href=https://nbviewer.jupyter.org/github/novetta/adaptnlp/tree/master/nbs/06_sequence_classification.ipynb>Source</a></b>
```python
#hide
example_text = "This didn't work at all"

classifier = TransformersSequenceClassifier.load("nlptown/bert-base-multilingual-uncased-sentiment")

sentences = classifier.predict(text=example_text,mini_batch_size=1,
)
```
</details>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="TransformersSequenceClassifier.predict" class="doc_header"><code>TransformersSequenceClassifier.predict</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/sequence_classification.py#L86" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>TransformersSequenceClassifier.predict</code>(<strong><code>text</code></strong>:<code>Union</code>[<code>List</code>[<code>Sentence</code>], <code>Sentence</code>, <code>List</code>[<code>str</code>], <code>str</code>], <strong><code>mini_batch_size</code></strong>:<code>int</code>=<em><code>32</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Predict method for running inference using the pre-trained sequence classifier model</p>
<ul>
<li><strong>text</strong> - String, list of strings, sentences, or list of sentences to run inference on</li>
<li><strong>mini_batch_size</strong> - Mini batch size</li>
<li><strong>&ast;&ast;kwargs</strong>(Optional) - Optional arguments for the Transformers classifier</li>
</ul>
<p><strong>Usage Examples:</strong></p>
<details>
<summary markdown="span">Click Me to Show Code Examples</summary><b><a href=https://nbviewer.jupyter.org/github/novetta/adaptnlp/tree/master/nbs/06_sequence_classification.ipynb>Source</a></b>
```python
#hide
example_text = "This didn't work at all"

classifier = TransformersSequenceClassifier.load("nlptown/bert-base-multilingual-uncased-sentiment")

sentences = classifier.predict(text=example_text,mini_batch_size=1,
)
```
</details>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="FlairSequenceClassifier" class="doc_header"><code>class</code> <code>FlairSequenceClassifier</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/sequence_classification.py#L303" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>FlairSequenceClassifier</code>(<strong><code>model_name_or_path</code></strong>:<code>str</code>) :: <a href="/adaptnlp/model.html#AdaptiveModel"><code>AdaptiveModel</code></a></p>
</blockquote>
<p>Adaptive Model for Flair's Sequence Classifier...very basic</p>
<p>Usage:</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">classifier</span> <span class="o">=</span> <span class="n">FlairSequenceClassifier</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;sentiment&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s1">&#39;Example text&#39;</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</pre></div>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong>model_name_or_path</strong> - A key string of one of Flair's pre-trained Sequence Classifier Model</li>
</ul>
<p><strong>Usage Examples:</strong></p>
<details>
<summary markdown="span">Click Me to Show Code Examples</summary><b><a href=https://nbviewer.jupyter.org/github/novetta/adaptnlp/tree/master/nbs/06_sequence_classification.ipynb>Source</a></b>
```python
#hide
example_text = "This didn't work at all"


classifier = FlairSequenceClassifier.load('sentiment')

sentences = classifier.predict(text=example_text,mini_batch_size=1,
)

pred = sentences[0].get_labels()[0]

test_eq(pred.value, 'NEGATIVE')
test_close(pred.score, 0.999, 1e-3)
```
</details>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="FlairSequenceClassifier.load" class="doc_header"><code>FlairSequenceClassifier.load</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/sequence_classification.py#L320" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>FlairSequenceClassifier.load</code>(<strong><code>model_name_or_path</code></strong>:<code>Union</code>[<a href="/adaptnlp/model_hub.html#HFModelResult"><code>HFModelResult</code></a>, <a href="/adaptnlp/model_hub.html#FlairModelResult"><code>FlairModelResult</code></a>, <code>str</code>])</p>
</blockquote>
<p>Class method for loading a constructing this classifier</p>
<ul>
<li><strong>model_name_or_path</strong> - A key string of one of Flair's pre-trained Sequence Classifier Model or a <a href="/adaptnlp/model_hub.html#HFModelResult"><code>HFModelResult</code></a></li>
</ul>
<p><strong>Usage Examples:</strong></p>
<details>
<summary markdown="span">Click Me to Show Code Examples</summary><b><a href=https://nbviewer.jupyter.org/github/novetta/adaptnlp/tree/master/nbs/06_sequence_classification.ipynb>Source</a></b>
```python
#hide
example_text = "This didn't work at all"


classifier = FlairSequenceClassifier.load('sentiment')

sentences = classifier.predict(text=example_text,mini_batch_size=1,
)

pred = sentences[0].get_labels()[0]

test_eq(pred.value, 'NEGATIVE')
test_close(pred.score, 0.999, 1e-3)
```
</details>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="FlairSequenceClassifier.predict" class="doc_header"><code>FlairSequenceClassifier.predict</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/sequence_classification.py#L331" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>FlairSequenceClassifier.predict</code>(<strong><code>text</code></strong>:<code>Union</code>[<code>List</code>[<code>Sentence</code>], <code>Sentence</code>, <code>List</code>[<code>str</code>], <code>str</code>], <strong><code>mini_batch_size</code></strong>:<code>int</code>=<em><code>32</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Predict method for running inference using the pre-trained sequence classifier model</p>
<ul>
<li><strong>text</strong> - String, list of strings, sentences, or list of sentences to run inference on</li>
<li><strong>mini_batch_size</strong> - Mini batch size</li>
<li><strong>&ast;&ast;kwargs</strong>(Optional) - Optional arguments for the Flair classifier</li>
</ul>
<p><strong>Usage Examples:</strong></p>
<details>
<summary markdown="span">Click Me to Show Code Examples</summary><b><a href=https://nbviewer.jupyter.org/github/novetta/adaptnlp/tree/master/nbs/06_sequence_classification.ipynb>Source</a></b>
```python
#hide
example_text = "This didn't work at all"


classifier = FlairSequenceClassifier.load('sentiment')

sentences = classifier.predict(text=example_text,mini_batch_size=1,
)

pred = sentences[0].get_labels()[0]

test_eq(pred.value, 'NEGATIVE')
test_close(pred.score, 0.999, 1e-3)
```
</details>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="EasySequenceClassifier" class="doc_header"><code>class</code> <code>EasySequenceClassifier</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/sequence_classification.py#L367" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>EasySequenceClassifier</code>()</p>
</blockquote>
<p>Sequence classification models</p>
<p>Usage:</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">classifier</span> <span class="o">=</span> <span class="n">EasySequenceClassifier</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">classifier</span><span class="o">.</span><span class="n">tag_text</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s1">&#39;text you want to label&#39;</span><span class="p">,</span> <span class="n">model_name_or_path</span><span class="o">=</span><span class="s1">&#39;en-sentiment&#39;</span><span class="p">)</span>
</pre></div>
<p><strong>Usage Examples:</strong></p>
<details>
<summary markdown="span">Click Me to Show Code Examples</summary><b><a href=https://nbviewer.jupyter.org/github/novetta/adaptnlp/tree/master/nbs/06_sequence_classification.ipynb>Source</a></b>
```python
#hide
hub = HFModelHub()
model = hub.search_model_by_name("nlptown/bert-base", user_uploaded=True)[0]
classifier = EasySequenceClassifier()
sentences = classifier.tag_text(text=example_text, 
                               model_name_or_path=model,
                               mini_batch_size=1)
for pred, truth in zip(preds, truth_lbls):
    test_eq(pred.value, truth.value)
    test_close(pred.score, truth.score, 1e-4)
```
</details>
<b><a href=https://nbviewer.jupyter.org/github/novetta/adaptnlp/tree/master/nbs/06a_tutorial.easy_sequence_classifier.ipynb>Source</a></b>
```python
We'll first need a "custom" dataset to start training our model. Our `EasySequenceClassifier.train()` method can run with either `datasets.Dataset` objects or CSV data file paths. Since the datasets library makes it so easy, we'll use the `datasets.load_dataset()` method to load in the IMDB Sentiment dataset. We'll show an example with a CSV later. 
```
</details>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="EasySequenceClassifier.tag_text" class="doc_header"><code>EasySequenceClassifier.tag_text</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/sequence_classification.py#L384" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>EasySequenceClassifier.tag_text</code>(<strong><code>text</code></strong>:<code>Union</code>[<code>List</code>[<code>Sentence</code>], <code>Sentence</code>, <code>List</code>[<code>str</code>], <code>str</code>], <strong><code>model_name_or_path</code></strong>:<code>Union</code>[<code>str</code>, <a href="/adaptnlp/model_hub.html#FlairModelResult"><code>FlairModelResult</code></a>, <a href="/adaptnlp/model_hub.html#HFModelResult"><code>HFModelResult</code></a>]=<em><code>'en-sentiment'</code></em>, <strong><code>mini_batch_size</code></strong>:<code>int</code>=<em><code>32</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Tags a text sequence with labels the sequence classification models have been trained on</p>
<ul>
<li><strong>text</strong> - String, list of strings, <code>Sentence</code>, or list of <code>Sentence</code>s to be classified</li>
<li><strong>model_name_or_path</strong> - The model name key or model path</li>
<li><strong>mini_batch_size</strong> - The mini batch size for running inference</li>
<li><strong>&ast;&ast;kwargs</strong> - (Optional) Keyword Arguments for Flair's <code>TextClassifier.predict()</code> method params
<strong>return</strong> A list of Flair's <code>Sentence</code>'s</li>
</ul>
<p><strong>Usage Examples:</strong></p>
<details>
<summary markdown="span">Click Me to Show Code Examples</summary><b><a href=https://nbviewer.jupyter.org/github/novetta/adaptnlp/tree/master/nbs/06_sequence_classification.ipynb>Source</a></b>
```python
#hide
hub = HFModelHub()
model = hub.search_model_by_name("nlptown/bert-base", user_uploaded=True)[0]
classifier = EasySequenceClassifier()
sentences = classifier.tag_text(text=example_text, 
                               model_name_or_path=model,
                               mini_batch_size=1)
for pred, truth in zip(preds, truth_lbls):
    test_eq(pred.value, truth.value)
    test_close(pred.score, truth.score, 1e-4)
```
</details>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="EasySequenceClassifier.tag_all" class="doc_header"><code>EasySequenceClassifier.tag_all</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/sequence_classification.py#L443" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>EasySequenceClassifier.tag_all</code>(<strong><code>text</code></strong>:<code>Union</code>[<code>List</code>[<code>Sentence</code>], <code>Sentence</code>, <code>List</code>[<code>str</code>], <code>str</code>], <strong><code>mini_batch_size</code></strong>:<code>int</code>=<em><code>32</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Tags text with all labels from all sequence classification models</p>
<ul>
<li><strong>text</strong> - Text input, it can be a string or any of Flair's <code>Sentence</code> input formats</li>
<li><strong>mini_batch_size</strong> - The mini batch size for running inference</li>
<li><strong>&ast;&ast;kwargs</strong> - (Optional) Keyword Arguments for Flair's <code>TextClassifier.predict()</code> method params</li>
<li><strong>return</strong> - A list of Flair's <code>Sentence</code>'s</li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="EasySequenceClassifier.release_model" class="doc_header"><code>EasySequenceClassifier.release_model</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/sequence_classification.py#L521" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>EasySequenceClassifier.release_model</code>(<strong><code>model_name_or_path</code></strong>:<code>str</code>)</p>
</blockquote>
<p>Unload <code>model_name_or_path</code> from classifier and empty cuda memory cache</p>
<p>May leave residual cache per pytorch documentation on torch.cuda.empty_cache()</p>
<ul>
<li><strong>model_name_or_path</strong> - The model name or key path that you want to unload and release memory from</li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

