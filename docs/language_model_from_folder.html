---

title: Tutorial&#58; Fine-Tuning a Language Model on Text Files with IMDB


keywords: fastai
sidebar: home_sidebar

summary: "Tuning a base Language model on the IMDB dataset"
description: "Tuning a base Language model on the IMDB dataset"
nb_path: "nbs/training_api_tutorials/language_model/language_model_from_folder.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/training_api_tutorials/language_model/language_model_from_folder.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Introduction">Introduction<a class="anchor-link" href="#Introduction"> </a></h2><p>In this tutorial we will be showing an end-to-end example of fine-tuning a Transformer language model on a custom dataset in text files format.</p>
<p>By the end of this you should be able to:</p>
<ol>
<li>Build a dataset with the <a href="/adaptnlp/training.language_model.html#LanguageModelDatasets"><code>LanguageModelDatasets</code></a> class, and their DataLoaders</li>
<li>Build a <a href="/adaptnlp/training.language_model.html#LanguageModelTuner"><code>LanguageModelTuner</code></a> quickly, find a good learning rate, and train with the One-Cycle Policy</li>
<li>Save that model away, to be used with deployment or other HuggingFace libraries</li>
<li>Apply inference using both the <code>Tuner</code> available function as well as with the <a href="/adaptnlp/text_generation.html#EasyTextGenerator"><code>EasyTextGenerator</code></a> class within AdaptNLP</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Installing-the-Library">Installing the Library<a class="anchor-link" href="#Installing-the-Library"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This tutorial utilizies the latest AdaptNLP version, as well as parts of the <code>fastai</code> library. Please run the below code to install them:</p>
<div class="highlight"><pre><span></span><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">adaptnlp</span> <span class="o">-</span><span class="n">U</span>
</pre></div>
<p>(or <code>pip3</code>)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Getting-the-Dataset">Getting the Dataset<a class="anchor-link" href="#Getting-the-Dataset"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>First we need a dataset. We will use the <code>fastai</code> library to download the full <code>IMDB</code> Movie Reviews dataset</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">fastai.data.external</span> <span class="kn">import</span> <span class="n">URLs</span><span class="p">,</span> <span class="n">untar_data</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>URLs</code> holds a namespace of many data endpoints, and <code>untar_data</code> is a function that can download and extract any data from a given URL.</p>
<p>Combining both, we can download the data:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data_path</span> <span class="o">=</span> <span class="n">untar_data</span><span class="p">(</span><span class="n">URLs</span><span class="o">.</span><span class="n">IMDB</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If we look at what was downloaded, we will find a <code>train</code> and <code>test</code> folder:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data_path</span><span class="o">.</span><span class="n">ls</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(#7) [Path(&#39;/root/.fastai/data/imdb/test&#39;),Path(&#39;/root/.fastai/data/imdb/README&#39;),Path(&#39;/root/.fastai/data/imdb/train&#39;),Path(&#39;/root/.fastai/data/imdb/imdb.vocab&#39;),Path(&#39;/root/.fastai/data/imdb/tmp_clas&#39;),Path(&#39;/root/.fastai/data/imdb/unsup&#39;),Path(&#39;/root/.fastai/data/imdb/tmp_lm&#39;)]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In each are folders seperating each text file by class:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="p">(</span><span class="n">data_path</span><span class="o">/</span><span class="s1">&#39;train&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">ls</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(#4) [Path(&#39;/root/.fastai/data/imdb/train/pos&#39;),Path(&#39;/root/.fastai/data/imdb/train/neg&#39;),Path(&#39;/root/.fastai/data/imdb/train/unsupBow.feat&#39;),Path(&#39;/root/.fastai/data/imdb/train/labeledBow.feat&#39;)]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As a result, we can say the dataset follows the following format:</p>
<ul>
<li><code>train</code><ul>
<li><code>class_a</code><ul>
<li><code>text1.txt</code></li>
<li><code>text2.txt</code></li>
<li>...</li>
</ul>
</li>
<li><code>class_b</code><ul>
<li><code>text1.txt</code></li>
<li>...</li>
</ul>
</li>
</ul>
</li>
<li><code>test</code> (or <code>valid</code>)<ul>
<li><code>class_a</code><ul>
<li><code>text1.txt</code></li>
<li>...</li>
</ul>
</li>
<li><code>class_b</code><ul>
<li><code>text1.txt</code></li>
<li>...</li>
</ul>
</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include note.html content='In this instance, test and validation have very similar meanings. Both are the dataset which is used to calculate the metrics during training (such as accuracy or F1Score)' %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now that we have the dataset, and we know the format it is in, let's pick a viable model to train with</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Picking-a-Model-with-the-Hub">Picking a Model with the Hub<a class="anchor-link" href="#Picking-a-Model-with-the-Hub"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>AdaptNLP has a <a href="/adaptnlp/model_hub.html#HFModelHub"><code>HFModelHub</code></a> class that allows you to communicate with the HuggingFace Hub and pick a model from it, as well as a namespace <code>HF_TASKS</code> class with a list of valid tasks we can search by.</p>
<p>Let's try and find one suitable for sequence classification.</p>
<p>First we need to import the class and generate an instance of it:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">HFModelHub</span><span class="p">,</span> <span class="n">HF_TASKS</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hub</span> <span class="o">=</span> <span class="n">HFModelHub</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next we can search for a model:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">models</span> <span class="o">=</span> <span class="n">hub</span><span class="o">.</span><span class="n">search_model_by_task</span><span class="p">(</span><span class="n">HF_TASKS</span><span class="o">.</span><span class="n">TEXT_GENERATION</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's look at a few:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">models</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[Model Name: distilgpt2, Tasks: [text-generation],
 Model Name: gpt2-large, Tasks: [text-generation],
 Model Name: gpt2-medium, Tasks: [text-generation],
 Model Name: gpt2-xl, Tasks: [text-generation],
 Model Name: gpt2, Tasks: [text-generation],
 Model Name: openai-gpt, Tasks: [text-generation],
 Model Name: transfo-xl-wt103, Tasks: [text-generation],
 Model Name: xlnet-base-cased, Tasks: [text-generation],
 Model Name: xlnet-large-cased, Tasks: [text-generation]]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>These are models specifically tagged with the <code>text-generation</code> tag, so you may not see a few models you would expect such as <code>bert_base_cased</code>.</p>
<p>We'll use that first model, <code>distilgpt2</code>:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Model Name: distilgpt2, Tasks: [text-generation]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now that we have picked a model, let's use the data API to prepare our data</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include note.html content='It should be mentioned that this is optional, you can always just pass in the string name of a model such as "bert-base-cased"' %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Building-TaskDatasets-with-LanguageModelDatasets">Building <a href="/adaptnlp/training.core.html#TaskDatasets"><code>TaskDatasets</code></a> with <a href="/adaptnlp/training.language_model.html#LanguageModelDatasets"><code>LanguageModelDatasets</code></a><a class="anchor-link" href="#Building-TaskDatasets-with-LanguageModelDatasets"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Each task has a high-level data wrapper around the <a href="/adaptnlp/training.core.html#TaskDatasets"><code>TaskDatasets</code></a> class. In our case this is the <a href="/adaptnlp/training.language_model.html#LanguageModelDatasets"><code>LanguageModelDatasets</code></a> class:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">LanguageModelDatasets</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There are multiple different constructors for the <a href="/adaptnlp/training.language_model.html#LanguageModelDatasets"><code>LanguageModelDatasets</code></a> class, and you should never call the main constructor directly.</p>
<p>We will be using <code>from_folders</code> method:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="LanguageModelDatasets.from_folders" class="doc_header"><code>LanguageModelDatasets.from_folders</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/language_model.py#L155" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>LanguageModelDatasets.from_folders</code>(<strong><code>train_path</code></strong>:<code>Path</code>, <strong><code>tokenizer_name</code></strong>:<code>str</code>, <strong><code>block_size</code></strong>:<code>int</code>=<em><code>128</code></em>, <strong><code>masked_lm</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>valid_path</code></strong>:<code>Path</code>=<em><code>None</code></em>, <strong><code>split_func</code></strong>:<code>callable</code>=<em><code>None</code></em>, <strong><code>split_pct</code></strong>:<code>float</code>=<em><code>0.1</code></em>, <strong><code>tokenize_kwargs</code></strong>:<code>dict</code>=<em><code>{}</code></em>, <strong><code>auto_kwargs</code></strong>:<code>dict</code>=<em><code>{}</code></em>)</p>
</blockquote>
<p>Builds <a href="/adaptnlp/training.language_model.html#LanguageModelDatasets"><code>LanguageModelDatasets</code></a> from a folder or group of folders</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>train_path</code></strong> : <em><code>&lt;class 'pathlib.Path'&gt;</code></em>    <p>The path to the training data</p></li>
</ul>
<ul>
<li><strong><code>tokenizer_name</code></strong> : <em><code>&lt;class 'str'&gt;</code></em> <p>The name of the tokenizer</p></li>
</ul>
<ul>
<li><strong><code>block_size</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em> <p>The size of each block</p></li>
</ul>
<ul>
<li><strong><code>masked_lm</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em> <p>Whether the language model is a MLM</p></li>
</ul>
<ul>
<li><strong><code>valid_path</code></strong> : <em><code>&lt;class 'pathlib.Path'&gt;</code></em>, <em>optional</em>    <p>An optional validation path</p></li>
</ul>
<ul>
<li><strong><code>split_func</code></strong> : <em><code>&lt;built-in function callable&gt;</code></em>, <em>optional</em>  <p>Optionally a splitting function similar to RandomSplitter</p></li>
</ul>
<ul>
<li><strong><code>split_pct</code></strong> : <em><code>&lt;class 'float'&gt;</code></em>, <em>optional</em>    <p>What % to split the df between training and validation</p></li>
</ul>
<ul>
<li><strong><code>tokenize_kwargs</code></strong> : <em><code>&lt;class 'dict'&gt;</code></em>, <em>optional</em>   <p>kwargs for the tokenize function</p></li>
</ul>
<ul>
<li><strong><code>auto_kwargs</code></strong> : <em><code>&lt;class 'dict'&gt;</code></em>, <em>optional</em>   <p>kwargs for the AutoTokenizer.from_pretrained constructor</p></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Anything you would normally pass to the tokenizer call (such as <code>max_length</code>, <code>padding</code>) should go in <code>tokenize_kwargs</code>, and anything going to the <code>AutoTokenizer.from_pretrained</code> constructor should be passed to the <code>auto_kwargs</code>.</p>
<p>In our case we have a <code>train_path</code> and <code>valid_path</code></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">fastcore.basics</span> <span class="kn">import</span> <span class="n">patch</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Also, we will set a block_size of 128, and it is <em>not</em> a masked language model:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dsets</span> <span class="o">=</span> <span class="n">LanguageModelDatasets</span><span class="o">.</span><span class="n">from_folders</span><span class="p">(</span>
    <span class="n">train_path</span><span class="o">=</span><span class="n">data_path</span><span class="o">/</span><span class="s1">&#39;train&#39;</span><span class="p">,</span>
    <span class="n">valid_path</span><span class="o">=</span><span class="n">data_path</span><span class="o">/</span><span class="s1">&#39;test&#39;</span><span class="p">,</span>
    <span class="n">tokenizer_name</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
    <span class="n">block_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
    <span class="n">masked_lm</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Using custom data configuration default-1f2b71eec4880b46
Reusing dataset text_no_new_line (/root/.cache/huggingface/datasets/text_no_new_line/default-1f2b71eec4880b46/0.0.0)
Using custom data configuration default-04d8fbd2bd2108a0
Reusing dataset text_no_new_line (/root/.cache/huggingface/datasets/text_no_new_line/default-04d8fbd2bd2108a0/0.0.0)
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>No value for `max_length` set, automatically adjusting to the size of the model and including truncation
Sequence length set to: 1024




</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include note.html content='If you only have a training folder, just pass in a <code>split_func</code> or <code>split_pct</code> to either have it split the dataset in a custom way, or pass in a percentage to randomly split by' %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And finally turn it into some <a href="/adaptnlp/training.core.html#AdaptiveDataLoaders"><code>AdaptiveDataLoaders</code></a>.</p>
<p>These are just fastai's <code>DataLoaders</code> class, but it overrides a few functions to have it work nicely with HuggingFace's <code>Dataset</code> class</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="LanguageModelDatasets.dataloaders" class="doc_header"><code>LanguageModelDatasets.dataloaders</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/language_model.py#L202" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>LanguageModelDatasets.dataloaders</code>(<strong><code>batch_size</code></strong>=<em><code>8</code></em>, <strong><code>shuffle_train</code></strong>=<em><code>True</code></em>, <strong><code>collate_fn</code></strong>=<em><code>default_data_collator</code></em>, <strong><code>mlm_probability</code></strong>:<code>float</code>=<em><code>0.15</code></em>, <strong><code>path</code></strong>=<em><code>'.'</code></em>, <strong><code>device</code></strong>=<em><code>None</code></em>)</p>
</blockquote>
<p>Build DataLoaders from <code>self</code></p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>batch_size</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em> <p>A batch size</p></li>
</ul>
<ul>
<li><strong><code>shuffle_train</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em> <p>Whether to shuffle the training dataset</p></li>
</ul>
<ul>
<li><strong><code>collate_fn</code></strong> : <em><code>&lt;class 'function'&gt;</code></em>, <em>optional</em>    <p>A custom collation function</p></li>
</ul>
<ul>
<li><strong><code>mlm_probability</code></strong> : <em><code>&lt;class 'float'&gt;</code></em>, <em>optional</em>  <p>Token masking probablity for Masked Language Models</p></li>
</ul>
<ul>
<li><p><strong><code>path</code></strong> : <em><code>&lt;class 'str'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>device</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em></p>
</li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally, let's view a batch of data with the <code>show_batch</code> function:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span><span class="o">.</span><span class="n">show_batch</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Input</th>
      <th>Label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>dad."&lt;br /&gt;&lt;br /&gt;This film makes periodic appearances on TV but today my teenage son and I saw it in a theater with quite a few youngsters present. It was great to see computer-besotted kids in an affluent community respond with cheers and applause to special effects that must seem primitive to them.&lt;br /&gt;&lt;br /&gt;"Thief of Bagdad" is a pre-war Hollywood classic from a time when strong production values often resulted in enduringly attractive and important releases. This is one of the best of its kind.&lt;br /&gt;&lt;br /&gt;9/10.This movie is simply incredible! I had expected something quite different form the film that I actually saw. However, it is very insightful in that it shows the aggressive nature of human sexuality and its linkage with animal behavior. Let me warn those among the readers of this article who are easily offended by content that is all too sexual, for the explicit sexual nature of this film feels like a high-brow sort of pornography. It even features a scene that comes extremely close to rape.&lt;br /&gt;&lt;br /&gt;Meanwhile, I strongly suggest seeing this rare work of "sexual art". Every minute of the picture breathes the sexual spirit of the seventies, by the way. One should not forget how times have changed!&lt;br /&gt;&lt;br /&gt;Go see it! It´s worth your money and time!If you have ever read and enjoyed a novel by Tom Robbins you will appreciate this movie as a whole-hearted attempt to translate his outrageously unconventional writing style into a workable piece of big screen art. The actors and the direction of this film are both good. &lt;br /&gt;&lt;br /&gt;The only trouble with the film, as I can see it, is that Robbins can relate ideas and sentiments with his words that were still beyond Hollywood's capabilities at the time this film was shot.&lt;br /&gt;&lt;br /&gt;Given both the irreverence of today's movies, as well as the willingness and abilityof today's audiences to delve into the bizarre, I think "Even Cowgirls... would receive a better reception today than it did when it was originally released.With Iphigenia, Mikhali Cacoyannis is perhaps the first film director to have successfully brought the feel of ancient Greek theatre to the screen. His own screenplay, an adaptation of Euripides' tragedy, was far from easy, compared to that of the other two films of the trilogy he directed. The story has been very carefully deconstructed from Euripides' version and</td>
      <td>dad."&lt;br /&gt;&lt;br /&gt;This film makes periodic appearances on TV but today my teenage son and I saw it in a theater with quite a few youngsters present. It was great to see computer-besotted kids in an affluent community respond with cheers and applause to special effects that must seem primitive to them.&lt;br /&gt;&lt;br /&gt;"Thief of Bagdad" is a pre-war Hollywood classic from a time when strong production values often resulted in enduringly attractive and important releases. This is one of the best of its kind.&lt;br /&gt;&lt;br /&gt;9/10.This movie is simply incredible! I had expected something quite different form the film that I actually saw. However, it is very insightful in that it shows the aggressive nature of human sexuality and its linkage with animal behavior. Let me warn those among the readers of this article who are easily offended by content that is all too sexual, for the explicit sexual nature of this film feels like a high-brow sort of pornography. It even features a scene that comes extremely close to rape.&lt;br /&gt;&lt;br /&gt;Meanwhile, I strongly suggest seeing this rare work of "sexual art". Every minute of the picture breathes the sexual spirit of the seventies, by the way. One should not forget how times have changed!&lt;br /&gt;&lt;br /&gt;Go see it! It´s worth your money and time!If you have ever read and enjoyed a novel by Tom Robbins you will appreciate this movie as a whole-hearted attempt to translate his outrageously unconventional writing style into a workable piece of big screen art. The actors and the direction of this film are both good. &lt;br /&gt;&lt;br /&gt;The only trouble with the film, as I can see it, is that Robbins can relate ideas and sentiments with his words that were still beyond Hollywood's capabilities at the time this film was shot.&lt;br /&gt;&lt;br /&gt;Given both the irreverence of today's movies, as well as the willingness and abilityof today's audiences to delve into the bizarre, I think "Even Cowgirls... would receive a better reception today than it did when it was originally released.With Iphigenia, Mikhali Cacoyannis is perhaps the first film director to have successfully brought the feel of ancient Greek theatre to the screen. His own screenplay, an adaptation of Euripides' tragedy, was far from easy, compared to that of the other two films of the trilogy he directed. The story has been very carefully deconstructed from Euripides' version and</td>
    </tr>
    <tr>
      <th>1</th>
      <td>up his seat for one of the intended victims, flees with his tail in-between his legs, rather than face immanent death with the school kids he's promised not to leave behind.&lt;br /&gt;&lt;br /&gt;It's more of character study, and a come to Jesus moment for one character, than a story about the genocide in "RAWANDA". This movie didn't have to take place in RAWANDA, it could have taken place any one of the Genocidal hell holes going around this world at any given time.This is one seriously disturbed movie. Even Though the boys deserved some of what they got.....the sadistic gruesome executions were "slightly" over the top. The only character showing some conscience early in the hunt was killed off before he could offer some help to the sad plot.&lt;br /&gt;&lt;br /&gt;At the beginning of the movie, there looked to be some promise of a mediocre affair, but this was just a ploy to lull the viewers into a false sense of security, before the joy of what was to come. &lt;br /&gt;&lt;br /&gt;The only thing that could have saved the movie for me was if Jack Nicholson had jumped out of the bushes and yelled, "and, where is the batman?". Kim Basinger could have screamed. &lt;br /&gt;&lt;br /&gt;Now that would have been cool!I stopped by BB and picked up 4 zombie flicks to watch over the weekend. Now, I understand that the effects will be cheesy, the acting will be sub-par, and the sets will be suspect. So I'm not expecting much. But it should at least have a story. Stories don't cost a thing except time.....apparently, they didn't have any time either.&lt;br /&gt;&lt;br /&gt;"Zombie Nation" had 5 zombies that appeared near the end of the movie that all looked like new wave hookers. The picture of the zombie on the front cover NEVER appears in the movie. It was absolutely agonizing to watch and had nothing to offer the genre.&lt;br /&gt;&lt;br /&gt;The running time is only 81 minutes but it felt like 2 hours. According to my wife (who could only hear the movie since she was on the computer in another room), it sounded like zombie porn....which if you think about, sounds kinda gross.....but it wasn't even that good.&lt;br /&gt;&lt;br /&gt;The only suggestion I can make is that maybe the writer tried to do too many things and ended up with an incoherent mess.&lt;br /&gt;&lt;br</td>
      <td>up his seat for one of the intended victims, flees with his tail in-between his legs, rather than face immanent death with the school kids he's promised not to leave behind.&lt;br /&gt;&lt;br /&gt;It's more of character study, and a come to Jesus moment for one character, than a story about the genocide in "RAWANDA". This movie didn't have to take place in RAWANDA, it could have taken place any one of the Genocidal hell holes going around this world at any given time.This is one seriously disturbed movie. Even Though the boys deserved some of what they got.....the sadistic gruesome executions were "slightly" over the top. The only character showing some conscience early in the hunt was killed off before he could offer some help to the sad plot.&lt;br /&gt;&lt;br /&gt;At the beginning of the movie, there looked to be some promise of a mediocre affair, but this was just a ploy to lull the viewers into a false sense of security, before the joy of what was to come. &lt;br /&gt;&lt;br /&gt;The only thing that could have saved the movie for me was if Jack Nicholson had jumped out of the bushes and yelled, "and, where is the batman?". Kim Basinger could have screamed. &lt;br /&gt;&lt;br /&gt;Now that would have been cool!I stopped by BB and picked up 4 zombie flicks to watch over the weekend. Now, I understand that the effects will be cheesy, the acting will be sub-par, and the sets will be suspect. So I'm not expecting much. But it should at least have a story. Stories don't cost a thing except time.....apparently, they didn't have any time either.&lt;br /&gt;&lt;br /&gt;"Zombie Nation" had 5 zombies that appeared near the end of the movie that all looked like new wave hookers. The picture of the zombie on the front cover NEVER appears in the movie. It was absolutely agonizing to watch and had nothing to offer the genre.&lt;br /&gt;&lt;br /&gt;The running time is only 81 minutes but it felt like 2 hours. According to my wife (who could only hear the movie since she was on the computer in another room), it sounded like zombie porn....which if you think about, sounds kinda gross.....but it wasn't even that good.&lt;br /&gt;&lt;br /&gt;The only suggestion I can make is that maybe the writer tried to do too many things and ended up with an incoherent mess.&lt;br /&gt;&lt;br</td>
    </tr>
    <tr>
      <th>2</th>
      <td>and how they painted the ones on their side. It was the ending that I hated. I was disappointed that it was earth but 150k years back. But to travel all that way just to start over? Are you kidding me? 38k people that fought for their very existence and once they get to paradise, they abandon technology? No way. Sure they were eating paper and rationing food, but that is over. They can live like humans again. They only have one good doctor. What are they going to do when someone has a tooth ache never mind giving birth... yea right. No one would have made that choice.I have to agree with some of the other comments and even go a step further. &lt;br /&gt;&lt;br /&gt;Nothing about this film worked, absolutely nothing. Delmar our central character makes the decision to become a surrogate mother in order to earn enough money to buy a restaurant but along the way fall for a wise ex-jailbird. At the same time her friend Hortense is trying to get her lawyer boyfriend to finally marry her. She also happens to be sleeping with Marlon who is desperately in love with her. Then there's Delmar's brother Jethro who gets involved with a former coke addict, Missy who reveals she was sexually abused by her adopted father. On the sidelines we also have the eccentricmother who has an assortment of equally odd friends, one of whom dies on the couch at the beginning of the film. So far so good but after introducing these characters and story lines addressing life, death, grief and love in the first half, the film simply loses direction. &lt;br /&gt;&lt;br /&gt;If the writer had only selected one or two characters and allowed us to follow their stories maybe things would have been fine but equal screen time is given to all with the result that no one story or character is fully developed. For instance, why does Delmar think she will be able to hand over her child in exchange for money, especially when the prospective parents are a creepy bigoted lawyer and his semi alcoholic and depressed wife? Why is Hortense so desperate to marry a man who is a jerk and clearly doesn't love her? How is it Missy manages to kick her coke habit overnight? Is Jethro regularly drawn to women with overwhelming problems, or is Missy the exception? Has Delmar and Jethro's mother always been on the eccentric side, or is it a more recent development? Why is Jethro so keen on Cadillacs that he</td>
      <td>and how they painted the ones on their side. It was the ending that I hated. I was disappointed that it was earth but 150k years back. But to travel all that way just to start over? Are you kidding me? 38k people that fought for their very existence and once they get to paradise, they abandon technology? No way. Sure they were eating paper and rationing food, but that is over. They can live like humans again. They only have one good doctor. What are they going to do when someone has a tooth ache never mind giving birth... yea right. No one would have made that choice.I have to agree with some of the other comments and even go a step further. &lt;br /&gt;&lt;br /&gt;Nothing about this film worked, absolutely nothing. Delmar our central character makes the decision to become a surrogate mother in order to earn enough money to buy a restaurant but along the way fall for a wise ex-jailbird. At the same time her friend Hortense is trying to get her lawyer boyfriend to finally marry her. She also happens to be sleeping with Marlon who is desperately in love with her. Then there's Delmar's brother Jethro who gets involved with a former coke addict, Missy who reveals she was sexually abused by her adopted father. On the sidelines we also have the eccentricmother who has an assortment of equally odd friends, one of whom dies on the couch at the beginning of the film. So far so good but after introducing these characters and story lines addressing life, death, grief and love in the first half, the film simply loses direction. &lt;br /&gt;&lt;br /&gt;If the writer had only selected one or two characters and allowed us to follow their stories maybe things would have been fine but equal screen time is given to all with the result that no one story or character is fully developed. For instance, why does Delmar think she will be able to hand over her child in exchange for money, especially when the prospective parents are a creepy bigoted lawyer and his semi alcoholic and depressed wife? Why is Hortense so desperate to marry a man who is a jerk and clearly doesn't love her? How is it Missy manages to kick her coke habit overnight? Is Jethro regularly drawn to women with overwhelming problems, or is Missy the exception? Has Delmar and Jethro's mother always been on the eccentric side, or is it a more recent development? Why is Jethro so keen on Cadillacs that he</td>
    </tr>
    <tr>
      <th>3</th>
      <td>corner.&lt;br /&gt;&lt;br /&gt;Peter's fate ultimately lies with the heavenly court and American prosecutor (Raymond Massey), whose jury consists of several deceased war heroes and posh British delegates. The surreal trial, which dissolves from b/w back into rich Technicolor, once the verdict is announced, may well be a dream, but the final shot in the hospital validates the predictable outcome.&lt;br /&gt;&lt;br /&gt;The abstract, frame filling "stairway to heaven" (the American title of the film) is used twice: the first time in b/w, when it elevates Peter and his enigmatic French guardian upwards, crossing giant statues of Peter's potential attorneys for the trial, including Abraham Lincoln and Plato. The second time, the softly lit colour stairway provides the setting for what is an iconic image in cinema - Peter and June frozen side-by-side, their marvelled eyes fixed forward in the frame, their fate sealed.&lt;br /&gt;&lt;br /&gt;The unlikely affection shared between Peter and June never turns mushy or verbose; it's treated with nobility and the perception that the couple are already suitable enough to be married and simply need to convince people of their love, so it can keep them together. &lt;br /&gt;&lt;br /&gt;The French Conductor, who can freeze time and people's bodies, obtrudes many of their key moments together, lecturing Peter about history and among his mischievous tricks, pinching Peter's 'Top 100 Game Tricks' book and his coffee cup.&lt;br /&gt;&lt;br /&gt;As visually inspired as other Powell/Pressburger collaborations, this was the first time they combined colour with b/w  the latter having a cheerful quality when used for the heaven scenes, and both are equally captivating. &lt;br /&gt;&lt;br /&gt;The outstanding script more than matches the imaginative set design, with dialogue that sounds so immediate that is doesn't feel like it was written or performed for the screen. Amusing and witty, Powell/Pressburger's writing deserves equal acclamation with their forte for colour and composition.&lt;br /&gt;&lt;br /&gt;Made in 1946, "A Matter of Life and Death" is one of those films that defies it age, looking fresh and inventive, even in this age where CGI would vamp up its artificial effects, probably stripping them of their emotional wonder. &lt;br /&gt;&lt;br /&gt;Other jarring changes would include the need for reduced average seconds for cutting and the inevitable plea to shorten dialogue so it can preserve</td>
      <td>corner.&lt;br /&gt;&lt;br /&gt;Peter's fate ultimately lies with the heavenly court and American prosecutor (Raymond Massey), whose jury consists of several deceased war heroes and posh British delegates. The surreal trial, which dissolves from b/w back into rich Technicolor, once the verdict is announced, may well be a dream, but the final shot in the hospital validates the predictable outcome.&lt;br /&gt;&lt;br /&gt;The abstract, frame filling "stairway to heaven" (the American title of the film) is used twice: the first time in b/w, when it elevates Peter and his enigmatic French guardian upwards, crossing giant statues of Peter's potential attorneys for the trial, including Abraham Lincoln and Plato. The second time, the softly lit colour stairway provides the setting for what is an iconic image in cinema - Peter and June frozen side-by-side, their marvelled eyes fixed forward in the frame, their fate sealed.&lt;br /&gt;&lt;br /&gt;The unlikely affection shared between Peter and June never turns mushy or verbose; it's treated with nobility and the perception that the couple are already suitable enough to be married and simply need to convince people of their love, so it can keep them together. &lt;br /&gt;&lt;br /&gt;The French Conductor, who can freeze time and people's bodies, obtrudes many of their key moments together, lecturing Peter about history and among his mischievous tricks, pinching Peter's 'Top 100 Game Tricks' book and his coffee cup.&lt;br /&gt;&lt;br /&gt;As visually inspired as other Powell/Pressburger collaborations, this was the first time they combined colour with b/w  the latter having a cheerful quality when used for the heaven scenes, and both are equally captivating. &lt;br /&gt;&lt;br /&gt;The outstanding script more than matches the imaginative set design, with dialogue that sounds so immediate that is doesn't feel like it was written or performed for the screen. Amusing and witty, Powell/Pressburger's writing deserves equal acclamation with their forte for colour and composition.&lt;br /&gt;&lt;br /&gt;Made in 1946, "A Matter of Life and Death" is one of those films that defies it age, looking fresh and inventive, even in this age where CGI would vamp up its artificial effects, probably stripping them of their emotional wonder. &lt;br /&gt;&lt;br /&gt;Other jarring changes would include the need for reduced average seconds for cutting and the inevitable plea to shorten dialogue so it can preserve</td>
    </tr>
    <tr>
      <th>4</th>
      <td>carry out for the 3 months that Bill is in New York, while Bill meets with Cleo and another woman. At the end, love is in the air for Bill and one other.............&lt;br /&gt;&lt;br /&gt;The picture quality and sound quality are poor in this film. The story is interspersed with musical numbers but the songs are bad and Kathryn Crawford has a terrible voice. Rogers isn't that good either. He's pleasant enough but only really comes to life when playing the drums or trombone. There is a very irritating character who plays a cab driver (Roscoe Karns) and the film is just dull.i've seen a movie thats sort of like this, were a transsexual drugs woman and he then picks there nose with a knife and rips there nose to peaces. he then slices there tongue and eats it.&lt;br /&gt;&lt;br /&gt;the most gruesome part of the movie is were he cuts there left eye out and starts dancing with it. he then starts to eat the woman naked.&lt;br /&gt;&lt;br /&gt;(i'm not sure what the movies called but i know it's a cult movie and that it was made in Germany).&lt;br /&gt;&lt;br /&gt;anyway THE NOSE PICKER is fairly crap.&lt;br /&gt;&lt;br /&gt;its a crap movie and the picture and volume quality is very rubbish.&lt;br /&gt;&lt;br /&gt;please don't waste you're time buying and watching this movie its totally crap.&lt;br /&gt;&lt;br /&gt;i prefer DAY OF THE WOMAN also known as I SPIT ON YOUR GRAVE (its one of the best cult movies ever) check out this link http://www.imdb.com/title/tt0077713/Having searched for this movie high and low, I actually found it when I least expected, playing on the Sundance Channel very early in the morning one day. Why I searched endlessly for a small vanity project that Chuck Barris that was made during the last waning years of the TV show, I haven't a clue. The film is simply put horrible. The scripted part that deals with a week that is. Of course the highlight of the film is seeing the real performers that were "too hot for TV" or rejected for some reason or other. That part is still horrid, but campy bad which was enjoyable in it's own way. Now that I saw what I sought after for so long will I watch it again in my lifetime? Resoundingly NO!! Do yourself a favor and just watch the MUCH</td>
      <td>carry out for the 3 months that Bill is in New York, while Bill meets with Cleo and another woman. At the end, love is in the air for Bill and one other.............&lt;br /&gt;&lt;br /&gt;The picture quality and sound quality are poor in this film. The story is interspersed with musical numbers but the songs are bad and Kathryn Crawford has a terrible voice. Rogers isn't that good either. He's pleasant enough but only really comes to life when playing the drums or trombone. There is a very irritating character who plays a cab driver (Roscoe Karns) and the film is just dull.i've seen a movie thats sort of like this, were a transsexual drugs woman and he then picks there nose with a knife and rips there nose to peaces. he then slices there tongue and eats it.&lt;br /&gt;&lt;br /&gt;the most gruesome part of the movie is were he cuts there left eye out and starts dancing with it. he then starts to eat the woman naked.&lt;br /&gt;&lt;br /&gt;(i'm not sure what the movies called but i know it's a cult movie and that it was made in Germany).&lt;br /&gt;&lt;br /&gt;anyway THE NOSE PICKER is fairly crap.&lt;br /&gt;&lt;br /&gt;its a crap movie and the picture and volume quality is very rubbish.&lt;br /&gt;&lt;br /&gt;please don't waste you're time buying and watching this movie its totally crap.&lt;br /&gt;&lt;br /&gt;i prefer DAY OF THE WOMAN also known as I SPIT ON YOUR GRAVE (its one of the best cult movies ever) check out this link http://www.imdb.com/title/tt0077713/Having searched for this movie high and low, I actually found it when I least expected, playing on the Sundance Channel very early in the morning one day. Why I searched endlessly for a small vanity project that Chuck Barris that was made during the last waning years of the TV show, I haven't a clue. The film is simply put horrible. The scripted part that deals with a week that is. Of course the highlight of the film is seeing the real performers that were "too hot for TV" or rejected for some reason or other. That part is still horrid, but campy bad which was enjoyable in it's own way. Now that I saw what I sought after for so long will I watch it again in my lifetime? Resoundingly NO!! Do yourself a favor and just watch the MUCH</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>When training a language model, the input and output are made to be the exact same, so there isn't a shown noticable difference here.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Building-Tuner">Building <code>Tuner</code><a class="anchor-link" href="#Building-Tuner"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next we need to build a compatible <code>Tuner</code> for our problem. These tuners contain good defaults for our problem space, including loss functions and metrics.</p>
<p>First let's import the <a href="/adaptnlp/training.language_model.html#LanguageModelTuner"><code>LanguageModelTuner</code></a> and view it's documentation</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">LanguageModelTuner</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="LanguageModelTuner" class="doc_header"><code>class</code> <code>LanguageModelTuner</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/language_model.py#L228" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>LanguageModelTuner</code>(<strong><code>dls</code></strong>:<code>DataLoaders</code>, <strong><code>model_name</code></strong>, <strong><code>tokenizer</code></strong>=<em><code>None</code></em>, <strong><code>language_model_type</code></strong>:<code>LMType</code>=<em><code>'causal'</code></em>, <strong><code>loss_func</code></strong>=<em><code>CrossEntropyLoss()</code></em>, <strong><code>metrics</code></strong>=<em><code>[&lt;fastai.metrics.Perplexity object at 0x7ffac36c2460&gt;]</code></em>, <strong><code>opt_func</code></strong>=<em><code>Adam</code></em>, <strong><code>additional_cbs</code></strong>=<em><code>None</code></em>, <strong><code>expose_fastai_api</code></strong>=<em><code>False</code></em>, <strong>**<code>kwargs</code></strong>) :: <a href="/adaptnlp/training.core.html#AdaptiveTuner"><code>AdaptiveTuner</code></a></p>
</blockquote>
<p>An <a href="/adaptnlp/training.core.html#AdaptiveTuner"><code>AdaptiveTuner</code></a> with good defaults for Language Model fine-tuning
<strong>Valid kwargs and defaults:</strong></p>
<ul>
<li><code>lr</code>:float = 0.001</li>
<li><code>splitter</code>:function = <code>trainable_params</code></li>
<li><code>cbs</code>:list = None</li>
<li><code>path</code>:Path = None</li>
<li><code>model_dir</code>:Path = 'models'</li>
<li><code>wd</code>:float = None</li>
<li><code>wd_bn_bias</code>:bool = False</li>
<li><code>train_bn</code>:bool = True</li>
<li><code>moms</code>: tuple(float) = (0.95, 0.85, 0.95)</li>
</ul>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>dls</code></strong> : <em><code>&lt;class 'fastai.data.core.DataLoaders'&gt;</code></em>   <p>A set of DataLoaders or AdaptiveDataLoaders</p></li>
</ul>
<ul>
<li><strong><code>model_name</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em>  <p>A HuggingFace model</p></li>
</ul>
<ul>
<li><strong><code>tokenizer</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em> <p>A HuggingFace tokenizer</p></li>
</ul>
<ul>
<li><strong><code>language_model_type</code></strong> : <em><code>&lt;class 'fastcore.basics.LMType'&gt;</code></em>, <em>optional</em> <p>The type of language model to use</p></li>
</ul>
<ul>
<li><strong><code>loss_func</code></strong> : <em><code>&lt;class 'fastai.losses.CrossEntropyLossFlat'&gt;</code></em>, <em>optional</em>   <p>A loss function</p></li>
</ul>
<ul>
<li><strong><code>metrics</code></strong> : <em><code>&lt;class 'list'&gt;</code></em>, <em>optional</em>   <p>Metrics to monitor the training with</p></li>
</ul>
<ul>
<li><strong><code>opt_func</code></strong> : <em><code>&lt;class 'function'&gt;</code></em>, <em>optional</em>  <p>A fastai or torch Optimizer</p></li>
</ul>
<ul>
<li><strong><code>additional_cbs</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em>    <p>Additional Callbacks to have always tied to the Tuner,</p></li>
</ul>
<ul>
<li><strong><code>expose_fastai_api</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em> <p>Whether to expose the fastai API</p></li>
</ul>
<ul>
<li><strong><code>kwargs</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next we'll pass in our <code>DataLoaders</code>, the name of our model, and the tokenizer:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include note.html content='If you are not using the data API (<a href="/adaptnlp/training.core.html#TaskDatasets"><code>TaskDatasets</code></a>, <a href="/adaptnlp/training.sequence_classification.html#SequenceClassificationDatasets"><code>SequenceClassificationDatasets</code></a>, etc), you need to pass in the tokenizer to the constructor as well with <code>tokenizer=tokenizer</code>' %}</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span> <span class="o">=</span> <span class="n">LanguageModelTuner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">dls</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>By default we can see that it used <code>CrossEntropyLoss</code> as our loss function, and <code>Perplexity</code> as our metric</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span><span class="o">.</span><span class="n">loss_func</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>FlattenedLoss of CrossEntropyLoss()</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="p">[</span><span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">tuner</span><span class="o">.</span><span class="n">metrics</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>perplexity
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally we just need to train our model!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Fine-Tuning">Fine-Tuning<a class="anchor-link" href="#Fine-Tuning"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And all that's left is to <code>tune</code>. There are only 4 or 5 functions you can call on our <code>tuner</code> currently, and this is by design to make it simplistic. In case you don't want to be boxed in however, if you pass in <code>expose_fastai_api=True</code> to our earlier call, it will expose the entirety of <code>Learner</code> to you, so you can call <code>fit_one_cycle</code>, <code>lr_find</code>, and everything else as <code>Tuner</code> uses <code>fastai</code> under the hood.</p>
<p>First, let's call <code>lr_find</code>, which uses fastai's Learning Rate Finder to help us pick a learning rate.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="AdaptiveTuner.lr_find" class="doc_header"><code>AdaptiveTuner.lr_find</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/core.py#L389" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>AdaptiveTuner.lr_find</code>(<strong><code>start_lr</code></strong>=<em><code>1e-07</code></em>, <strong><code>end_lr</code></strong>=<em><code>10</code></em>, <strong><code>num_it</code></strong>=<em><code>100</code></em>, <strong><code>stop_div</code></strong>=<em><code>True</code></em>, <strong><code>show_plot</code></strong>=<em><code>True</code></em>, <strong><code>suggest_funcs</code></strong>=<em><code>valley</code></em>)</p>
</blockquote>
<p>Runs fastai's <code>LR Finder</code></p>
<p><strong>Parameters:</strong></p>
<ul>
<li><p><strong><code>start_lr</code></strong> : <em><code>&lt;class 'float'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>end_lr</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>num_it</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>stop_div</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>show_plot</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>suggest_funcs</code></strong> : <em><code>&lt;class 'function'&gt;</code></em>, <em>optional</em></p>
</li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/opt/venv/lib/python3.8/site-packages/fastai/callback/schedule.py:270: UserWarning: color is redundantly defined by the &#39;color&#39; keyword argument and the fmt string &#34;ro&#34; (-&gt; color=&#39;r&#39;). The keyword argument will take precedence.
  ax.plot(val, idx, &#39;ro&#39;, label=nm, c=color)
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>SuggestedLRs(valley=7.585775892948732e-05)</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It recommends a learning rate of around 5e-5, so we will use that.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr</span> <span class="o">=</span> <span class="mf">5e-5</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's look at the documentation for <code>tune</code>:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="AdaptiveTuner.tune" class="doc_header"><code>AdaptiveTuner.tune</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/core.py#L375" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>AdaptiveTuner.tune</code>(<strong><code>epochs</code></strong>:<code>int</code>, <strong><code>lr</code></strong>:<code>float</code>=<em><code>None</code></em>, <strong><code>strategy</code></strong>:<code>Strategy</code>=<em><code>'fit_one_cycle'</code></em>, <strong><code>callbacks</code></strong>:<code>list</code>=<em><code>[]</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Fine tune <code>self.model</code> for <code>epochs</code> with an <code>lr</code> and <code>strategy</code></p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>epochs</code></strong> : <em><code>&lt;class 'int'&gt;</code></em> <p>Number of iterations to train for</p></li>
</ul>
<ul>
<li><strong><code>lr</code></strong> : <em><code>&lt;class 'float'&gt;</code></em>, <em>optional</em>   <p>If None, finds a new learning rate and uses suggestion_method</p></li>
</ul>
<ul>
<li><strong><code>strategy</code></strong> : <em><code>&lt;class 'fastcore.basics.Strategy'&gt;</code></em>, <em>optional</em>  <p>A fitting method</p></li>
</ul>
<ul>
<li><strong><code>callbacks</code></strong> : <em><code>&lt;class 'list'&gt;</code></em>, <em>optional</em> <p>Extra fastai Callbacks</p></li>
</ul>
<ul>
<li><strong><code>kwargs</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can pass in a number of epochs, a learning rate, a strategy, and additional fastai callbacks to call.</p>
<p>Valid strategies live in the <code>Strategy</code> namespace class, and consist of:</p>
<ul>
<li>OneCycle (Also called the <a href="https://docs.fast.ai/callback.schedule.html#Learner.fit_one_cycle">One-Cycle Policy</a>)</li>
<li><a href="https://docs.fast.ai/callback.schedule.html#Learner.fit_flat_cos">CosineAnnealing</a></li>
<li><a href="https://docs.fast.ai/callback.schedule.html#Learner.fit_sgdr">SGDR</a></li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">Strategy</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this tutorial we will train with the One-Cycle policy, as currently it is one of the best schedulers to use.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span><span class="o">.</span><span class="n">tune</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="n">Strategy</span><span class="o">.</span><span class="n">OneCycle</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>perplexity</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>3.907161</td>
      <td>3.809843</td>
      <td>45.143364</td>
      <td>31:15</td>
    </tr>
    <tr>
      <td>1</td>
      <td>3.814265</td>
      <td>3.767976</td>
      <td>43.292336</td>
      <td>31:22</td>
    </tr>
    <tr>
      <td>2</td>
      <td>3.766881</td>
      <td>3.760747</td>
      <td>42.980507</td>
      <td>31:02</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Saving-Model">Saving Model<a class="anchor-link" href="#Saving-Model"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now that we have a trained model, let's save those weights away.</p>
<p>Calling <code>tuner.save</code> will save both the model and the tokenizer in the same format as how HuggingFace does:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="AdaptiveTuner.save" class="doc_header"><code>AdaptiveTuner.save</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/core.py#L397" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>AdaptiveTuner.save</code>(<strong><code>save_directory</code></strong>)</p>
</blockquote>
<p>Save a pretrained model to a <code>save_directory</code></p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>save_directory</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em>  <p>A folder to save our model to</p></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;good_model&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&#39;good_model&#39;</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Performing-Inference">Performing Inference<a class="anchor-link" href="#Performing-Inference"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There are two ways to get predictions, the first is with the <code>.predict</code> method in our <code>tuner</code>. This is great for if you just finished training and want to see how your model performs on some new data!
The other method is with AdaptNLP's inference API, which we will show afterwards</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="In-Tuner">In Tuner<a class="anchor-link" href="#In-Tuner"> </a></h3><p>First let's write a sentence to test with</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sentence</span> <span class="o">=</span> <span class="s2">&quot;Hugh Jackman is a terrible&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And then predict with it:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="LanguageModelTuner.predict" class="doc_header"><code>LanguageModelTuner.predict</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/language_model.py#L293" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>LanguageModelTuner.predict</code>(<strong><code>text</code></strong>:<code>Union</code>[<code>List</code>[<code>str</code>], <code>str</code>], <strong><code>bs</code></strong>:<code>int</code>=<em><code>64</code></em>, <strong><code>num_tokens_to_produce</code></strong>:<code>int</code>=<em><code>50</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Predict some <code>text</code> for sequence classification with the currently loaded model</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>text</code></strong> : <em><code>typing.Union[typing.List[str], str]</code></em> <p>Some text or list of texts to do inference with</p></li>
</ul>
<ul>
<li><strong><code>bs</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em> <p>A batch size to use for multiple texts</p></li>
</ul>
<ul>
<li><strong><code>num_tokens_to_produce</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em>  <p>Number of tokens to generate</p></li>
</ul>
<ul>
<li><strong><code>kwargs</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">num_tokens_to_produce</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

    <div>
        <style>
            /* Turns off some styling */
            progress {
                /* gets rid of default border in Firefox and Opera. */
                border: none;
                /* Needs to be in here for Safari polyfill so background images work as expected. */
                background-size: auto;
            }
            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
                background: #F44336;
            }
        </style>
      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>
      100.00% [1/1 00:00<00:00]
    </div>
    
</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;generated_text&#39;: [&#34;Hugh Jackman is a terrible actor, and I&#39;m not sure if he&#39;s a good actor&#34;]}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="With-the-Inference-API">With the Inference API<a class="anchor-link" href="#With-the-Inference-API"> </a></h3><p>Next we will use the <a href="/adaptnlp/text_generation.html#EasyTextGenerator"><code>EasyTextGenerator</code></a> class, which AdaptNLP offers:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">EasyTextGenerator</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We simply construct the class:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">classifier</span> <span class="o">=</span> <span class="n">EasyTextGenerator</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And call the <code>tag_text</code> method, passing in the sentence, the location of our saved model, and some names for our classes:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">classifier</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
    <span class="n">sentence</span><span class="p">,</span>
    <span class="n">model_name_or_path</span><span class="o">=</span><span class="s1">&#39;good_model&#39;</span><span class="p">,</span>
    <span class="n">num_tokens_to_produce</span><span class="o">=</span><span class="mi">13</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

    <div>
        <style>
            /* Turns off some styling */
            progress {
                /* gets rid of default border in Firefox and Opera. */
                border: none;
                /* Needs to be in here for Safari polyfill so background images work as expected. */
                background-size: auto;
            }
            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
                background: #F44336;
            }
        </style>
      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>
      100.00% [1/1 00:00<00:00]
    </div>
    
</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;generated_text&#39;: [&#34;Hugh Jackman is a terrible actor, and I&#39;m not sure if he&#39;s a good actor&#34;]}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And we got the exact same output!</p>

</div>
</div>
</div>
</div>
 

