---

title: Tutorial - Sequence Classification


keywords: fastai
sidebar: home_sidebar

summary: "Performing Sequence Classification with AdaptNLP"
description: "Performing Sequence Classification with AdaptNLP"
nb_path: "nbs/06a_tutorial.easy_sequence_classifier.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/06a_tutorial.easy_sequence_classifier.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Sequence Classification (or Text Classification) is the NLP task of predicting a label for a sequence of words.</p>
<p>For example, a string of <code>That movie was terrible because the acting was bad</code> could be tagged with a label of <code>negative</code>. A string of <code>That movie was great because the acting was good</code> could be tagged with a label of <code>positive</code>.</p>
<p>A model that can predict sentiment from text is called a sentiment classifier, which is an example of a sequence classification model.</p>
<p>Below, we'll walk through how we can use AdaptNLP's EasySequenceClassification module to easily do the following:</p>
<ol>
<li>Load pre-trained models and tag data using mini-batched inference</li>
<li>Train and fine-tune a pre-trained model on your own dataset</li>
<li>Evaluate your model</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Loading-Pretrained-Models-and-Tag-Data-using-Mini-Batched-Inference">Loading Pretrained Models and Tag Data using Mini-Batched Inference<a class="anchor-link" href="#Loading-Pretrained-Models-and-Tag-Data-using-Mini-Batched-Inference"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We'll first get started by importing the EasySequenceClassifier class from AdaptNLP and instantiating the
<a href="/adaptnlp/sequence_classification.html#EasySequenceClassifier"><code>EasySequenceClassifier</code></a> class object.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">EasySequenceClassifier</span>
<span class="kn">from</span> <span class="nn">pprint</span> <span class="kn">import</span> <span class="n">pprint</span>

<span class="n">classifier</span> <span class="o">=</span> <span class="n">EasySequenceClassifier</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>With this class we can dynamically load models to run on inference.</p>
<p>Let's use the <a href="/adaptnlp/model_hub.html#HFModelHub"><code>HFModelHub</code></a> to search for some pre-trained sequence classification models to use:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">HFModelHub</span>
<span class="n">hub</span> <span class="o">=</span> <span class="n">HFModelHub</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can either seach by task or by model name. Below is an example of the associated models HuggingFace has come out with:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hub</span><span class="o">.</span><span class="n">search_model_by_task</span><span class="p">(</span><span class="s1">&#39;text-classification&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[Model Name: distilbert-base-uncased-finetuned-sst-2-english, Tasks: [text-classification],
 Model Name: roberta-base-openai-detector, Tasks: [text-classification],
 Model Name: roberta-large-mnli, Tasks: [text-classification],
 Model Name: roberta-large-openai-detector, Tasks: [text-classification]]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For this example though we will tag some text with a model that <a href="https://www.nlp.town/">NLP Town</a> has trained called <code>nlptown/bert-base-multilingual-uncased-sentiment</code>. Let's find it in the model hub:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">hub</span><span class="o">.</span><span class="n">search_model_by_name</span><span class="p">(</span><span class="s1">&#39;nlptown/bert-base&#39;</span><span class="p">,</span> <span class="n">user_uploaded</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">];</span> <span class="n">model</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Model Name: nlptown/bert-base-multilingual-uncased-sentiment, Tasks: [text-classification]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This is a multi-lingual model that predicts how many stars (1-5) a text review has given a product. More information can be found via. the Transformers model card <a href="https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment">here</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next we can perform some inference. First let's write some example text:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">example_text</span> <span class="o">=</span> <span class="s2">&quot;This didn&#39;t work at all&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Then we can tell our classifier to tag some text with <code>tag_text</code>:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sentences</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">tag_text</span><span class="p">(</span>
    <span class="n">text</span><span class="o">=</span><span class="n">example_text</span><span class="p">,</span>
    <span class="n">model_name_or_path</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">mini_batch_size</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>2021-05-31 16:09:42,794 loading file nlptown/bert-base-multilingual-uncased-sentiment
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/opt/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2104: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding=&#39;longest&#39;` to pad to the longest sequence in the batch, or use `padding=&#39;max_length&#39;` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now let's look at our outputs:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tag Score Outputs:

Sentences: [&#34;This did n&#39;t work at all&#34;]

Classes: [&#39;1 star&#39;]

Probabilities: 
	tensor([[8.4212e-01, 1.3793e-01, 1.8024e-02, 1.2419e-03, 6.8153e-04]])
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It's easy to pass in multiple sentences at once as well (in an array). Let's try that now:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">multiple_text</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;This didn&#39;t work well at all.&quot;</span><span class="p">,</span>
                 <span class="s2">&quot;I really liked it.&quot;</span><span class="p">,</span>
                 <span class="s2">&quot;It was really useful.&quot;</span><span class="p">,</span>
                 <span class="s2">&quot;It broke after I bought it.&quot;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We'll pass it into the <code>classifier</code> just like before:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sentences</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">tag_text</span><span class="p">(</span>
    <span class="n">text</span><span class="o">=</span><span class="n">multiple_text</span><span class="p">,</span>
    <span class="n">model_name_or_path</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">mini_batch_size</span><span class="o">=</span><span class="mi">2</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And we can check the outputs again:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tag Score Outputs:

Sentences: [&#34;This did n&#39;t work well at all .&#34;, &#39;I really liked it .&#39;, &#39;It was really useful .&#39;, &#39;It broke after I bought it .&#39;]

Classes: [&#39;1 star&#39;, &#39;4 stars&#39;, &#39;5 stars&#39;, &#39;1 star&#39;]

Probabilities: 
	tensor([[6.2198e-01, 3.3563e-01, 4.0320e-02, 1.5827e-03, 4.8790e-04],
        [3.2305e-03, 4.7872e-03, 5.4017e-02, 4.8129e-01, 4.5668e-01],
        [5.9679e-03, 9.2630e-03, 7.0121e-02, 4.1363e-01, 5.0102e-01],
        [4.4894e-01, 3.9348e-01, 1.4158e-01, 1.2110e-02, 3.8937e-03]])
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include note.html content='The output is going to be a probility distribution of what the text should be tagged. If you&#8217;re running this on a GPU, you can specify the <code>mini_batch_size</code> parameter to run mini-batch inference against your data for faster run time.' %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You can set <code>model_name_or_path</code> to any of Transformer's or Flair's pre-trained sequence classification models.</p>
<p>Let's tag some text with another model, specifically Oliver Guhr's German sentiment model called <code>oliverguhr/german-sentiment-bert</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>First we'll write some german text:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">german_text</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Das hat überhaupt nicht gut funktioniert.&quot;</span><span class="p">,</span>
               <span class="s2">&quot;Ich mochte es wirklich.&quot;</span><span class="p">,</span>
               <span class="s2">&quot;Es war wirklich nützlich.&quot;</span><span class="p">,</span>
               <span class="s2">&quot;Es ist kaputt gegangen, nachdem ich es gekauft habe.&quot;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And then tag it:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sentences</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">tag_text</span><span class="p">(</span>
    <span class="n">german_text</span><span class="p">,</span>
    <span class="n">model_name_or_path</span><span class="o">=</span><span class="s2">&quot;oliverguhr/german-sentiment-bert&quot;</span><span class="p">,</span>
    <span class="n">mini_batch_size</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include note.html content='As seen here, you can either search for a model through the various <code>ModelHub</code> classes, or you can directly pass in the string to the model you want' %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's look at the output:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tag Score Outputs:

Sentences: [&#39;Das hat überhaupt nicht gut funktioniert .&#39;, &#39;Ich mochte es wirklich .&#39;, &#39;Es war wirklich nützlich .&#39;, &#39;Es ist kaputt gegangen , nachdem ich es gekauft habe .&#39;]

Classes: [&#39;negative&#39;, &#39;positive&#39;, &#39;positive&#39;, &#39;negative&#39;]

Probabilities: 
	tensor([[8.2706e-04, 9.9915e-01, 2.7373e-05],
        [7.0231e-01, 2.0294e-01, 9.4746e-02],
        [9.8132e-01, 1.8442e-02, 2.3914e-04],
        [4.2462e-03, 9.9566e-01, 9.4817e-05]])
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Don't forget you can still quickly run inference with the multi-lingual review sentiment model you loaded in earlier (memory permitting)! Just change the <code>model_name_or_path</code> param to the model you used before.</p>

</div>
</div>
</div>
</div>
 

