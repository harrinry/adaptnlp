---

title: Tutorial&#58; Fine-Tuning a Language Model on CSV Files with IMDB


keywords: fastai
sidebar: home_sidebar

summary: "Tuning a base Language model on the IMDB dataset"
description: "Tuning a base Language model on the IMDB dataset"
nb_path: "nbs/training_api_tutorials/language_model/language_model_from_csv.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/training_api_tutorials/language_model/language_model_from_csv.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Introduction">Introduction<a class="anchor-link" href="#Introduction"> </a></h2><p>In this tutorial we will be showing an end-to-end example of fine-tuning a Transformer language model on a custom dataset in CSV file format.</p>
<p>By the end of this you should be able to:</p>
<ol>
<li>Build a dataset with the <a href="/adaptnlp/training.language_model.html#LanguageModelDatasets"><code>LanguageModelDatasets</code></a> class, and their DataLoaders</li>
<li>Build a <a href="/adaptnlp/training.language_model.html#LanguageModelTuner"><code>LanguageModelTuner</code></a> quickly, find a good learning rate, and train with the One-Cycle Policy</li>
<li>Save that model away, to be used with deployment or other HuggingFace libraries</li>
<li>Apply inference using both the <code>Tuner</code> available function as well as with the <a href="/adaptnlp/text_generation.html#EasyTextGenerator"><code>EasyTextGenerator</code></a> class within AdaptNLP</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Installing-the-Library">Installing the Library<a class="anchor-link" href="#Installing-the-Library"> </a></h2><p>This tutorial utilizies the latest AdaptNLP version, as well as parts of the <code>fastai</code> library. Please run the below code to install them:</p>
<div class="highlight"><pre><span></span><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">adaptnlp</span> <span class="o">-</span><span class="n">U</span>
</pre></div>
<p>(or <code>pip3</code>)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Getting-the-Dataset">Getting the Dataset<a class="anchor-link" href="#Getting-the-Dataset"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>First we need a dataset. We will use the <code>fastai</code> library to download the <code>IMDB_SAMPLE</code> dataset, a subset of IMDB Movie Reviews.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">fastai.data.external</span> <span class="kn">import</span> <span class="n">URLs</span><span class="p">,</span> <span class="n">untar_data</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>URLs</code> holds a namespace of many data endpoints, and <code>untar_data</code> is a function that can download and extract any data from a given URL.</p>
<p>Combining both, we can download the data:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data_path</span> <span class="o">=</span> <span class="n">untar_data</span><span class="p">(</span><span class="n">URLs</span><span class="o">.</span><span class="n">IMDB_SAMPLE</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If we look at what was downloaded, we will find a <code>texts.csv</code> file:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data_path</span><span class="o">.</span><span class="n">ls</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(#1) [Path(&#39;/root/.fastai/data/imdb_sample/texts.csv&#39;)]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This is our data we want to use. This CSV is formatted with a table of columns with <code>label</code>, <code>text</code>, and <code>is_valid</code> dictating whether it is part of the validation set or not.</p>
<p>Now that we have the dataset, and we know the format it is in, let's pick a viable model to train with</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Picking-a-Model-with-the-Hub">Picking a Model with the Hub<a class="anchor-link" href="#Picking-a-Model-with-the-Hub"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>AdaptNLP has a <a href="/adaptnlp/model_hub.html#HFModelHub"><code>HFModelHub</code></a> class that allows you to communicate with the HuggingFace Hub and pick a model from it, as well as a namespace <code>HF_TASKS</code> class with a list of valid tasks we can search by.</p>
<p>Let's try and find one suitable for sequence classification.</p>
<p>First we need to import the class and generate an instance of it:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">HFModelHub</span><span class="p">,</span> <span class="n">HF_TASKS</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hub</span> <span class="o">=</span> <span class="n">HFModelHub</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next we can search for a model:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">models</span> <span class="o">=</span> <span class="n">hub</span><span class="o">.</span><span class="n">search_model_by_task</span><span class="p">(</span><span class="n">HF_TASKS</span><span class="o">.</span><span class="n">TEXT_GENERATION</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's look at a few:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">models</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[Model Name: distilgpt2, Tasks: [text-generation],
 Model Name: gpt2-large, Tasks: [text-generation],
 Model Name: gpt2-medium, Tasks: [text-generation],
 Model Name: gpt2-xl, Tasks: [text-generation],
 Model Name: gpt2, Tasks: [text-generation],
 Model Name: openai-gpt, Tasks: [text-generation],
 Model Name: transfo-xl-wt103, Tasks: [text-generation],
 Model Name: xlnet-base-cased, Tasks: [text-generation],
 Model Name: xlnet-large-cased, Tasks: [text-generation]]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>These are models specifically tagged with the <code>text-generation</code> tag, so you may not see a few models you would expect such as <code>bert_base_cased</code>.</p>
<p>We'll use that first model, <code>distilgpt2</code>:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Model Name: distilgpt2, Tasks: [text-generation]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now that we have picked a model, let's use the data API to prepare our data</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include note.html content='It should be mentioned that this is optional, you can always just pass in the string name of a model such as "bert-base-cased"' %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Building-TaskDatasets-with-LanguageModelDatasets">Building <a href="/adaptnlp/training.core.html#TaskDatasets"><code>TaskDatasets</code></a> with <a href="/adaptnlp/training.language_model.html#LanguageModelDatasets"><code>LanguageModelDatasets</code></a><a class="anchor-link" href="#Building-TaskDatasets-with-LanguageModelDatasets"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Each task has a high-level data wrapper around the <a href="/adaptnlp/training.core.html#TaskDatasets"><code>TaskDatasets</code></a> class. In our case this is the <a href="/adaptnlp/training.language_model.html#LanguageModelDatasets"><code>LanguageModelDatasets</code></a> class:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">LanguageModelDatasets</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There are multiple different constructors for the <a href="/adaptnlp/training.language_model.html#LanguageModelDatasets"><code>LanguageModelDatasets</code></a> class, and you should never call the main constructor directly.</p>
<p>We will be using <code>from_csvs</code>, which wraps around the <code>from_dfs</code> constructor:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="LanguageModelDatasets.from_csvs" class="doc_header"><code>LanguageModelDatasets.from_csvs</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/language_model.py#L123" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>LanguageModelDatasets.from_csvs</code>(<strong><code>train_csv</code></strong>:<code>Path</code>, <strong><code>text_col</code></strong>:<code>str</code>, <strong><code>tokenizer_name</code></strong>:<code>str</code>, <strong><code>block_size</code></strong>:<code>int</code>=<em><code>128</code></em>, <strong><code>masked_lm</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>valid_csv</code></strong>:<code>Path</code>=<em><code>None</code></em>, <strong><code>split_func</code></strong>:<code>callable</code>=<em><code>None</code></em>, <strong><code>split_pct</code></strong>:<code>float</code>=<em><code>0.1</code></em>, <strong><code>tokenize_kwargs</code></strong>:<code>dict</code>=<em><code>{}</code></em>, <strong><code>auto_kwargs</code></strong>:<code>dict</code>=<em><code>{}</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Builds <a href="/adaptnlp/training.language_model.html#LanguageModelDatasets"><code>LanguageModelDatasets</code></a> from a single csv or set of csvs. A convience constructor for <code>from_dfs</code></p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>train_csv</code></strong> : <em><code>&lt;class 'pathlib.Path'&gt;</code></em> <p>A training csv file</p></li>
</ul>
<ul>
<li><strong><code>text_col</code></strong> : <em><code>&lt;class 'str'&gt;</code></em>   <p>The name of the text column</p></li>
</ul>
<ul>
<li><strong><code>tokenizer_name</code></strong> : <em><code>&lt;class 'str'&gt;</code></em> <p>The name of the tokenizer</p></li>
</ul>
<ul>
<li><strong><code>block_size</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em> <p>The size of each block</p></li>
</ul>
<ul>
<li><strong><code>masked_lm</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em> <p>Whether the language model is a MLM</p></li>
</ul>
<ul>
<li><strong><code>valid_csv</code></strong> : <em><code>&lt;class 'pathlib.Path'&gt;</code></em>, <em>optional</em> <p>An optional validation csv</p></li>
</ul>
<ul>
<li><strong><code>split_func</code></strong> : <em><code>&lt;built-in function callable&gt;</code></em>, <em>optional</em>  <p>Optionally a splitting function similar to RandomSplitter</p></li>
</ul>
<ul>
<li><strong><code>split_pct</code></strong> : <em><code>&lt;class 'float'&gt;</code></em>, <em>optional</em>    <p>What % to split the df between training and validation</p></li>
</ul>
<ul>
<li><strong><code>tokenize_kwargs</code></strong> : <em><code>&lt;class 'dict'&gt;</code></em>, <em>optional</em>   <p>kwargs for the tokenize function</p></li>
</ul>
<ul>
<li><strong><code>auto_kwargs</code></strong> : <em><code>&lt;class 'dict'&gt;</code></em>, <em>optional</em>   <p>kwargs for the AutoTokenizer.from_pretrained constructor</p></li>
</ul>
<ul>
<li><strong><code>kwargs</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Anything you would normally pass to the tokenizer call (such as <code>max_length</code>, <code>padding</code>) should go in <code>tokenize_kwargs</code>, and anything going to the <code>AutoTokenizer.from_pretrained</code> constructor should be passed to the <code>auto_kwargs</code>.</p>
<p>In our case we only have a <code>train_csv</code> and we have a tokenizer name. We also want to split 90%/10% (which is the default)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Also, we will set a block_size of 128, and it is <em>not</em> a masked language model:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dsets</span> <span class="o">=</span> <span class="n">LanguageModelDatasets</span><span class="o">.</span><span class="n">from_csvs</span><span class="p">(</span>
    <span class="n">train_csv</span><span class="o">=</span><span class="n">data_path</span><span class="o">/</span><span class="s1">&#39;texts.csv&#39;</span><span class="p">,</span>
    <span class="n">text_col</span><span class="o">=</span><span class="s1">&#39;text&#39;</span><span class="p">,</span>
    <span class="n">tokenizer_name</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
    <span class="n">block_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
    <span class="n">masked_lm</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>No value for `max_length` set, automatically adjusting to the size of the model and including truncation
Sequence length set to: 1024




</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include note.html content='If you have a training and validation CSV, simply pass in the validation CSV path as <code>valid_csv=path/to/validation_dataset.csv</code> and do not pass in any <code>split_func</code> or <code>split_pct</code>. Everything else is the exact same' %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And finally turn it into some <a href="/adaptnlp/training.core.html#AdaptiveDataLoaders"><code>AdaptiveDataLoaders</code></a>.</p>
<p>These are just fastai's <code>DataLoaders</code> class, but it overrides a few functions to have it work nicely with HuggingFace's <code>Dataset</code> class</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="LanguageModelDatasets.dataloaders" class="doc_header"><code>LanguageModelDatasets.dataloaders</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/language_model.py#L202" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>LanguageModelDatasets.dataloaders</code>(<strong><code>batch_size</code></strong>=<em><code>8</code></em>, <strong><code>shuffle_train</code></strong>=<em><code>True</code></em>, <strong><code>collate_fn</code></strong>=<em><code>default_data_collator</code></em>, <strong><code>mlm_probability</code></strong>:<code>float</code>=<em><code>0.15</code></em>, <strong><code>path</code></strong>=<em><code>'.'</code></em>, <strong><code>device</code></strong>=<em><code>None</code></em>)</p>
</blockquote>
<p>Build DataLoaders from <code>self</code></p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>batch_size</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em> <p>A batch size</p></li>
</ul>
<ul>
<li><strong><code>shuffle_train</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em> <p>Whether to shuffle the training dataset</p></li>
</ul>
<ul>
<li><strong><code>collate_fn</code></strong> : <em><code>&lt;class 'function'&gt;</code></em>, <em>optional</em>    <p>A custom collation function</p></li>
</ul>
<ul>
<li><strong><code>mlm_probability</code></strong> : <em><code>&lt;class 'float'&gt;</code></em>, <em>optional</em>  <p>Token masking probablity for Masked Language Models</p></li>
</ul>
<ul>
<li><p><strong><code>path</code></strong> : <em><code>&lt;class 'str'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>device</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em></p>
</li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally, let's view a batch of data with the <code>show_batch</code> function:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span><span class="o">.</span><span class="n">show_batch</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Input</th>
      <th>Labels</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2".&lt;br /&gt;&lt;br /&gt;It starts out trying to borrow its comic relief style of Star Wars, but mercifully (since the humor doesn't work) gives up on comedy and plays it serious. In that sense, it's superior to the Star Wars franchise, which started with a clever sense of humor, and eventually deteriorated to Jar-Jar's annoying silliness.&lt;br /&gt;&lt;br /&gt;The agricultural details were apparently drawn by someone who had never seen a farm. The harvester was driving through the unharvested middle of a field, dumping silage onto unharvested crops, rather than working from one side to the other and dumping the silage onto already-harvested rows or into a truck. Corn (maize) was pouring out the grain chute, but the farm lands were drawn like a wheat field.&lt;br /&gt;&lt;br /&gt;When it was time for Kim's father had to face his fate, there wasn't any dramatic weight to the scene. That could have been partly the fault of the English-language voice actor, but the drawings didn't show much weight either. Kim's reactions in that scene were similarly unconvincing.&lt;br /&gt;&lt;br /&gt;Similarly, when a character named Henderson was killed, Chris showed very little reaction, even though they were apparently supposed to have been close. (Henderson's death is no spoiler; his name isn't revealed until his death scene.) She seems to promptly forget him. Someone's expression of sympathy shows more feeling than she does. I think the voice actor deserves most of the blame in that case; there's at least a hint of feeling in the drawings of Chris.&lt;br /&gt;&lt;br /&gt;On several occasions, villains fail to accomplish their orders. A villain leader often punishes those failures with miserable deaths. I can't say whether that's lifted from Star Wars, or if that comes from an earlier source -- possibly the Lensman books.&lt;br /&gt;&lt;br /&gt;There's a scene where a space ship crash-lands. As it plunges toward the ground, parts are break off the ship. But so many pieces are fall off that there should be nothing left of it by the time it lands.&lt;br /&gt;&lt;br /&gt;While in most cases Chris seems like a competent, tough space hero, there's a scene where she shrieks like an incompetent damsel in distress. Someone tough enough to get over Henderson's death so quickly should at least be able to shout, "help, it's got me and I can't</td>
      <td>2".&lt;br /&gt;&lt;br /&gt;It starts out trying to borrow its comic relief style of Star Wars, but mercifully (since the humor doesn't work) gives up on comedy and plays it serious. In that sense, it's superior to the Star Wars franchise, which started with a clever sense of humor, and eventually deteriorated to Jar-Jar's annoying silliness.&lt;br /&gt;&lt;br /&gt;The agricultural details were apparently drawn by someone who had never seen a farm. The harvester was driving through the unharvested middle of a field, dumping silage onto unharvested crops, rather than working from one side to the other and dumping the silage onto already-harvested rows or into a truck. Corn (maize) was pouring out the grain chute, but the farm lands were drawn like a wheat field.&lt;br /&gt;&lt;br /&gt;When it was time for Kim's father had to face his fate, there wasn't any dramatic weight to the scene. That could have been partly the fault of the English-language voice actor, but the drawings didn't show much weight either. Kim's reactions in that scene were similarly unconvincing.&lt;br /&gt;&lt;br /&gt;Similarly, when a character named Henderson was killed, Chris showed very little reaction, even though they were apparently supposed to have been close. (Henderson's death is no spoiler; his name isn't revealed until his death scene.) She seems to promptly forget him. Someone's expression of sympathy shows more feeling than she does. I think the voice actor deserves most of the blame in that case; there's at least a hint of feeling in the drawings of Chris.&lt;br /&gt;&lt;br /&gt;On several occasions, villains fail to accomplish their orders. A villain leader often punishes those failures with miserable deaths. I can't say whether that's lifted from Star Wars, or if that comes from an earlier source -- possibly the Lensman books.&lt;br /&gt;&lt;br /&gt;There's a scene where a space ship crash-lands. As it plunges toward the ground, parts are break off the ship. But so many pieces are fall off that there should be nothing left of it by the time it lands.&lt;br /&gt;&lt;br /&gt;While in most cases Chris seems like a competent, tough space hero, there's a scene where she shrieks like an incompetent damsel in distress. Someone tough enough to get over Henderson's death so quickly should at least be able to shout, "help, it's got me and I can't</td>
    </tr>
    <tr>
      <th>1</th>
      <td>a script that gives the heroine some intelligence and agency, and an actress who can convey those qualities.&lt;br /&gt;&lt;br /&gt;Hugh Jackman is similarly cheated by the script. Allen apparently can't stand it that Jackman is so stunningly good looking and young, and so he gives Jackman nothing to say or do. Like Johansson, he is used merely for his good looks. This is a shame, because, as Jackman has shown in any number of productions, from "Oklahoma" to "X Men," he CAN act.&lt;br /&gt;&lt;br /&gt;Here's the big plot twist -- Jackman, suave, charming English Lord, really is a killer. So, though the movie says it is all about letting someone else, other than Allen, get the girl, she doesn't get anyone. Jackman, the man she's been making love to, is a man who murdered a prostitute. Nice, Woody. Nice way to punish your heroine for being beyond your grasp.&lt;br /&gt;&lt;br /&gt;In a passive aggressive touch, Allen deprives his heroine of his own presence, as well, killing off his character, the magician, leaving Scarlett Johansson all alone at the end of the film.&lt;br /&gt;&lt;br /&gt;A final note: at my screening, not a single audience member laughed at any point during the film. Always a bad sign when a film is advertised as a comedy.The movie is plain bad. Simply awful. The string of bad movies from Bollywood has no end! They must be running out of excuses for making such awful movies (or not).&lt;br /&gt;&lt;br /&gt;The problem seems to be with mainly the directors. This movie has 2 good actors who have proved in the past that the have the ability to deliver great performance...but they were directed so poorly. The poor script did not help either.&lt;br /&gt;&lt;br /&gt;This movie has plenty of ridiculous moments and very bad editing in the first half. For instance :&lt;br /&gt;&lt;br /&gt;After his 1st big concert, Ajay Devgan, meets up with Om Puri (from whom he ran away some 30 years ago and talked to again) and all Om Puri finds to say is to beware of his friendship with Salman!!! What a load of crap. Seriously. Not to mention the baaad soundtrack. Whatever happened to Shankar Ehsaan Loy?&lt;br /&gt;&lt;br /&gt;Ajay Devgun is total miscast for portraying a rockstar.&lt;br /&gt;&lt;br /&gt;Only saving grace</td>
      <td>a script that gives the heroine some intelligence and agency, and an actress who can convey those qualities.&lt;br /&gt;&lt;br /&gt;Hugh Jackman is similarly cheated by the script. Allen apparently can't stand it that Jackman is so stunningly good looking and young, and so he gives Jackman nothing to say or do. Like Johansson, he is used merely for his good looks. This is a shame, because, as Jackman has shown in any number of productions, from "Oklahoma" to "X Men," he CAN act.&lt;br /&gt;&lt;br /&gt;Here's the big plot twist -- Jackman, suave, charming English Lord, really is a killer. So, though the movie says it is all about letting someone else, other than Allen, get the girl, she doesn't get anyone. Jackman, the man she's been making love to, is a man who murdered a prostitute. Nice, Woody. Nice way to punish your heroine for being beyond your grasp.&lt;br /&gt;&lt;br /&gt;In a passive aggressive touch, Allen deprives his heroine of his own presence, as well, killing off his character, the magician, leaving Scarlett Johansson all alone at the end of the film.&lt;br /&gt;&lt;br /&gt;A final note: at my screening, not a single audience member laughed at any point during the film. Always a bad sign when a film is advertised as a comedy.The movie is plain bad. Simply awful. The string of bad movies from Bollywood has no end! They must be running out of excuses for making such awful movies (or not).&lt;br /&gt;&lt;br /&gt;The problem seems to be with mainly the directors. This movie has 2 good actors who have proved in the past that the have the ability to deliver great performance...but they were directed so poorly. The poor script did not help either.&lt;br /&gt;&lt;br /&gt;This movie has plenty of ridiculous moments and very bad editing in the first half. For instance :&lt;br /&gt;&lt;br /&gt;After his 1st big concert, Ajay Devgan, meets up with Om Puri (from whom he ran away some 30 years ago and talked to again) and all Om Puri finds to say is to beware of his friendship with Salman!!! What a load of crap. Seriously. Not to mention the baaad soundtrack. Whatever happened to Shankar Ehsaan Loy?&lt;br /&gt;&lt;br /&gt;Ajay Devgun is total miscast for portraying a rockstar.&lt;br /&gt;&lt;br /&gt;Only saving grace</td>
    </tr>
    <tr>
      <th>2</th>
      <td>to entice Robert into sex. Robert wants none of it, and puts on a jazz record. Ellen turns on the radio; Robert turns up the music; Ellen turns on the TV; Robert turns on another TV. Cacophony ensues. Ellen goes up on the roof, Robert joins her. Ellen confesses that she needs to experience more men, men other than Robert. Robert says that he too needs to experience men.&lt;br /&gt;&lt;br /&gt;We next follow Robert as he visits an artist, Martin, played by Steve Buscemi. I wish Buscemi could have more roles like this, where he is a sexy, smart, totally desirable guy. Robert praises Martin's work, much more than it deserves, promises to get it into a show. Martin is excited, until it turns out that Robert is speaking out of his groin, it is all a mating dance. Robert tries to kiss Martin, on the lips, and Martin pulls back, saying that he is not gay. Robert asserts that he's not gay either, Martin scoffs. Both admit that the artworks are bad. Robert is about to leave, when Martin allows Robert to kiss him. They make out, and Robert goes down on Martin.&lt;br /&gt;&lt;br /&gt;Next we follow Martin, as he prepares for an art show at a Manhattan gallery. He is smitten by the receptionist, Anna, played by Rosario Dawson. (I had to cut some of this review to keep it under 1000 words)... and they make love to each other.&lt;br /&gt;&lt;br /&gt;We next follow Anna, who is sitting at a lunch stand. Her boyfriend, Nick (Adrian Grenier), enters, bearing flowers. She is cold toward him; he tries to figure out why. He coaxes out of her the information that she has had sex with someone while he was in San Francisco. She coaxes out of him the fact that he has stayed with his ex-gf while in San Francisco, and had sex with her. The latter revelation turns out to be a lie. The two of them make out in the luncheonette, but she decides that they must break up. Nick is heartbroken.&lt;br /&gt;&lt;br /&gt;And we follow Nick, who confesses his troubles to an older woman who he meets on a park bench, Joey (Carol Kane). Joey is sort of weird and child-like, but is a good audience for Nick, who needs a sympathetic ear. The two of them go to Coney Island</td>
      <td>to entice Robert into sex. Robert wants none of it, and puts on a jazz record. Ellen turns on the radio; Robert turns up the music; Ellen turns on the TV; Robert turns on another TV. Cacophony ensues. Ellen goes up on the roof, Robert joins her. Ellen confesses that she needs to experience more men, men other than Robert. Robert says that he too needs to experience men.&lt;br /&gt;&lt;br /&gt;We next follow Robert as he visits an artist, Martin, played by Steve Buscemi. I wish Buscemi could have more roles like this, where he is a sexy, smart, totally desirable guy. Robert praises Martin's work, much more than it deserves, promises to get it into a show. Martin is excited, until it turns out that Robert is speaking out of his groin, it is all a mating dance. Robert tries to kiss Martin, on the lips, and Martin pulls back, saying that he is not gay. Robert asserts that he's not gay either, Martin scoffs. Both admit that the artworks are bad. Robert is about to leave, when Martin allows Robert to kiss him. They make out, and Robert goes down on Martin.&lt;br /&gt;&lt;br /&gt;Next we follow Martin, as he prepares for an art show at a Manhattan gallery. He is smitten by the receptionist, Anna, played by Rosario Dawson. (I had to cut some of this review to keep it under 1000 words)... and they make love to each other.&lt;br /&gt;&lt;br /&gt;We next follow Anna, who is sitting at a lunch stand. Her boyfriend, Nick (Adrian Grenier), enters, bearing flowers. She is cold toward him; he tries to figure out why. He coaxes out of her the information that she has had sex with someone while he was in San Francisco. She coaxes out of him the fact that he has stayed with his ex-gf while in San Francisco, and had sex with her. The latter revelation turns out to be a lie. The two of them make out in the luncheonette, but she decides that they must break up. Nick is heartbroken.&lt;br /&gt;&lt;br /&gt;And we follow Nick, who confesses his troubles to an older woman who he meets on a park bench, Joey (Carol Kane). Joey is sort of weird and child-like, but is a good audience for Nick, who needs a sympathetic ear. The two of them go to Coney Island</td>
    </tr>
    <tr>
      <th>3</th>
      <td>I thought this film was alright; much better than I expected it to be. I was skeptical at first - the idea of a computer virus that can also infect people seemed a little ludicrous to me. But in the end, I thought the film handled the concept well (even if some scenes were a little clichéd).&lt;br /&gt;&lt;br /&gt;The cast was quite good, and the two leads seemed to take their roles very seriously. I couldn't help thinking, though, that Janine Turner is a bit of a Geena Davis look-a-like. Maybe it's just her face or the make-up, hair and clothes she had in this movie but it just kept nagging at the back of my mind the whole time.&lt;br /&gt;&lt;br /&gt;While it's not a'must see' or a great film by any standard, 'Fatal Error' is an entertaining flick that will keep you watching until the end.While I count myself as a fan of the Babylon 5 television series, the original movie that introduced the series was a weak start. Although many of the elements that would later mature and become much more compelling in the series are there, the pace of The Gathering is slow, the makeup somewhat inadequate, and the plot confusing. Worse, the characterization in the premiere episode is poor. Although the ratings chart shows that many fans are willing to overlook these problems, I remember The Gathering almost turned me off off what soon grew into a spectacular series.How unfortunate, to have so many of my "a" list, and good "b" list actors agree to do this movie, but they did, and that is what sucked me into watching it. I had never heard of this movie, but there was Cuba Gooding Jr. right on the DVD cover, and James Woods in the background how bad can it be? In a word Very! This movie starts o.k. has some twists and turns, then just lays an egg. The ending was so weak, it was as if the writer got called away and his 4 year old son sat down at the type writer and hacked out the ending. How ironic a for a movie titled "The end game" to have such a poor one. These are the types of movies that can move "a" list actors to the "b" list in hurry. I hope Cuba Gooding JR, and James Woods don't make a habit of this.A definite no. A resounding NO. This movie is an absolute dud.&lt;br /&gt;&lt;br /&gt;Having</td>
      <td>I thought this film was alright; much better than I expected it to be. I was skeptical at first - the idea of a computer virus that can also infect people seemed a little ludicrous to me. But in the end, I thought the film handled the concept well (even if some scenes were a little clichéd).&lt;br /&gt;&lt;br /&gt;The cast was quite good, and the two leads seemed to take their roles very seriously. I couldn't help thinking, though, that Janine Turner is a bit of a Geena Davis look-a-like. Maybe it's just her face or the make-up, hair and clothes she had in this movie but it just kept nagging at the back of my mind the whole time.&lt;br /&gt;&lt;br /&gt;While it's not a'must see' or a great film by any standard, 'Fatal Error' is an entertaining flick that will keep you watching until the end.While I count myself as a fan of the Babylon 5 television series, the original movie that introduced the series was a weak start. Although many of the elements that would later mature and become much more compelling in the series are there, the pace of The Gathering is slow, the makeup somewhat inadequate, and the plot confusing. Worse, the characterization in the premiere episode is poor. Although the ratings chart shows that many fans are willing to overlook these problems, I remember The Gathering almost turned me off off what soon grew into a spectacular series.How unfortunate, to have so many of my "a" list, and good "b" list actors agree to do this movie, but they did, and that is what sucked me into watching it. I had never heard of this movie, but there was Cuba Gooding Jr. right on the DVD cover, and James Woods in the background how bad can it be? In a word Very! This movie starts o.k. has some twists and turns, then just lays an egg. The ending was so weak, it was as if the writer got called away and his 4 year old son sat down at the type writer and hacked out the ending. How ironic a for a movie titled "The end game" to have such a poor one. These are the types of movies that can move "a" list actors to the "b" list in hurry. I hope Cuba Gooding JR, and James Woods don't make a habit of this.A definite no. A resounding NO. This movie is an absolute dud.&lt;br /&gt;&lt;br /&gt;Having</td>
    </tr>
    <tr>
      <th>4</th>
      <td>&gt;&lt;br /&gt;All in all pretty dull slasher flick that doesn't go anywhere I'd definitely wouldn't recommend it to Slasher fans.From a plot and movement standpoint, this movie was terrible. I found myself looking at the clock in theater hoping it would end and relieved after 80 long minutes that it mercifully did. Basically, five characters appear in the movie, A Son &amp; Father, son's girl friend, and two male characters of the son's age who appear and then disappear without context or explanation. The movie and scenes seemed to suggest homo-eroticism, but nothing ever actually happened to reveal this one way or another. There were a couple of brilliant scenes. At the beginning of the movie, the son's girl friend shows up at a window outside his room and they engage in an odd conversation. The photography and acting lent an incredible seductiveness to the interaction between the two, ending with her admitting to having another man who was "older". End of that story.Watching It Lives By Night makes you wonder, just who in the world greenlit this crap. A newlywed couple go spelunking on their honeymoon, get attacked by bats and the husband starts to run around in his pajamas attacking various people. And where exactly are they? They're in the desert, then they're skiing, then they're in a small town that looks like it has mountains nearby. The town is run by a sheriff who likes to watch and has a personal vendetta against whiny doctor boy. The ski hospital is run by a really groovy guy with a nice thick mustache and the wife looks like Mary Tyler Moore or Marilyn Quayle. There's no dramatic tension and the ending will leave you filled with anger. Special effects and makeup guru Stan Winston did the effects for this movie. I guess you have to start somewhere.I remember I saw this cartoon when I was 6 or 7. My grandfather picked up the video of it for free at the mall. I remember that it really sucked. The plot had no sense. I hated the fox that became Casper's friend. He was so stupid! Casper cried his head off if he couldn't find a friend. So what? Get over it! The only good part and I don't want to sound mean-spirited was when the fox got shot and died at the end. I laughed my head off in payback because this cartoon sucked so much. The bad news is the fox resurrects and becomes a ghost. I wish he</td>
      <td>&gt;&lt;br /&gt;All in all pretty dull slasher flick that doesn't go anywhere I'd definitely wouldn't recommend it to Slasher fans.From a plot and movement standpoint, this movie was terrible. I found myself looking at the clock in theater hoping it would end and relieved after 80 long minutes that it mercifully did. Basically, five characters appear in the movie, A Son &amp; Father, son's girl friend, and two male characters of the son's age who appear and then disappear without context or explanation. The movie and scenes seemed to suggest homo-eroticism, but nothing ever actually happened to reveal this one way or another. There were a couple of brilliant scenes. At the beginning of the movie, the son's girl friend shows up at a window outside his room and they engage in an odd conversation. The photography and acting lent an incredible seductiveness to the interaction between the two, ending with her admitting to having another man who was "older". End of that story.Watching It Lives By Night makes you wonder, just who in the world greenlit this crap. A newlywed couple go spelunking on their honeymoon, get attacked by bats and the husband starts to run around in his pajamas attacking various people. And where exactly are they? They're in the desert, then they're skiing, then they're in a small town that looks like it has mountains nearby. The town is run by a sheriff who likes to watch and has a personal vendetta against whiny doctor boy. The ski hospital is run by a really groovy guy with a nice thick mustache and the wife looks like Mary Tyler Moore or Marilyn Quayle. There's no dramatic tension and the ending will leave you filled with anger. Special effects and makeup guru Stan Winston did the effects for this movie. I guess you have to start somewhere.I remember I saw this cartoon when I was 6 or 7. My grandfather picked up the video of it for free at the mall. I remember that it really sucked. The plot had no sense. I hated the fox that became Casper's friend. He was so stupid! Casper cried his head off if he couldn't find a friend. So what? Get over it! The only good part and I don't want to sound mean-spirited was when the fox got shot and died at the end. I laughed my head off in payback because this cartoon sucked so much. The bad news is the fox resurrects and becomes a ghost. I wish he</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>When training a language model, the input and output are made to be the exact same, so there isn't a shown noticable difference here.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Building-Tuner">Building <code>Tuner</code><a class="anchor-link" href="#Building-Tuner"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next we need to build a compatible <code>Tuner</code> for our problem. These tuners contain good defaults for our problem space, including loss functions and metrics.</p>
<p>First let's import the <a href="/adaptnlp/training.language_model.html#LanguageModelTuner"><code>LanguageModelTuner</code></a> and view it's documentation</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">LanguageModelTuner</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="LanguageModelTuner" class="doc_header"><code>class</code> <code>LanguageModelTuner</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/language_model.py#L228" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>LanguageModelTuner</code>(<strong><code>dls</code></strong>:<code>DataLoaders</code>, <strong><code>model_name</code></strong>, <strong><code>tokenizer</code></strong>=<em><code>None</code></em>, <strong><code>language_model_type</code></strong>:<code>LMType</code>=<em><code>'causal'</code></em>, <strong><code>loss_func</code></strong>=<em><code>CrossEntropyLoss()</code></em>, <strong><code>metrics</code></strong>=<em><code>[&lt;fastai.metrics.Perplexity object at 0x7efbaae870a0&gt;]</code></em>, <strong><code>opt_func</code></strong>=<em><code>Adam</code></em>, <strong><code>additional_cbs</code></strong>=<em><code>None</code></em>, <strong><code>expose_fastai_api</code></strong>=<em><code>False</code></em>, <strong>**<code>kwargs</code></strong>) :: <a href="/adaptnlp/training.core.html#AdaptiveTuner"><code>AdaptiveTuner</code></a></p>
</blockquote>
<p>An <a href="/adaptnlp/training.core.html#AdaptiveTuner"><code>AdaptiveTuner</code></a> with good defaults for Language Model fine-tuning
<strong>Valid kwargs and defaults:</strong></p>
<ul>
<li><code>lr</code>:float = 0.001</li>
<li><code>splitter</code>:function = <code>trainable_params</code></li>
<li><code>cbs</code>:list = None</li>
<li><code>path</code>:Path = None</li>
<li><code>model_dir</code>:Path = 'models'</li>
<li><code>wd</code>:float = None</li>
<li><code>wd_bn_bias</code>:bool = False</li>
<li><code>train_bn</code>:bool = True</li>
<li><code>moms</code>: tuple(float) = (0.95, 0.85, 0.95)</li>
</ul>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>dls</code></strong> : <em><code>&lt;class 'fastai.data.core.DataLoaders'&gt;</code></em>   <p>A set of DataLoaders or AdaptiveDataLoaders</p></li>
</ul>
<ul>
<li><strong><code>model_name</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em>  <p>A HuggingFace model</p></li>
</ul>
<ul>
<li><strong><code>tokenizer</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em> <p>A HuggingFace tokenizer</p></li>
</ul>
<ul>
<li><strong><code>language_model_type</code></strong> : <em><code>&lt;class 'fastcore.basics.LMType'&gt;</code></em>, <em>optional</em> <p>The type of language model to use</p></li>
</ul>
<ul>
<li><strong><code>loss_func</code></strong> : <em><code>&lt;class 'fastai.losses.CrossEntropyLossFlat'&gt;</code></em>, <em>optional</em>   <p>A loss function</p></li>
</ul>
<ul>
<li><strong><code>metrics</code></strong> : <em><code>&lt;class 'list'&gt;</code></em>, <em>optional</em>   <p>Metrics to monitor the training with</p></li>
</ul>
<ul>
<li><strong><code>opt_func</code></strong> : <em><code>&lt;class 'function'&gt;</code></em>, <em>optional</em>  <p>A fastai or torch Optimizer</p></li>
</ul>
<ul>
<li><strong><code>additional_cbs</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em>    <p>Additional Callbacks to have always tied to the Tuner,</p></li>
</ul>
<ul>
<li><strong><code>expose_fastai_api</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em> <p>Whether to expose the fastai API</p></li>
</ul>
<ul>
<li><strong><code>kwargs</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next we'll pass in our <code>DataLoaders</code>, the name of our model, and the tokenizer:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include note.html content='If you are not using the data API (<a href="/adaptnlp/training.core.html#TaskDatasets"><code>TaskDatasets</code></a>, <a href="/adaptnlp/training.sequence_classification.html#SequenceClassificationDatasets"><code>SequenceClassificationDatasets</code></a>, etc), you need to pass in the tokenizer to the constructor as well with <code>tokenizer=tokenizer</code>' %}</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span> <span class="o">=</span> <span class="n">LanguageModelTuner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">dls</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>By default we can see that it used <code>CrossEntropyLoss</code> as our loss function, and <code>Perplexity</code> as our metric</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span><span class="o">.</span><span class="n">loss_func</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>FlattenedLoss of CrossEntropyLoss()</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="p">[</span><span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">tuner</span><span class="o">.</span><span class="n">metrics</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>perplexity
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally we just need to train our model!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Fine-Tuning">Fine-Tuning<a class="anchor-link" href="#Fine-Tuning"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To fine-tune, AdaptNLP's tuner class provides only a few functions to work with. The important ones are the <code>tune</code> and <code>lr_find</code> class.</p>
<p>As the <code>Tuner</code> uses <code>fastai</code> under the hood, <code>lr_find</code> calls fastai's Learning Rate Finder to help us pick a learning rate. Let's do that now:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="AdaptiveTuner.lr_find" class="doc_header"><code>AdaptiveTuner.lr_find</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/core.py#L413" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>AdaptiveTuner.lr_find</code>(<strong><code>start_lr</code></strong>=<em><code>1e-07</code></em>, <strong><code>end_lr</code></strong>=<em><code>10</code></em>, <strong><code>num_it</code></strong>=<em><code>100</code></em>, <strong><code>stop_div</code></strong>=<em><code>True</code></em>, <strong><code>show_plot</code></strong>=<em><code>True</code></em>, <strong><code>suggest_funcs</code></strong>=<em><code>valley</code></em>)</p>
</blockquote>
<p>Runs fastai's <code>LR Finder</code></p>
<p><strong>Parameters:</strong></p>
<ul>
<li><p><strong><code>start_lr</code></strong> : <em><code>&lt;class 'float'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>end_lr</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>num_it</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>stop_div</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>show_plot</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>suggest_funcs</code></strong> : <em><code>&lt;class 'function'&gt;</code></em>, <em>optional</em></p>
</li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/opt/venv/lib/python3.8/site-packages/fastai/callback/schedule.py:270: UserWarning: color is redundantly defined by the &#39;color&#39; keyword argument and the fmt string &#34;ro&#34; (-&gt; color=&#39;r&#39;). The keyword argument will take precedence.
  ax.plot(val, idx, &#39;ro&#39;, label=nm, c=color)
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>SuggestedLRs(valley=6.30957365501672e-05)</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It recommends a learning rate of around 5e-5, so we will use that.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr</span> <span class="o">=</span> <span class="mf">5e-5</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's look at the documentation for <code>tune</code>:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="AdaptiveTuner.tune" class="doc_header"><code>AdaptiveTuner.tune</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/core.py#L399" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>AdaptiveTuner.tune</code>(<strong><code>epochs</code></strong>:<code>int</code>, <strong><code>lr</code></strong>:<code>float</code>=<em><code>None</code></em>, <strong><code>strategy</code></strong>:<code>Strategy</code>=<em><code>'fit_one_cycle'</code></em>, <strong><code>callbacks</code></strong>:<code>list</code>=<em><code>[]</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Fine tune <code>self.model</code> for <code>epochs</code> with an <code>lr</code> and <code>strategy</code></p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>epochs</code></strong> : <em><code>&lt;class 'int'&gt;</code></em> <p>Number of iterations to train for</p></li>
</ul>
<ul>
<li><strong><code>lr</code></strong> : <em><code>&lt;class 'float'&gt;</code></em>, <em>optional</em>   <p>If None, finds a new learning rate and uses suggestion_method</p></li>
</ul>
<ul>
<li><strong><code>strategy</code></strong> : <em><code>&lt;class 'fastcore.basics.Strategy'&gt;</code></em>, <em>optional</em>  <p>A fitting method</p></li>
</ul>
<ul>
<li><strong><code>callbacks</code></strong> : <em><code>&lt;class 'list'&gt;</code></em>, <em>optional</em> <p>Extra fastai Callbacks</p></li>
</ul>
<ul>
<li><strong><code>kwargs</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can pass in a number of epochs, a learning rate, a strategy, and additional fastai callbacks to call.</p>
<p>Valid strategies live in the <code>Strategy</code> namespace class, and consist of:</p>
<ul>
<li>OneCycle (Also called the <a href="https://docs.fast.ai/callback.schedule.html#Learner.fit_one_cycle">One-Cycle Policy</a>)</li>
<li><a href="https://docs.fast.ai/callback.schedule.html#Learner.fit_flat_cos">CosineAnnealing</a></li>
<li><a href="https://docs.fast.ai/callback.schedule.html#Learner.fit_sgdr">SGDR</a></li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">Strategy</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this tutorial we will train with the One-Cycle policy, as currently it is one of the best schedulers to use.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span><span class="o">.</span><span class="n">tune</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="n">Strategy</span><span class="o">.</span><span class="n">OneCycle</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>perplexity</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>4.061049</td>
      <td>3.879425</td>
      <td>48.396393</td>
      <td>00:55</td>
    </tr>
    <tr>
      <td>1</td>
      <td>3.973648</td>
      <td>3.857744</td>
      <td>47.358402</td>
      <td>00:54</td>
    </tr>
    <tr>
      <td>2</td>
      <td>3.900359</td>
      <td>3.858645</td>
      <td>47.401066</td>
      <td>00:54</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Saving-Model">Saving Model<a class="anchor-link" href="#Saving-Model"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now that we have a trained model, let's save those weights away.</p>
<p>Calling <code>tuner.save</code> will save both the model and the tokenizer in the same format as how HuggingFace does:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="AdaptiveTuner.save" class="doc_header"><code>AdaptiveTuner.save</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/core.py#L421" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>AdaptiveTuner.save</code>(<strong><code>save_directory</code></strong>)</p>
</blockquote>
<p>Save a pretrained model to a <code>save_directory</code></p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>save_directory</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em>  <p>A folder to save our model to</p></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;good_model&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&#39;good_model&#39;</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Performing-Inference">Performing Inference<a class="anchor-link" href="#Performing-Inference"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There are two ways to get predictions, the first is with the <code>.predict</code> method in our <code>tuner</code>. This is great for if you just finished training and want to see how your model performs on some new data!
The other method is with AdaptNLP's inference API, which we will show afterwards</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="In-Tuner">In Tuner<a class="anchor-link" href="#In-Tuner"> </a></h3><p>First let's write a sentence to test with</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sentence</span> <span class="o">=</span> <span class="s2">&quot;Hugh Jackman is a terrible &quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And then predict with it:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="LanguageModelTuner.predict" class="doc_header"><code>LanguageModelTuner.predict</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/language_model.py#L293" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>LanguageModelTuner.predict</code>(<strong><code>text</code></strong>:<code>Union</code>[<code>List</code>[<code>str</code>], <code>str</code>], <strong><code>bs</code></strong>:<code>int</code>=<em><code>64</code></em>, <strong><code>num_tokens_to_produce</code></strong>:<code>int</code>=<em><code>50</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Predict some <code>text</code> for sequence classification with the currently loaded model</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>text</code></strong> : <em><code>typing.Union[typing.List[str], str]</code></em> <p>Some text or list of texts to do inference with</p></li>
</ul>
<ul>
<li><strong><code>bs</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em> <p>A batch size to use for multiple texts</p></li>
</ul>
<ul>
<li><strong><code>num_tokens_to_produce</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em>  <p>Number of tokens to generate</p></li>
</ul>
<ul>
<li><strong><code>kwargs</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">num_tokens_to_produce</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

    <div>
        <style>
            /* Turns off some styling */
            progress {
                /* gets rid of default border in Firefox and Opera. */
                border: none;
                /* Needs to be in here for Safari polyfill so background images work as expected. */
                background-size: auto;
            }
            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
                background: #F44336;
            }
        </style>
      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>
      100.00% [1/1 00:00<00:00]
    </div>
    
</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;generated_text&#39;: [&#34;Hugh Jackman is a terrible icky, and I&#39;m not sure if he&#39;s a good actor&#34;]}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="With-the-Inference-API">With the Inference API<a class="anchor-link" href="#With-the-Inference-API"> </a></h3><p>Next we will use the <a href="/adaptnlp/text_generation.html#EasyTextGenerator"><code>EasyTextGenerator</code></a> class, which AdaptNLP offers:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">EasyTextGenerator</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We simply construct the class:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">classifier</span> <span class="o">=</span> <span class="n">EasyTextGenerator</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And call the <code>tag_text</code> method, passing in the sentence, the location of our saved model, and some names for our classes:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">classifier</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
    <span class="n">sentence</span><span class="p">,</span>
    <span class="n">model_name_or_path</span><span class="o">=</span><span class="s1">&#39;good_model&#39;</span><span class="p">,</span>
    <span class="n">num_tokens_to_produce</span><span class="o">=</span><span class="mi">13</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

    <div>
        <style>
            /* Turns off some styling */
            progress {
                /* gets rid of default border in Firefox and Opera. */
                border: none;
                /* Needs to be in here for Safari polyfill so background images work as expected. */
                background-size: auto;
            }
            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
                background: #F44336;
            }
        </style>
      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>
      100.00% [1/1 00:00<00:00]
    </div>
    
</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;generated_text&#39;: [&#34;Hugh Jackman is a terrible icky, and I&#39;m not sure if he&#39;s a good actor&#34;]}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And we got the exact same output!</p>

</div>
</div>
</div>
</div>
 

