---

title: Tutorial&#58; Fine-Tuning a Language Model on CSV Files with IMDB


keywords: fastai
sidebar: home_sidebar

summary: "Tuning a base Language model on the IMDB dataset"
description: "Tuning a base Language model on the IMDB dataset"
nb_path: "nbs/training_api_tutorials/language_model/language_model_from_csv.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/training_api_tutorials/language_model/language_model_from_csv.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Introduction">Introduction<a class="anchor-link" href="#Introduction"> </a></h2><p>In this tutorial we will be showing an end-to-end example of fine-tuning a Transformer language model on a custom dataset in CSV file format.</p>
<p>By the end of this you should be able to:</p>
<ol>
<li>Build a dataset with the <a href="/adaptnlp/training.language_model.html#LanguageModelDatasets"><code>LanguageModelDatasets</code></a> class, and their DataLoaders</li>
<li>Build a <a href="/adaptnlp/training.language_model.html#LanguageModelTuner"><code>LanguageModelTuner</code></a> quickly, find a good learning rate, and train with the One-Cycle Policy</li>
<li>Save that model away, to be used with deployment or other HuggingFace libraries</li>
<li>Apply inference using both the <code>Tuner</code> available function as well as with the <a href="/adaptnlp/text_generation.html#EasyTextGenerator"><code>EasyTextGenerator</code></a> class within AdaptNLP</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Installing-the-Library">Installing the Library<a class="anchor-link" href="#Installing-the-Library"> </a></h2><p>This tutorial utilizies the latest AdaptNLP version, as well as parts of the <code>fastai</code> library. Please run the below code to install them:</p>
<div class="highlight"><pre><span></span><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">adaptnlp</span> <span class="o">-</span><span class="n">U</span>
</pre></div>
<p>(or <code>pip3</code>)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Getting-the-Dataset">Getting the Dataset<a class="anchor-link" href="#Getting-the-Dataset"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>First we need a dataset. We will use the <code>fastai</code> library to download the <code>IMDB_SAMPLE</code> dataset, a subset of IMDB Movie Reviews.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">fastai.data.external</span> <span class="kn">import</span> <span class="n">URLs</span><span class="p">,</span> <span class="n">untar_data</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>URLs</code> holds a namespace of many data endpoints, and <code>untar_data</code> is a function that can download and extract any data from a given URL.</p>
<p>Combining both, we can download the data:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data_path</span> <span class="o">=</span> <span class="n">untar_data</span><span class="p">(</span><span class="n">URLs</span><span class="o">.</span><span class="n">IMDB_SAMPLE</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If we look at what was downloaded, we will find a <code>texts.csv</code> file:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data_path</span><span class="o">.</span><span class="n">ls</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(#1) [Path(&#39;/root/.fastai/data/imdb_sample/texts.csv&#39;)]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This is our data we want to use. This CSV is formatted with a table of columns with <code>label</code>, <code>text</code>, and <code>is_valid</code> dictating whether it is part of the validation set or not.</p>
<p>Now that we have the dataset, and we know the format it is in, let's pick a viable model to train with</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Picking-a-Model-with-the-Hub">Picking a Model with the Hub<a class="anchor-link" href="#Picking-a-Model-with-the-Hub"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>AdaptNLP has a <a href="/adaptnlp/model_hub.html#HFModelHub"><code>HFModelHub</code></a> class that allows you to communicate with the HuggingFace Hub and pick a model from it, as well as a namespace <code>HF_TASKS</code> class with a list of valid tasks we can search by.</p>
<p>Let's try and find one suitable for sequence classification.</p>
<p>First we need to import the class and generate an instance of it:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">HFModelHub</span><span class="p">,</span> <span class="n">HF_TASKS</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hub</span> <span class="o">=</span> <span class="n">HFModelHub</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next we can search for a model:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">models</span> <span class="o">=</span> <span class="n">hub</span><span class="o">.</span><span class="n">search_model_by_task</span><span class="p">(</span><span class="n">HF_TASKS</span><span class="o">.</span><span class="n">TEXT_GENERATION</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's look at a few:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">models</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[Model Name: distilgpt2, Tasks: [text-generation],
 Model Name: gpt2-large, Tasks: [text-generation],
 Model Name: gpt2-medium, Tasks: [text-generation],
 Model Name: gpt2-xl, Tasks: [text-generation],
 Model Name: gpt2, Tasks: [text-generation],
 Model Name: openai-gpt, Tasks: [text-generation],
 Model Name: transfo-xl-wt103, Tasks: [text-generation],
 Model Name: xlnet-base-cased, Tasks: [text-generation],
 Model Name: xlnet-large-cased, Tasks: [text-generation]]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>These are models specifically tagged with the <code>text-generation</code> tag, so you may not see a few models you would expect such as <code>bert_base_cased</code>.</p>
<p>We'll use that first model, <code>distilgpt2</code>:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Model Name: distilgpt2, Tasks: [text-generation]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now that we have picked a model, let's use the data API to prepare our data</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include note.html content='It should be mentioned that this is optional, you can always just pass in the string name of a model such as "bert-base-cased"' %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Building-TaskDatasets-with-LanguageModelDatasets">Building <a href="/adaptnlp/training.core.html#TaskDatasets"><code>TaskDatasets</code></a> with <a href="/adaptnlp/training.language_model.html#LanguageModelDatasets"><code>LanguageModelDatasets</code></a><a class="anchor-link" href="#Building-TaskDatasets-with-LanguageModelDatasets"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Each task has a high-level data wrapper around the <a href="/adaptnlp/training.core.html#TaskDatasets"><code>TaskDatasets</code></a> class. In our case this is the <a href="/adaptnlp/training.language_model.html#LanguageModelDatasets"><code>LanguageModelDatasets</code></a> class:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">LanguageModelDatasets</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There are multiple different constructors for the <a href="/adaptnlp/training.language_model.html#LanguageModelDatasets"><code>LanguageModelDatasets</code></a> class, and you should never call the main constructor directly.</p>
<p>We will be using <code>from_csvs</code>, which wraps around the <code>from_dfs</code> constructor:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="LanguageModelDatasets.from_csvs" class="doc_header"><code>LanguageModelDatasets.from_csvs</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/language_model.py#L123" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>LanguageModelDatasets.from_csvs</code>(<strong><code>train_csv</code></strong>:<code>Path</code>, <strong><code>text_col</code></strong>:<code>str</code>, <strong><code>tokenizer_name</code></strong>:<code>str</code>, <strong><code>block_size</code></strong>:<code>int</code>=<em><code>128</code></em>, <strong><code>masked_lm</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>valid_csv</code></strong>:<code>Path</code>=<em><code>None</code></em>, <strong><code>split_func</code></strong>:<code>callable</code>=<em><code>None</code></em>, <strong><code>split_pct</code></strong>:<code>float</code>=<em><code>0.1</code></em>, <strong><code>tokenize_kwargs</code></strong>:<code>dict</code>=<em><code>{}</code></em>, <strong><code>auto_kwargs</code></strong>:<code>dict</code>=<em><code>{}</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Builds <a href="/adaptnlp/training.language_model.html#LanguageModelDatasets"><code>LanguageModelDatasets</code></a> from a single csv or set of csvs. A convience constructor for <code>from_dfs</code></p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>train_csv</code></strong> : <em><code>&lt;class 'pathlib.Path'&gt;</code></em> <p>A training csv file</p></li>
</ul>
<ul>
<li><strong><code>text_col</code></strong> : <em><code>&lt;class 'str'&gt;</code></em>   <p>The name of the text column</p></li>
</ul>
<ul>
<li><strong><code>tokenizer_name</code></strong> : <em><code>&lt;class 'str'&gt;</code></em> <p>The name of the tokenizer</p></li>
</ul>
<ul>
<li><strong><code>block_size</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em> <p>The size of each block</p></li>
</ul>
<ul>
<li><strong><code>masked_lm</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em> <p>Whether the language model is a MLM</p></li>
</ul>
<ul>
<li><strong><code>valid_csv</code></strong> : <em><code>&lt;class 'pathlib.Path'&gt;</code></em>, <em>optional</em> <p>An optional validation csv</p></li>
</ul>
<ul>
<li><strong><code>split_func</code></strong> : <em><code>&lt;built-in function callable&gt;</code></em>, <em>optional</em>  <p>Optionally a splitting function similar to RandomSplitter</p></li>
</ul>
<ul>
<li><strong><code>split_pct</code></strong> : <em><code>&lt;class 'float'&gt;</code></em>, <em>optional</em>    <p>What % to split the df between training and validation</p></li>
</ul>
<ul>
<li><strong><code>tokenize_kwargs</code></strong> : <em><code>&lt;class 'dict'&gt;</code></em>, <em>optional</em>   <p>kwargs for the tokenize function</p></li>
</ul>
<ul>
<li><strong><code>auto_kwargs</code></strong> : <em><code>&lt;class 'dict'&gt;</code></em>, <em>optional</em>   <p>kwargs for the AutoTokenizer.from_pretrained constructor</p></li>
</ul>
<ul>
<li><strong><code>kwargs</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Anything you would normally pass to the tokenizer call (such as <code>max_length</code>, <code>padding</code>) should go in <code>tokenize_kwargs</code>, and anything going to the <code>AutoTokenizer.from_pretrained</code> constructor should be passed to the <code>auto_kwargs</code>.</p>
<p>In our case we only have a <code>train_csv</code> and we have a tokenizer name. We also want to split 90%/10% (which is the default)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Also, we will set a block_size of 128, and it is <em>not</em> a masked language model:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dsets</span> <span class="o">=</span> <span class="n">LanguageModelDatasets</span><span class="o">.</span><span class="n">from_csvs</span><span class="p">(</span>
    <span class="n">train_csv</span><span class="o">=</span><span class="n">data_path</span><span class="o">/</span><span class="s1">&#39;texts.csv&#39;</span><span class="p">,</span>
    <span class="n">text_col</span><span class="o">=</span><span class="s1">&#39;text&#39;</span><span class="p">,</span>
    <span class="n">tokenizer_name</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
    <span class="n">block_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
    <span class="n">masked_lm</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>No value for `max_length` set, automatically adjusting to the size of the model and including truncation
Sequence length set to: 1024




</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include note.html content='If you have a training and validation CSV, simply pass in the validation CSV path as <code>valid_csv=path/to/validation_dataset.csv</code> and do not pass in any <code>split_func</code> or <code>split_pct</code>. Everything else is the exact same' %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And finally turn it into some <a href="/adaptnlp/training.core.html#AdaptiveDataLoaders"><code>AdaptiveDataLoaders</code></a>.</p>
<p>These are just fastai's <code>DataLoaders</code> class, but it overrides a few functions to have it work nicely with HuggingFace's <code>Dataset</code> class</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="LanguageModelDatasets.dataloaders" class="doc_header"><code>LanguageModelDatasets.dataloaders</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/language_model.py#L202" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>LanguageModelDatasets.dataloaders</code>(<strong><code>batch_size</code></strong>=<em><code>8</code></em>, <strong><code>shuffle_train</code></strong>=<em><code>True</code></em>, <strong><code>collate_fn</code></strong>=<em><code>default_data_collator</code></em>, <strong><code>mlm_probability</code></strong>:<code>float</code>=<em><code>0.15</code></em>, <strong><code>path</code></strong>=<em><code>'.'</code></em>, <strong><code>device</code></strong>=<em><code>None</code></em>)</p>
</blockquote>
<p>Build DataLoaders from <code>self</code></p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>batch_size</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em> <p>A batch size</p></li>
</ul>
<ul>
<li><strong><code>shuffle_train</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em> <p>Whether to shuffle the training dataset</p></li>
</ul>
<ul>
<li><strong><code>collate_fn</code></strong> : <em><code>&lt;class 'function'&gt;</code></em>, <em>optional</em>    <p>A custom collation function</p></li>
</ul>
<ul>
<li><strong><code>mlm_probability</code></strong> : <em><code>&lt;class 'float'&gt;</code></em>, <em>optional</em>  <p>Token masking probablity for Masked Language Models</p></li>
</ul>
<ul>
<li><p><strong><code>path</code></strong> : <em><code>&lt;class 'str'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>device</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em></p>
</li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally, let's view a batch of data with the <code>show_batch</code> function:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span><span class="o">.</span><span class="n">show_batch</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Input</th>
      <th>Label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>night.&lt;br /&gt;&lt;br /&gt;The fact that Todd Sheets seriously considers Zombie Bloodbath to be THAT superior to Zombie Rampage, amuses me to no end. I mean really, both are complete jokes on celluloid, but then again, so is Redneck Zombies, so, obviously Todd Sheets is in the company of awsomeness. By 1993, a movie this bad would no doubt, be a full-blast spoof, but Mr. Sheets stands his ground, giving us some good old fashion schlock, the way it was meant to be, unaware, clueless, and pointless. God bless Todd Sheets. For anyone seeking surprisingly worthwhile 90's B-Horror, Leif Jonker's Darkness should be at the top of your list. As for Zombie Bloodbath, if you're a gorehound who got bored sometime around 1990, then '93 would be the perfect time to pick up. 8/10I couldn't believe it. I had to rub my eyes a few times. Was it true? &lt;br /&gt;&lt;br /&gt;Yes, there were Billy Dee Williams, Jeff Conaway, Maxwell Caulfield and Tracy Scoggins - all of them have some manner of talent but here they all were in what basically adds up to a Cinemax-style skin flick set on board a spaceship!&lt;br /&gt;&lt;br /&gt;Sad as it is, "Alien Intruder" tries to be unique, with a computer virus/alien demon/harpy/whatever else you want to call her named Ariel (Scoggins) infiltrating this sort-of high-tech virtual reality station on board a spaceship where four men are allowed to live out their fantasies as the system is over-seen by their captain (Williams).&lt;br /&gt;&lt;br /&gt;Interesting? Maybe, but here everything just plays out like a well-padded episode of "Red Shoe Diaries". Williams out-classes everything right and left, and looks like he'd rather be doing anything else, ANYWHERE else. Ah, the things people do for money....&lt;br /&gt;&lt;br /&gt;The FX are pretty static, maybe even less than what you'd expect for a straight-to-video cheapie like this. Unfortunately, even the female nudity is less than you'd expect. SEXUAL INNUENDO is the real star here and, of course, it gets ALL the best scenes.&lt;br /&gt;&lt;br /&gt;If you like a movie that's all tease and no brains, check out "</td>
      <td>night.&lt;br /&gt;&lt;br /&gt;The fact that Todd Sheets seriously considers Zombie Bloodbath to be THAT superior to Zombie Rampage, amuses me to no end. I mean really, both are complete jokes on celluloid, but then again, so is Redneck Zombies, so, obviously Todd Sheets is in the company of awsomeness. By 1993, a movie this bad would no doubt, be a full-blast spoof, but Mr. Sheets stands his ground, giving us some good old fashion schlock, the way it was meant to be, unaware, clueless, and pointless. God bless Todd Sheets. For anyone seeking surprisingly worthwhile 90's B-Horror, Leif Jonker's Darkness should be at the top of your list. As for Zombie Bloodbath, if you're a gorehound who got bored sometime around 1990, then '93 would be the perfect time to pick up. 8/10I couldn't believe it. I had to rub my eyes a few times. Was it true? &lt;br /&gt;&lt;br /&gt;Yes, there were Billy Dee Williams, Jeff Conaway, Maxwell Caulfield and Tracy Scoggins - all of them have some manner of talent but here they all were in what basically adds up to a Cinemax-style skin flick set on board a spaceship!&lt;br /&gt;&lt;br /&gt;Sad as it is, "Alien Intruder" tries to be unique, with a computer virus/alien demon/harpy/whatever else you want to call her named Ariel (Scoggins) infiltrating this sort-of high-tech virtual reality station on board a spaceship where four men are allowed to live out their fantasies as the system is over-seen by their captain (Williams).&lt;br /&gt;&lt;br /&gt;Interesting? Maybe, but here everything just plays out like a well-padded episode of "Red Shoe Diaries". Williams out-classes everything right and left, and looks like he'd rather be doing anything else, ANYWHERE else. Ah, the things people do for money....&lt;br /&gt;&lt;br /&gt;The FX are pretty static, maybe even less than what you'd expect for a straight-to-video cheapie like this. Unfortunately, even the female nudity is less than you'd expect. SEXUAL INNUENDO is the real star here and, of course, it gets ALL the best scenes.&lt;br /&gt;&lt;br /&gt;If you like a movie that's all tease and no brains, check out "</td>
    </tr>
    <tr>
      <th>1</th>
      <td>on a three- or four-day leave. Joe is the "Sea Wolf" and Clarence, the bookish type, begs Joe to get him a "dame". Now, after they're picked up by the coppers they get little Donald home. That's where they meet Susie, that temptress, that jezebel. Just kidding! Clarence falls in love with her. At least he thinks he does. Is he right? Or is he a moron? Or is he just misguided by society? Find out all this and more when you watch {trumpet fanfare} ANCHORS AWEIGH!&lt;br /&gt;&lt;br /&gt;P.S. If you want to see Kathryn Grayson be anything but sickeningly sweet, try Kiss Me Kate (1953).A fun concept, but poorly executed. Except for the fairly good makeup effects, there's really not much to it. There are obvious problems; for example, after taking what seems to be weeks and weeks to get from fat to normal size, the main character seems to go from normal size to deathly thin in days... and once he's deathly thin he stays pretty much equally deathly thin for what seems to be a long time.&lt;br /&gt;&lt;br /&gt;In any case, the movie has far worse problems than that--the cinematography is decidedly low-budget-TV-show quality and most of all the acting is pretty awful all around. Robert John Burke seems to always be trying for some kind of weird snarling Charlton Heston impersonation and is literally painful to watch... the only scary thing is that Lucinda Jenney and Kari Wuhrer are both even worse.&lt;br /&gt;&lt;br /&gt;The only reason why I'm giving this movie as high as I am is that once the movie enters its last 1/3 or so and Joe Mantegna's character takes over, the movie develops a fun, campy 'cheesefest slaughterhouse' feel, and the gangster's crazy schemes for tormenting the totally obnoxious gypsies are somewhat fun to watch. The ending, if predictable, is also nicely mean. Avoid unless you're a King-o-Phile or are REALLY psyched up at the idea of the voice of Fat Tony from the Simpsons terrorizing a gypsy camp.December holiday specials, like the original Frosty, ought to be richly-produced with quality music and a wholesome, yet lighthearted storyline. They should have a touch of the mystical magic of the</td>
      <td>on a three- or four-day leave. Joe is the "Sea Wolf" and Clarence, the bookish type, begs Joe to get him a "dame". Now, after they're picked up by the coppers they get little Donald home. That's where they meet Susie, that temptress, that jezebel. Just kidding! Clarence falls in love with her. At least he thinks he does. Is he right? Or is he a moron? Or is he just misguided by society? Find out all this and more when you watch {trumpet fanfare} ANCHORS AWEIGH!&lt;br /&gt;&lt;br /&gt;P.S. If you want to see Kathryn Grayson be anything but sickeningly sweet, try Kiss Me Kate (1953).A fun concept, but poorly executed. Except for the fairly good makeup effects, there's really not much to it. There are obvious problems; for example, after taking what seems to be weeks and weeks to get from fat to normal size, the main character seems to go from normal size to deathly thin in days... and once he's deathly thin he stays pretty much equally deathly thin for what seems to be a long time.&lt;br /&gt;&lt;br /&gt;In any case, the movie has far worse problems than that--the cinematography is decidedly low-budget-TV-show quality and most of all the acting is pretty awful all around. Robert John Burke seems to always be trying for some kind of weird snarling Charlton Heston impersonation and is literally painful to watch... the only scary thing is that Lucinda Jenney and Kari Wuhrer are both even worse.&lt;br /&gt;&lt;br /&gt;The only reason why I'm giving this movie as high as I am is that once the movie enters its last 1/3 or so and Joe Mantegna's character takes over, the movie develops a fun, campy 'cheesefest slaughterhouse' feel, and the gangster's crazy schemes for tormenting the totally obnoxious gypsies are somewhat fun to watch. The ending, if predictable, is also nicely mean. Avoid unless you're a King-o-Phile or are REALLY psyched up at the idea of the voice of Fat Tony from the Simpsons terrorizing a gypsy camp.December holiday specials, like the original Frosty, ought to be richly-produced with quality music and a wholesome, yet lighthearted storyline. They should have a touch of the mystical magic of the</td>
    </tr>
    <tr>
      <th>2</th>
      <td>from a cinema.&lt;br /&gt;&lt;br /&gt;Paul Greengrass's dispassionate style worked exceptionally well on United 93 which was a sentiment overload desperate to happen, but on Bourne and his interminable woes it just has the effect of removing the audience from involvement with the character. He runs. He jumps. He punches. He gets blown up. He clears tall buildings. Yada yada yada. Above all - he SURVIVES. He survives like a plastic Action Man survives, which only makes the ridiculous stunts he pulls all the more slack and lacking in any kind of tension. So he drives off a building? So what? He'll survive. Yawn.&lt;br /&gt;&lt;br /&gt;There's a girl thrown into the mix because Bourne's love interest died in a previous incarnation, but she's just decor. I've seen more character depth and snappy dialogue in episodes of Captain Scarlet.&lt;br /&gt;&lt;br /&gt;Bourne's own journey of literal self-discovery is dull and formless and tells us nothing we didn't know from the first movie. He was turned into a killing machine. Big deal. He finds out his true identity. So what? It doesn't have any emotional resonance when it comes.&lt;br /&gt;&lt;br /&gt;The 'twist' ending is telegraphed and weak. Oh, dear, the more I think about this film the more I hate it! I've already reduced my score to 4 during the writing of this comment! I'd better end now before the slide continues.&lt;br /&gt;&lt;br /&gt;I love a good action flick and I love a good thriller. The Bourne Ultimatum is neither. It's a loud, tedious series of flashy edits, ridiculous sound effects and cartoon violence. &lt;br /&gt;&lt;br /&gt;The idea that it'shows the way' to the Bond franchise is utter crap. Casino Royale blows it out of the water.A Give this Movie a 10/10 because it deserves a 10/10. Two of the best actors of their time-Walter Matthau &amp; George Burns collaborate with Neil Simon and all of the other actors that are in this film + director Herbert Ross, and all of that makes this stage adaption come true. The Sunshine Boys is one of the best films of the 70's. I love the type of humor in this film, it just makes me laugh so hard.&lt;br /&gt;&lt;br /&gt;I got this movie on VHS 3 days ago (yes, VHS because it was cheaper-only</td>
      <td>from a cinema.&lt;br /&gt;&lt;br /&gt;Paul Greengrass's dispassionate style worked exceptionally well on United 93 which was a sentiment overload desperate to happen, but on Bourne and his interminable woes it just has the effect of removing the audience from involvement with the character. He runs. He jumps. He punches. He gets blown up. He clears tall buildings. Yada yada yada. Above all - he SURVIVES. He survives like a plastic Action Man survives, which only makes the ridiculous stunts he pulls all the more slack and lacking in any kind of tension. So he drives off a building? So what? He'll survive. Yawn.&lt;br /&gt;&lt;br /&gt;There's a girl thrown into the mix because Bourne's love interest died in a previous incarnation, but she's just decor. I've seen more character depth and snappy dialogue in episodes of Captain Scarlet.&lt;br /&gt;&lt;br /&gt;Bourne's own journey of literal self-discovery is dull and formless and tells us nothing we didn't know from the first movie. He was turned into a killing machine. Big deal. He finds out his true identity. So what? It doesn't have any emotional resonance when it comes.&lt;br /&gt;&lt;br /&gt;The 'twist' ending is telegraphed and weak. Oh, dear, the more I think about this film the more I hate it! I've already reduced my score to 4 during the writing of this comment! I'd better end now before the slide continues.&lt;br /&gt;&lt;br /&gt;I love a good action flick and I love a good thriller. The Bourne Ultimatum is neither. It's a loud, tedious series of flashy edits, ridiculous sound effects and cartoon violence. &lt;br /&gt;&lt;br /&gt;The idea that it'shows the way' to the Bond franchise is utter crap. Casino Royale blows it out of the water.A Give this Movie a 10/10 because it deserves a 10/10. Two of the best actors of their time-Walter Matthau &amp; George Burns collaborate with Neil Simon and all of the other actors that are in this film + director Herbert Ross, and all of that makes this stage adaption come true. The Sunshine Boys is one of the best films of the 70's. I love the type of humor in this film, it just makes me laugh so hard.&lt;br /&gt;&lt;br /&gt;I got this movie on VHS 3 days ago (yes, VHS because it was cheaper-only</td>
    </tr>
    <tr>
      <th>3</th>
      <td>my initial reaction when the credits started but just over an hour and a half later I was in a state of shock. What a superb movie &lt;br /&gt;&lt;br /&gt;The story starts on the day of the wedding between Sean Cloney and Sheila Kelly in the 1950s. There is a slight problem since they're getting married in the catholic church and that is Sheila is a protestant but in order for the wedding to happen Sheila takes a pledge that her children will be brought up catholic and attend the catholic school when they're old enough. The story - Which is set in the 1950s - then jumps forward a few years when the Cloney daughters are about to start school but Sheila has decided they'll be attending the local protestant school much to the disgust of local priest Father Stafford. From there things escalate &lt;br /&gt;&lt;br /&gt;Let me put my cards on the table and state that despite having both Irish catholic and Scottish protestant heritage I was brought up as agnostic and have considered myself as an atheist throughout my adult life. In fact when it comes to religion I consider myself a Marxist and religion is a cynical weapon used to manipulate people. A LOVE DIVIDED shows what happens when self appointed moral guardians take it upon themselves to tell other people what to think and believe. May I have the temerity to state that if Karl Marx saw this movie he'd love it and call it a masterpiece? Perhaps I shouldn't since the drama of this story shows what happens when other people do your thinking for you &lt;br /&gt;&lt;br /&gt;In reply to the couple of reviewers who have claimed this movie is propaganda of the worst sort I don't claim to know the exact details of what happened in County Wexford and there's no denying that Father Stafford and his flock of catholic sheep are portrayed as being the bad guys but Sheila isn't blameless herself. Think about a woman living in a rural village in 1950s Ireland who takes a pledge to bring her children up as catholics then changes her mind and believes there will be no consequences of this? This is a warning against taking pledges and not keeping to them. Not only that but she disappears to let other people pick up the pieces of their shattered lives. There's also something that no one else has picked up upon and that is that the only character with any type of moral sense is former IRA man Andy Bailey who is shown as being gallant not because he was a former IRA member ( That makes a change. We're not talking about THE DEVIL</td>
      <td>my initial reaction when the credits started but just over an hour and a half later I was in a state of shock. What a superb movie &lt;br /&gt;&lt;br /&gt;The story starts on the day of the wedding between Sean Cloney and Sheila Kelly in the 1950s. There is a slight problem since they're getting married in the catholic church and that is Sheila is a protestant but in order for the wedding to happen Sheila takes a pledge that her children will be brought up catholic and attend the catholic school when they're old enough. The story - Which is set in the 1950s - then jumps forward a few years when the Cloney daughters are about to start school but Sheila has decided they'll be attending the local protestant school much to the disgust of local priest Father Stafford. From there things escalate &lt;br /&gt;&lt;br /&gt;Let me put my cards on the table and state that despite having both Irish catholic and Scottish protestant heritage I was brought up as agnostic and have considered myself as an atheist throughout my adult life. In fact when it comes to religion I consider myself a Marxist and religion is a cynical weapon used to manipulate people. A LOVE DIVIDED shows what happens when self appointed moral guardians take it upon themselves to tell other people what to think and believe. May I have the temerity to state that if Karl Marx saw this movie he'd love it and call it a masterpiece? Perhaps I shouldn't since the drama of this story shows what happens when other people do your thinking for you &lt;br /&gt;&lt;br /&gt;In reply to the couple of reviewers who have claimed this movie is propaganda of the worst sort I don't claim to know the exact details of what happened in County Wexford and there's no denying that Father Stafford and his flock of catholic sheep are portrayed as being the bad guys but Sheila isn't blameless herself. Think about a woman living in a rural village in 1950s Ireland who takes a pledge to bring her children up as catholics then changes her mind and believes there will be no consequences of this? This is a warning against taking pledges and not keeping to them. Not only that but she disappears to let other people pick up the pieces of their shattered lives. There's also something that no one else has picked up upon and that is that the only character with any type of moral sense is former IRA man Andy Bailey who is shown as being gallant not because he was a former IRA member ( That makes a change. We're not talking about THE DEVIL</td>
    </tr>
    <tr>
      <th>4</th>
      <td>. Just when your thinking its going to get boring they throw a twist at you. Luckily this isn't a long movie and doesn't feel like it either. Much better then the other flight movie Flight Plan.&lt;br /&gt;&lt;br /&gt;Here is my Flight Plan comment: http://www.imdb.com/title/tt0408790/usercomments-578&lt;br /&gt;&lt;br /&gt;I recommend. Not too long and not too shabby.&lt;br /&gt;&lt;br /&gt;8/10This movie lacked... everything: story, acting, surprise, ingenuity and a soul. Fifteen minutes in, I was staring at the screen saying, "How could all of these guys get together and consider themselves friends (even without the girl)?" Another fifteen minutes in, I was praying for as much Amanda Peet as possible. When a bad movie quietly rears it's ugly head, eye candy is a nice consolation. But there wasn't much of that! Cheated on all fronts!I'm still trying to figure out if there was a point to this film.&lt;br /&gt;&lt;br /&gt;For content that's supposed to be so'rebellious' and 'controversial' the things that Maddox distributes to the students are awfully lame. Students seem to be easily swayed by vague anti-authoritarian sentiments and snippets of words illegibly scrawled onto leaflets. Rebel, everybody.&lt;br /&gt;&lt;br /&gt;I suppose it would have been too much to ask to have a teenage rebellion film where a school fire alarm doesn't get set off.&lt;br /&gt;&lt;br /&gt;Apparently a 'huge fight up on the football fields' is a fight that consists of two people.&lt;br /&gt;&lt;br /&gt;Characters personalities seem to wildly vary at random. A football jock who Maddox was fighting (and who subsequently got a staple on the face) is all smiles and apologies the next day.&lt;br /&gt;&lt;br /&gt;The fact that it doesn't come to any real conclusion of the plot makes me feel that the whole thing could have been fitted into a half hour after school special. If they had cut most of the attempted pseudo-glitch soundtrack.i've seen a movie thats sort of like this, were a transsexual drugs woman and he then picks there nose with a knife and rips there nose to peaces. he then slices there tongue and eats it.&lt;br /&gt;&lt;br /&gt;the most gruesome part of the movie is were he cuts there left eye out and starts dancing with it. he then starts to eat the woman naked.&lt;br</td>
      <td>. Just when your thinking its going to get boring they throw a twist at you. Luckily this isn't a long movie and doesn't feel like it either. Much better then the other flight movie Flight Plan.&lt;br /&gt;&lt;br /&gt;Here is my Flight Plan comment: http://www.imdb.com/title/tt0408790/usercomments-578&lt;br /&gt;&lt;br /&gt;I recommend. Not too long and not too shabby.&lt;br /&gt;&lt;br /&gt;8/10This movie lacked... everything: story, acting, surprise, ingenuity and a soul. Fifteen minutes in, I was staring at the screen saying, "How could all of these guys get together and consider themselves friends (even without the girl)?" Another fifteen minutes in, I was praying for as much Amanda Peet as possible. When a bad movie quietly rears it's ugly head, eye candy is a nice consolation. But there wasn't much of that! Cheated on all fronts!I'm still trying to figure out if there was a point to this film.&lt;br /&gt;&lt;br /&gt;For content that's supposed to be so'rebellious' and 'controversial' the things that Maddox distributes to the students are awfully lame. Students seem to be easily swayed by vague anti-authoritarian sentiments and snippets of words illegibly scrawled onto leaflets. Rebel, everybody.&lt;br /&gt;&lt;br /&gt;I suppose it would have been too much to ask to have a teenage rebellion film where a school fire alarm doesn't get set off.&lt;br /&gt;&lt;br /&gt;Apparently a 'huge fight up on the football fields' is a fight that consists of two people.&lt;br /&gt;&lt;br /&gt;Characters personalities seem to wildly vary at random. A football jock who Maddox was fighting (and who subsequently got a staple on the face) is all smiles and apologies the next day.&lt;br /&gt;&lt;br /&gt;The fact that it doesn't come to any real conclusion of the plot makes me feel that the whole thing could have been fitted into a half hour after school special. If they had cut most of the attempted pseudo-glitch soundtrack.i've seen a movie thats sort of like this, were a transsexual drugs woman and he then picks there nose with a knife and rips there nose to peaces. he then slices there tongue and eats it.&lt;br /&gt;&lt;br /&gt;the most gruesome part of the movie is were he cuts there left eye out and starts dancing with it. he then starts to eat the woman naked.&lt;br</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>When training a language model, the input and output are made to be the exact same, so there isn't a shown noticable difference here.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Building-Tuner">Building <code>Tuner</code><a class="anchor-link" href="#Building-Tuner"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next we need to build a compatible <code>Tuner</code> for our problem. These tuners contain good defaults for our problem space, including loss functions and metrics.</p>
<p>First let's import the <a href="/adaptnlp/training.language_model.html#LanguageModelTuner"><code>LanguageModelTuner</code></a> and view it's documentation</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">LanguageModelTuner</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="LanguageModelTuner" class="doc_header"><code>class</code> <code>LanguageModelTuner</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/language_model.py#L228" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>LanguageModelTuner</code>(<strong><code>dls</code></strong>:<code>DataLoaders</code>, <strong><code>model_name</code></strong>, <strong><code>tokenizer</code></strong>=<em><code>None</code></em>, <strong><code>language_model_type</code></strong>:<code>LMType</code>=<em><code>'causal'</code></em>, <strong><code>loss_func</code></strong>=<em><code>CrossEntropyLoss()</code></em>, <strong><code>metrics</code></strong>=<em><code>[&lt;fastai.metrics.Perplexity object at 0x7f38b8815460&gt;]</code></em>, <strong><code>opt_func</code></strong>=<em><code>Adam</code></em>, <strong><code>additional_cbs</code></strong>=<em><code>None</code></em>, <strong><code>expose_fastai_api</code></strong>=<em><code>False</code></em>, <strong>**<code>kwargs</code></strong>) :: <a href="/adaptnlp/training.core.html#AdaptiveTuner"><code>AdaptiveTuner</code></a></p>
</blockquote>
<p>An <a href="/adaptnlp/training.core.html#AdaptiveTuner"><code>AdaptiveTuner</code></a> with good defaults for Language Model fine-tuning
<strong>Valid kwargs and defaults:</strong></p>
<ul>
<li><code>lr</code>:float = 0.001</li>
<li><code>splitter</code>:function = <code>trainable_params</code></li>
<li><code>cbs</code>:list = None</li>
<li><code>path</code>:Path = None</li>
<li><code>model_dir</code>:Path = 'models'</li>
<li><code>wd</code>:float = None</li>
<li><code>wd_bn_bias</code>:bool = False</li>
<li><code>train_bn</code>:bool = True</li>
<li><code>moms</code>: tuple(float) = (0.95, 0.85, 0.95)</li>
</ul>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>dls</code></strong> : <em><code>&lt;class 'fastai.data.core.DataLoaders'&gt;</code></em>   <p>A set of DataLoaders or AdaptiveDataLoaders</p></li>
</ul>
<ul>
<li><strong><code>model_name</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em>  <p>A HuggingFace model</p></li>
</ul>
<ul>
<li><strong><code>tokenizer</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em> <p>A HuggingFace tokenizer</p></li>
</ul>
<ul>
<li><strong><code>language_model_type</code></strong> : <em><code>&lt;class 'fastcore.basics.LMType'&gt;</code></em>, <em>optional</em> <p>The type of language model to use</p></li>
</ul>
<ul>
<li><strong><code>loss_func</code></strong> : <em><code>&lt;class 'fastai.losses.CrossEntropyLossFlat'&gt;</code></em>, <em>optional</em>   <p>A loss function</p></li>
</ul>
<ul>
<li><strong><code>metrics</code></strong> : <em><code>&lt;class 'list'&gt;</code></em>, <em>optional</em>   <p>Metrics to monitor the training with</p></li>
</ul>
<ul>
<li><strong><code>opt_func</code></strong> : <em><code>&lt;class 'function'&gt;</code></em>, <em>optional</em>  <p>A fastai or torch Optimizer</p></li>
</ul>
<ul>
<li><strong><code>additional_cbs</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em>    <p>Additional Callbacks to have always tied to the Tuner,</p></li>
</ul>
<ul>
<li><strong><code>expose_fastai_api</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em> <p>Whether to expose the fastai API</p></li>
</ul>
<ul>
<li><strong><code>kwargs</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next we'll pass in our <code>DataLoaders</code>, the name of our model, and the tokenizer:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include note.html content='If you are not using the data API (<a href="/adaptnlp/training.core.html#TaskDatasets"><code>TaskDatasets</code></a>, <a href="/adaptnlp/training.sequence_classification.html#SequenceClassificationDatasets"><code>SequenceClassificationDatasets</code></a>, etc), you need to pass in the tokenizer to the constructor as well with<code>tokenizer=tokenizer</code>' %}</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span> <span class="o">=</span> <span class="n">LanguageModelTuner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">dls</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>By default we can see that it used <code>CrossEntropyLoss</code> as our loss function, and <code>Perplexity</code> as our metric</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span><span class="o">.</span><span class="n">loss_func</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>FlattenedLoss of CrossEntropyLoss()</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="p">[</span><span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">tuner</span><span class="o">.</span><span class="n">metrics</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>perplexity
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally we just need to train our model!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Fine-Tuning">Fine-Tuning<a class="anchor-link" href="#Fine-Tuning"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To fine-tune, AdaptNLP's tuner class provides only a few functions to work with. The important ones are the <code>tune</code> and <code>lr_find</code> class.</p>
<p>As the <code>Tuner</code> uses <code>fastai</code> under the hood, <code>lr_find</code> calls fastai's Learning Rate Finder to help us pick a learning rate. Let's do that now:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="AdaptiveTuner.lr_find" class="doc_header"><code>AdaptiveTuner.lr_find</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/core.py#L385" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>AdaptiveTuner.lr_find</code>(<strong><code>start_lr</code></strong>=<em><code>1e-07</code></em>, <strong><code>end_lr</code></strong>=<em><code>10</code></em>, <strong><code>num_it</code></strong>=<em><code>100</code></em>, <strong><code>stop_div</code></strong>=<em><code>True</code></em>, <strong><code>show_plot</code></strong>=<em><code>True</code></em>, <strong><code>suggest_funcs</code></strong>=<em><code>valley</code></em>)</p>
</blockquote>
<p>Runs fastai's <code>LR Finder</code></p>
<p><strong>Parameters:</strong></p>
<ul>
<li><p><strong><code>start_lr</code></strong> : <em><code>&lt;class 'float'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>end_lr</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>num_it</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>stop_div</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>show_plot</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>suggest_funcs</code></strong> : <em><code>&lt;class 'function'&gt;</code></em>, <em>optional</em></p>
</li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/opt/venv/lib/python3.8/site-packages/fastai/callback/schedule.py:270: UserWarning: color is redundantly defined by the &#39;color&#39; keyword argument and the fmt string &#34;ro&#34; (-&gt; color=&#39;r&#39;). The keyword argument will take precedence.
  ax.plot(val, idx, &#39;ro&#39;, label=nm, c=color)
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>SuggestedLRs(valley=6.30957365501672e-05)</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It recommends a learning rate of around 5e-5, so we will use that.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr</span> <span class="o">=</span> <span class="mf">5e-5</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's look at the documentation for <code>tune</code>:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="AdaptiveTuner.tune" class="doc_header"><code>AdaptiveTuner.tune</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/core.py#L371" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>AdaptiveTuner.tune</code>(<strong><code>epochs</code></strong>:<code>int</code>, <strong><code>lr</code></strong>:<code>float</code>=<em><code>None</code></em>, <strong><code>strategy</code></strong>:<code>Strategy</code>=<em><code>'fit_one_cycle'</code></em>, <strong><code>callbacks</code></strong>:<code>list</code>=<em><code>[]</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Fine tune <code>self.model</code> for <code>epochs</code> with an <code>lr</code> and <code>strategy</code></p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>epochs</code></strong> : <em><code>&lt;class 'int'&gt;</code></em> <p>Number of iterations to train for</p></li>
</ul>
<ul>
<li><strong><code>lr</code></strong> : <em><code>&lt;class 'float'&gt;</code></em>, <em>optional</em>   <p>If None, finds a new learning rate and uses suggestion_method</p></li>
</ul>
<ul>
<li><strong><code>strategy</code></strong> : <em><code>&lt;class 'fastcore.basics.Strategy'&gt;</code></em>, <em>optional</em>  <p>A fitting method</p></li>
</ul>
<ul>
<li><strong><code>callbacks</code></strong> : <em><code>&lt;class 'list'&gt;</code></em>, <em>optional</em> <p>Extra fastai Callbacks</p></li>
</ul>
<ul>
<li><strong><code>kwargs</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can pass in a number of epochs, a learning rate, a strategy, and additional fastai callbacks to call.</p>
<p>Valid strategies live in the <code>Strategy</code> namespace class, and consist of:</p>
<ul>
<li>OneCycle (Also called the <a href="https://docs.fast.ai/callback.schedule.html#Learner.fit_one_cycle">One-Cycle Policy</a>)</li>
<li><a href="https://docs.fast.ai/callback.schedule.html#Learner.fit_flat_cos">CosineAnnealing</a></li>
<li><a href="https://docs.fast.ai/callback.schedule.html#Learner.fit_sgdr">SGDR</a></li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">Strategy</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this tutorial we will train with the One-Cycle policy, as currently it is one of the best schedulers to use.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span><span class="o">.</span><span class="n">tune</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="n">Strategy</span><span class="o">.</span><span class="n">OneCycle</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>perplexity</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>4.061049</td>
      <td>3.879425</td>
      <td>48.396393</td>
      <td>00:55</td>
    </tr>
    <tr>
      <td>1</td>
      <td>3.973648</td>
      <td>3.857744</td>
      <td>47.358402</td>
      <td>00:54</td>
    </tr>
    <tr>
      <td>2</td>
      <td>3.900359</td>
      <td>3.858645</td>
      <td>47.401066</td>
      <td>00:54</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Saving-Model">Saving Model<a class="anchor-link" href="#Saving-Model"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now that we have a trained model, let's save those weights away.</p>
<p>Calling <code>tuner.save</code> will save both the model and the tokenizer in the same format as how HuggingFace does:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="AdaptiveTuner.save" class="doc_header"><code>AdaptiveTuner.save</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/core.py#L393" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>AdaptiveTuner.save</code>(<strong><code>save_directory</code></strong>)</p>
</blockquote>
<p>Save a pretrained model to a <code>save_directory</code></p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>save_directory</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em>  <p>A folder to save our model to</p></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;good_model&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&#39;good_model&#39;</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Performing-Inference">Performing Inference<a class="anchor-link" href="#Performing-Inference"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There are two ways to get predictions, the first is with the <code>.predict</code> method in our <code>tuner</code>. This is great for if you just finished training and want to see how your model performs on some new data!
The other method is with AdaptNLP's inference API, which we will show afterwards</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="In-Tuner">In Tuner<a class="anchor-link" href="#In-Tuner"> </a></h3><p>First let's write a sentence to test with</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sentence</span> <span class="o">=</span> <span class="s2">&quot;Hugh Jackman is a terrible &quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And then predict with it:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="LanguageModelTuner.predict" class="doc_header"><code>LanguageModelTuner.predict</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/language_model.py#L293" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>LanguageModelTuner.predict</code>(<strong><code>text</code></strong>:<code>Union</code>[<code>List</code>[<code>str</code>], <code>str</code>], <strong><code>bs</code></strong>:<code>int</code>=<em><code>64</code></em>, <strong><code>num_tokens_to_produce</code></strong>:<code>int</code>=<em><code>50</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Predict some <code>text</code> for sequence classification with the currently loaded model</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>text</code></strong> : <em><code>typing.Union[typing.List[str], str]</code></em> <p>Some text or list of texts to do inference with</p></li>
</ul>
<ul>
<li><strong><code>bs</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em> <p>A batch size to use for multiple texts</p></li>
</ul>
<ul>
<li><strong><code>num_tokens_to_produce</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em>  <p>Number of tokens to generate</p></li>
</ul>
<ul>
<li><strong><code>kwargs</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">num_tokens_to_produce</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

    <div>
        <style>
            /* Turns off some styling */
            progress {
                /* gets rid of default border in Firefox and Opera. */
                border: none;
                /* Needs to be in here for Safari polyfill so background images work as expected. */
                background-size: auto;
            }
            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
                background: #F44336;
            }
        </style>
      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>
      100.00% [1/1 00:00<00:00]
    </div>
    
</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;generated_text&#39;: [&#34;Hugh Jackman is a terrible icky, and I&#39;m not sure if he&#39;s a good actor&#34;]}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="With-the-Inference-API">With the Inference API<a class="anchor-link" href="#With-the-Inference-API"> </a></h3><p>Next we will use the <a href="/adaptnlp/text_generation.html#EasyTextGenerator"><code>EasyTextGenerator</code></a> class, which AdaptNLP offers:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">EasyTextGenerator</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We simply construct the class:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">classifier</span> <span class="o">=</span> <span class="n">EasyTextGenerator</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And call the <code>tag_text</code> method, passing in the sentence, the location of our saved model, and some names for our classes:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">classifier</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
    <span class="n">sentence</span><span class="p">,</span>
    <span class="n">model_name_or_path</span><span class="o">=</span><span class="s1">&#39;good_model&#39;</span><span class="p">,</span>
    <span class="n">num_tokens_to_produce</span><span class="o">=</span><span class="mi">13</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

    <div>
        <style>
            /* Turns off some styling */
            progress {
                /* gets rid of default border in Firefox and Opera. */
                border: none;
                /* Needs to be in here for Safari polyfill so background images work as expected. */
                background-size: auto;
            }
            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
                background: #F44336;
            }
        </style>
      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>
      100.00% [1/1 00:00<00:00]
    </div>
    
</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;generated_text&#39;: [&#34;Hugh Jackman is a terrible icky, and I&#39;m not sure if he&#39;s a good actor&#34;]}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And we got the exact same output!</p>

</div>
</div>
</div>
</div>
 

