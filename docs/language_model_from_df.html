---

title: Tutorial&#58; Fine-Tuning a Language Model on DataFrames with IMDB


keywords: fastai
sidebar: home_sidebar

summary: "Tuning a base Language model on the IMDB dataset"
description: "Tuning a base Language model on the IMDB dataset"
nb_path: "nbs/training_api_tutorials/language_model/language_model_from_df.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/training_api_tutorials/language_model/language_model_from_df.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Introduction">Introduction<a class="anchor-link" href="#Introduction"> </a></h2><p>In this tutorial we will be showing an end-to-end example of fine-tuning a Transformer language model on a custom dataset in <code>DataFrame</code> format.</p>
<p>By the end of this you should be able to:</p>
<ol>
<li>Build a dataset with the <a href="/adaptnlp/training.language_model.html#LanguageModelDatasets"><code>LanguageModelDatasets</code></a> class, and their DataLoaders</li>
<li>Build a <a href="/adaptnlp/training.language_model.html#LanguageModelTuner"><code>LanguageModelTuner</code></a> quickly, find a good learning rate, and train with the One-Cycle Policy</li>
<li>Save that model away, to be used with deployment or other HuggingFace libraries</li>
<li>Apply inference using both the <code>Tuner</code> available function as well as with the <a href="/adaptnlp/text_generation.html#EasyTextGenerator"><code>EasyTextGenerator</code></a> class within AdaptNLP</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Installing-the-Library">Installing the Library<a class="anchor-link" href="#Installing-the-Library"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This tutorial utilizies the latest AdaptNLP version, as well as parts of the <code>fastai</code> library. Please run the below code to install them:</p>
<div class="highlight"><pre><span></span><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">adaptnlp</span> <span class="o">-</span><span class="n">U</span>
</pre></div>
<p>(or <code>pip3</code>)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Getting-the-Dataset">Getting the Dataset<a class="anchor-link" href="#Getting-the-Dataset"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>First we need a dataset. We will use the <code>fastai</code> library to download the <code>IMDB_SAMPLE</code> dataset, a subset of IMDB Movie Reviews.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">fastai.data.external</span> <span class="kn">import</span> <span class="n">URLs</span><span class="p">,</span> <span class="n">untar_data</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>URLs</code> holds a namespace of many data endpoints, and <code>untar_data</code> is a function that can download and extract any data from a given URL.</p>
<p>Combining both, we can download the data:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data_path</span> <span class="o">=</span> <span class="n">untar_data</span><span class="p">(</span><span class="n">URLs</span><span class="o">.</span><span class="n">IMDB_SAMPLE</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If we look at what was downloaded, we will find a <code>texts.csv</code> file:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data_path</span><span class="o">.</span><span class="n">ls</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(#1) [Path(&#39;/root/.fastai/data/imdb_sample/texts.csv&#39;)]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This is our data we want to use. We should now open the <code>csv</code> in <code>pandas</code> to generate our <code>DataFrame</code> object:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data_path</span><span class="o">/</span><span class="s1">&#39;texts.csv&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's look at our data</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>label</th>
      <th>text</th>
      <th>is_valid</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>negative</td>
      <td>Un-bleeping-believable! Meg Ryan doesn't even look her usual pert lovable self in this, which normally makes me forgive her shallow ticky acting schtick. Hard to believe she was the producer on this dog. Plus Kevin Kline: what kind of suicide trip has his career been on? Whoosh... Banzai!!! Finally this was directed by the guy who did Big Chill? Must be a replay of Jonestown - hollywood style. Wooofff!</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1</th>
      <td>positive</td>
      <td>This is a extremely well-made film. The acting, script and camera-work are all first-rate. The music is good, too, though it is mostly early in the film, when things are still relatively cheery. There are no really superstars in the cast, though several faces will be familiar. The entire cast does an excellent job with the script.&lt;br /&gt;&lt;br /&gt;But it is hard to watch, because there is no good end to a situation like the one presented. It is now fashionable to blame the British for setting Hindus and Muslims against each other, and then cruelly separating them into two countries. There is som...</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>negative</td>
      <td>Every once in a long while a movie will come along that will be so awful that I feel compelled to warn people. If I labor all my days and I can save but one soul from watching this movie, how great will be my joy.&lt;br /&gt;&lt;br /&gt;Where to begin my discussion of pain. For starters, there was a musical montage every five minutes. There was no character development. Every character was a stereotype. We had swearing guy, fat guy who eats donuts, goofy foreign guy, etc. The script felt as if it were being written as the movie was being shot. The production value was so incredibly low that it felt li...</td>
      <td>False</td>
    </tr>
    <tr>
      <th>3</th>
      <td>positive</td>
      <td>Name just says it all. I watched this movie with my dad when it came out and having served in Korea he had great admiration for the man. The disappointing thing about this film is that it only concentrate on a short period of the man's life - interestingly enough the man's entire life would have made such an epic bio-pic that it is staggering to imagine the cost for production.&lt;br /&gt;&lt;br /&gt;Some posters elude to the flawed characteristics about the man, which are cheap shots. The theme of the movie "Duty, Honor, Country" are not just mere words blathered from the lips of a high-brassed offic...</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>negative</td>
      <td>This movie succeeds at being one of the most unique movies you've seen. However this comes from the fact that you can't make heads or tails of this mess. It almost seems as a series of challenges set up to determine whether or not you are willing to walk out of the movie and give up the money you just paid. If you don't want to feel slighted you'll sit through this horrible film and develop a real sense of pity for the actors involved, they've all seen better days, but then you realize they actually got paid quite a bit of money to do this and you'll lose pity for them just like you've alr...</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We will find that there is a <code>label</code>, some <code>text</code>, and a <code>is_valid</code> boolean, which determines if a row is part of the training or the validation set</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now that we've downloaded some data, let's pick a viable model to train with</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Picking-a-Model-with-the-Hub">Picking a Model with the Hub<a class="anchor-link" href="#Picking-a-Model-with-the-Hub"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>AdaptNLP has a <a href="/adaptnlp/model_hub.html#HFModelHub"><code>HFModelHub</code></a> class that allows you to communicate with the HuggingFace Hub and pick a model from it, as well as a namespace <code>HF_TASKS</code> class with a list of valid tasks we can search by.</p>
<p>Let's try and find one suitable for sequence classification.</p>
<p>First we need to import the class and generate an instance of it:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">HFModelHub</span><span class="p">,</span> <span class="n">HF_TASKS</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hub</span> <span class="o">=</span> <span class="n">HFModelHub</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next we can search for a model:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">models</span> <span class="o">=</span> <span class="n">hub</span><span class="o">.</span><span class="n">search_model_by_task</span><span class="p">(</span><span class="n">HF_TASKS</span><span class="o">.</span><span class="n">TEXT_GENERATION</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's look at a few:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">models</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[Model Name: distilgpt2, Tasks: [text-generation],
 Model Name: gpt2-large, Tasks: [text-generation],
 Model Name: gpt2-medium, Tasks: [text-generation],
 Model Name: gpt2-xl, Tasks: [text-generation],
 Model Name: gpt2, Tasks: [text-generation],
 Model Name: openai-gpt, Tasks: [text-generation],
 Model Name: transfo-xl-wt103, Tasks: [text-generation],
 Model Name: xlnet-base-cased, Tasks: [text-generation],
 Model Name: xlnet-large-cased, Tasks: [text-generation]]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>These are models specifically tagged with the <code>text-generation</code> tag, so you may not see a few models you would expect such as <code>bert_base_cased</code>.</p>
<p>We'll use that first model, <code>distilgpt2</code>:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Model Name: distilgpt2, Tasks: [text-generation]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now that we have picked a model, let's use the data API to prepare our data</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include note.html content='It should be mentioned that this is optional, you can always just pass in the string name of a model such as "bert-base-cased"' %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Building-TaskDatasets-with-LanguageModelDatasets">Building <a href="/adaptnlp/training.core.html#TaskDatasets"><code>TaskDatasets</code></a> with <a href="/adaptnlp/training.language_model.html#LanguageModelDatasets"><code>LanguageModelDatasets</code></a><a class="anchor-link" href="#Building-TaskDatasets-with-LanguageModelDatasets"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Each task has a high-level data wrapper around the <a href="/adaptnlp/training.core.html#TaskDatasets"><code>TaskDatasets</code></a> class. In our case this is the <a href="/adaptnlp/training.language_model.html#LanguageModelDatasets"><code>LanguageModelDatasets</code></a> class:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">LanguageModelDatasets</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There are multiple different constructors for the <a href="/adaptnlp/training.language_model.html#LanguageModelDatasets"><code>LanguageModelDatasets</code></a> class, and you should never call the main constructor directly.</p>
<p>We will be using <code>from_dfs</code>:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="LanguageModelDatasets.from_dfs" class="doc_header"><code>LanguageModelDatasets.from_dfs</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/language_model.py#L74" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>LanguageModelDatasets.from_dfs</code>(<strong><code>train_df</code></strong>:<code>DataFrame</code>, <strong><code>text_col</code></strong>:<code>str</code>, <strong><code>tokenizer_name</code></strong>:<code>str</code>, <strong><code>block_size</code></strong>:<code>int</code>=<em><code>128</code></em>, <strong><code>masked_lm</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>valid_df</code></strong>:<code>DataFrame</code>=<em><code>None</code></em>, <strong><code>split_func</code></strong>:<code>callable</code>=<em><code>None</code></em>, <strong><code>split_pct</code></strong>:<code>float</code>=<em><code>0.1</code></em>, <strong><code>tokenize_kwargs</code></strong>:<code>dict</code>=<em><code>{}</code></em>, <strong><code>auto_kwargs</code></strong>:<code>dict</code>=<em><code>{}</code></em>)</p>
</blockquote>
<p>Builds <a href="/adaptnlp/training.language_model.html#LanguageModelDatasets"><code>LanguageModelDatasets</code></a> from a <code>DataFrame</code> or file path</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>train_df</code></strong> : <em><code>&lt;class 'pandas.core.frame.DataFrame'&gt;</code></em>   <p>A Pandas Dataframe</p></li>
</ul>
<ul>
<li><strong><code>text_col</code></strong> : <em><code>&lt;class 'str'&gt;</code></em>   <p>The name of the text column</p></li>
</ul>
<ul>
<li><strong><code>tokenizer_name</code></strong> : <em><code>&lt;class 'str'&gt;</code></em> <p>The name of the tokenizer</p></li>
</ul>
<ul>
<li><strong><code>block_size</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em> <p>The size of each block</p></li>
</ul>
<ul>
<li><strong><code>masked_lm</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em> <p>Whether the language model is a MLM</p></li>
</ul>
<ul>
<li><strong><code>valid_df</code></strong> : <em><code>&lt;class 'pandas.core.frame.DataFrame'&gt;</code></em>, <em>optional</em>   <p>An optional validation DataFrame</p></li>
</ul>
<ul>
<li><strong><code>split_func</code></strong> : <em><code>&lt;built-in function callable&gt;</code></em>, <em>optional</em>  <p>Optionally a splitting function similar to RandomSplitter</p></li>
</ul>
<ul>
<li><strong><code>split_pct</code></strong> : <em><code>&lt;class 'float'&gt;</code></em>, <em>optional</em>    <p>What % to split the df between training and validation</p></li>
</ul>
<ul>
<li><strong><code>tokenize_kwargs</code></strong> : <em><code>&lt;class 'dict'&gt;</code></em>, <em>optional</em>   <p>kwargs for the tokenize function</p></li>
</ul>
<ul>
<li><strong><code>auto_kwargs</code></strong> : <em><code>&lt;class 'dict'&gt;</code></em>, <em>optional</em>   <p>kwargs for the AutoTokenizer.from_pretrained constructor</p></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Anything you would normally pass to the tokenizer call (such as <code>max_length</code>, <code>padding</code>) should go in <code>tokenize_kwargs</code>, and anything going to the <code>AutoTokenizer.from_pretrained</code> constructor should be passed to the <code>auto_kwargs</code>.</p>
<p>In our case we only have a <code>train_df</code>, and since we are training a language model, we want to split the data 90/10 (which is the default)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Also, we will set a block_size of 128, and it is <em>not</em> a masked language model:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dsets</span> <span class="o">=</span> <span class="n">LanguageModelDatasets</span><span class="o">.</span><span class="n">from_dfs</span><span class="p">(</span>
    <span class="n">train_df</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
    <span class="n">text_col</span><span class="o">=</span><span class="s1">&#39;text&#39;</span><span class="p">,</span>
    <span class="n">tokenizer_name</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
    <span class="n">block_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
    <span class="n">masked_lm</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>No value for `max_length` set, automatically adjusting to the size of the model and including truncation
Sequence length set to: 1024




</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include note.html content='If you have a training and validation <code>DataFrame</code>, simply pass in the validation <code>DataFrame</code> as <code>valid_df=validation_dataframe</code> and do not pass in any <code>split_func</code> or <code>split_pct</code>. Everything else is the exact same' %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And finally turn it into some <a href="/adaptnlp/training.core.html#AdaptiveDataLoaders"><code>AdaptiveDataLoaders</code></a>.</p>
<p>These are just fastai's <code>DataLoaders</code> class, but it overrides a few functions to have it work nicely with HuggingFace's <code>Dataset</code> class</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="LanguageModelDatasets.dataloaders" class="doc_header"><code>LanguageModelDatasets.dataloaders</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/language_model.py#L202" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>LanguageModelDatasets.dataloaders</code>(<strong><code>batch_size</code></strong>=<em><code>8</code></em>, <strong><code>shuffle_train</code></strong>=<em><code>True</code></em>, <strong><code>collate_fn</code></strong>=<em><code>default_data_collator</code></em>, <strong><code>mlm_probability</code></strong>:<code>float</code>=<em><code>0.15</code></em>, <strong><code>path</code></strong>=<em><code>'.'</code></em>, <strong><code>device</code></strong>=<em><code>None</code></em>)</p>
</blockquote>
<p>Build DataLoaders from <code>self</code></p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>batch_size</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em> <p>A batch size</p></li>
</ul>
<ul>
<li><strong><code>shuffle_train</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em> <p>Whether to shuffle the training dataset</p></li>
</ul>
<ul>
<li><strong><code>collate_fn</code></strong> : <em><code>&lt;class 'function'&gt;</code></em>, <em>optional</em>    <p>A custom collation function</p></li>
</ul>
<ul>
<li><strong><code>mlm_probability</code></strong> : <em><code>&lt;class 'float'&gt;</code></em>, <em>optional</em>  <p>Token masking probablity for Masked Language Models</p></li>
</ul>
<ul>
<li><p><strong><code>path</code></strong> : <em><code>&lt;class 'str'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>device</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em></p>
</li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally, let's view a batch of data with the <code>show_batch</code> function:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span><span class="o">.</span><span class="n">show_batch</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Input</th>
      <th>Label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>acknowledge the real essence of what makes them the modern day Puerto Ricans,but barely mentioned how Africans influenced the way their Spanish is spoken, the food and music. She is so typical and I lost a lot of respect for her and will not support anything else she does. Also, since she wants to dance around her African-ness then she need not take more roles associated with blackness (i.e. Lackawanna Blues). We can find a prideful Black Latina next time (thank you Zoe Saldana,Gina Torres, Gina Ravera and Melissa DeSousa).&lt;br /&gt;&lt;br /&gt;To the Puerto Rican on here that said they are African and not "black"....thank you. We "blacks" certainly do not have anything in common with "you" so there is no love lost. But, since you are probably in the States and have benefited from the Civil Rights movement we would like for you refuse any decent human treatment you received courtesy of the blood,sweat and tears from the backs of the "blacks" you share nothing with.&lt;br /&gt;&lt;br /&gt;If I am correct Puerto Ricans have a terrible image in the media, but we blacks do not spend our time trying to disrespect you because we know that the media loves to exploits the low points and behaviors of all minorities to maintain mindless generalizations. However, you evidently have fed into the hype that one you are somehow white or superior...you are not. Also, you somehow feel compelled to believe that black culture is BET...again you are incorrect and need to take a vacation out of the hood. Try visiting Atlanta, Ga., Houston, Texas, Charlotte, N.C. Trust me none of those blacks want to claim your "culture" either.I think James Cameron might be becoming my favorite director because this is my second review of his movies. Anyway, everyone remembers the RMS Titanic. It was big, fast, and "unsinkable"... until April 1912. It was all over the news and one of the biggest tragedies ever. Well James Cameron decided to make a movie out of it but star two fictional characters to be in the spotlight instead of the ship. Well, onto the main review but let me remind you that this is all opinion and zero fact and the only fact that will be present is an event from the film.&lt;br /&gt;&lt;br /&gt;So our two main characters are Jack (Leonardo DiCaprio) and Rose (Kate Winslet). They're not annoying too much but</td>
      <td>acknowledge the real essence of what makes them the modern day Puerto Ricans,but barely mentioned how Africans influenced the way their Spanish is spoken, the food and music. She is so typical and I lost a lot of respect for her and will not support anything else she does. Also, since she wants to dance around her African-ness then she need not take more roles associated with blackness (i.e. Lackawanna Blues). We can find a prideful Black Latina next time (thank you Zoe Saldana,Gina Torres, Gina Ravera and Melissa DeSousa).&lt;br /&gt;&lt;br /&gt;To the Puerto Rican on here that said they are African and not "black"....thank you. We "blacks" certainly do not have anything in common with "you" so there is no love lost. But, since you are probably in the States and have benefited from the Civil Rights movement we would like for you refuse any decent human treatment you received courtesy of the blood,sweat and tears from the backs of the "blacks" you share nothing with.&lt;br /&gt;&lt;br /&gt;If I am correct Puerto Ricans have a terrible image in the media, but we blacks do not spend our time trying to disrespect you because we know that the media loves to exploits the low points and behaviors of all minorities to maintain mindless generalizations. However, you evidently have fed into the hype that one you are somehow white or superior...you are not. Also, you somehow feel compelled to believe that black culture is BET...again you are incorrect and need to take a vacation out of the hood. Try visiting Atlanta, Ga., Houston, Texas, Charlotte, N.C. Trust me none of those blacks want to claim your "culture" either.I think James Cameron might be becoming my favorite director because this is my second review of his movies. Anyway, everyone remembers the RMS Titanic. It was big, fast, and "unsinkable"... until April 1912. It was all over the news and one of the biggest tragedies ever. Well James Cameron decided to make a movie out of it but star two fictional characters to be in the spotlight instead of the ship. Well, onto the main review but let me remind you that this is all opinion and zero fact and the only fact that will be present is an event from the film.&lt;br /&gt;&lt;br /&gt;So our two main characters are Jack (Leonardo DiCaprio) and Rose (Kate Winslet). They're not annoying too much but</td>
    </tr>
    <tr>
      <th>1</th>
      <td>transformation from gruff to caring was so well realised, making it more believable than Scrooge in Christmas Carol. After Inspector Morse, this is Thaw's finest hour. He was matched earnestly by a young Nick Robinson, who gave a thoroughly convincing portrayal of an evacuee traumatised by the abusive relationship with his mother. The script and music made it worth the buy, and you also see Thaw playing the organ. Amazing! The most moving scene, was Willie finding out about Zak's death, and then Tom telling him about his deceased family who died of scarlatina. Buy this, you'll love it! 10/10 Bethany CoxI was required to watch the movie for my work, so I didn't pay for it (on the contrary, i got paid), but I still found the movie to suck far more than average. The jokes were lame, the two lead actresses... well, to use the "First wives club" division of women's ages in Hollywood, they are no longer in their "hot chick" age but more in their "district attorney" age. What angered me most about the movie was the main plot line, which pretty much completely plagiarized "Beavis &amp; Butthead Do America" (in which the boys are all jazzed up about some dude offering them money to "do his wife", not realizing they're expected to assassinate her). All in all, a bland piece of crap.Now my friends, films like "La Bête" (aka "The Beast" or "O Monstro")only can be done in the old continent :),in this film we see all: horses dirty sex, nymphomaniac kind off gorilla, non sense dialogs, etc, etc, etc... In the serious terms now,its an allegory, that men sometimes could be bestial, visceral and brutal,Walerian Borowczyk (the director) shows us the loss of innocence, sexual violence, rape and brutality. Its a astonishing cinematic experience, bizarre and full of grotesque scenes. For all fans of European shocking exploitation, i recommend this film.If you like this one i recommend: "Orloff Against the Invisible Man" and "Alterated States".This is an amazing film to watch or show young people. Aside from a very brief nude scene, it gives an interesting glimpse into colonial rule in Africa that you'll rarely find in other films. It does bear a superficial similarity to OUT OF Africa, but without all the romantic</td>
      <td>transformation from gruff to caring was so well realised, making it more believable than Scrooge in Christmas Carol. After Inspector Morse, this is Thaw's finest hour. He was matched earnestly by a young Nick Robinson, who gave a thoroughly convincing portrayal of an evacuee traumatised by the abusive relationship with his mother. The script and music made it worth the buy, and you also see Thaw playing the organ. Amazing! The most moving scene, was Willie finding out about Zak's death, and then Tom telling him about his deceased family who died of scarlatina. Buy this, you'll love it! 10/10 Bethany CoxI was required to watch the movie for my work, so I didn't pay for it (on the contrary, i got paid), but I still found the movie to suck far more than average. The jokes were lame, the two lead actresses... well, to use the "First wives club" division of women's ages in Hollywood, they are no longer in their "hot chick" age but more in their "district attorney" age. What angered me most about the movie was the main plot line, which pretty much completely plagiarized "Beavis &amp; Butthead Do America" (in which the boys are all jazzed up about some dude offering them money to "do his wife", not realizing they're expected to assassinate her). All in all, a bland piece of crap.Now my friends, films like "La Bête" (aka "The Beast" or "O Monstro")only can be done in the old continent :),in this film we see all: horses dirty sex, nymphomaniac kind off gorilla, non sense dialogs, etc, etc, etc... In the serious terms now,its an allegory, that men sometimes could be bestial, visceral and brutal,Walerian Borowczyk (the director) shows us the loss of innocence, sexual violence, rape and brutality. Its a astonishing cinematic experience, bizarre and full of grotesque scenes. For all fans of European shocking exploitation, i recommend this film.If you like this one i recommend: "Orloff Against the Invisible Man" and "Alterated States".This is an amazing film to watch or show young people. Aside from a very brief nude scene, it gives an interesting glimpse into colonial rule in Africa that you'll rarely find in other films. It does bear a superficial similarity to OUT OF Africa, but without all the romantic</td>
    </tr>
    <tr>
      <th>2</th>
      <td>br /&gt;The plot of "Genova" sounds promising, but unfortunately it is empty and without focus. The film only consists of a collection of scenes depicting the daily life of the family, such as swimming, taking piano lessons or cooking eggs. Most of such scenes are redundant and tiresome, completely failing to engage viewers emotionally. The ending is very disappointing as it is not spectacular, moving or emotional. I can safely say that I am disappointed and bored by "Genova" The only thing good about the film is the sunny weather and the beauty of Genova. "Genova" can serve as an extended tourism advertisement for the city, but not as a film to be enjoyed.As an adult I really did enjoy this one. I watched it with my 2 granddaughters and the 3 1/2 year old was fascinated and the 15 month old giggled at the mice.&lt;br /&gt;&lt;br /&gt;The music is fun and the animation is wonderful. This sequel does what Return to Neverland didn't accomplish. A good follow-up to the Cinderella story; but what becomes of Drusilla? Another sequel? I hope so!This may have been made for the hell of it, but it was most probably the worst film i've seen in years, The best thing about the entire DVD would be the case!!! I'm surprised that people took the time to make something so rubbish and yet spend money on it too, I'm glad i only rented. I suppose the real fans of this film would probably have to be sadistic and Gothic to care about it without taking in any CGI or any other effects for that matter, I hope Alex Chandon learnt a lesson about lighting and SFX to make a better film in the future, that is, if he is still in work.&lt;br /&gt;&lt;br /&gt;Notes to buyers this is extremely disappointing, DON'T BUY IT!!!!!There are no people like "Show People" Marion Davies (as Peggy Pepper) and William Haines (as Billy Boone). My introduction to Ms. Davies was a "clip" from this film; the delightfully spoofy one in which she lowers a scarf to reveal different emotions. My introduction to Mr. Haines was in viewing this film, presently; though, it's possible I've seen him in a less memorable role. Haines makes an incredible impression, when he joins Davies for a commissary meal - tossing his hat into the ring with some wonderful bits at the dining table. Indeed, Haines and Davies deliver</td>
      <td>br /&gt;The plot of "Genova" sounds promising, but unfortunately it is empty and without focus. The film only consists of a collection of scenes depicting the daily life of the family, such as swimming, taking piano lessons or cooking eggs. Most of such scenes are redundant and tiresome, completely failing to engage viewers emotionally. The ending is very disappointing as it is not spectacular, moving or emotional. I can safely say that I am disappointed and bored by "Genova" The only thing good about the film is the sunny weather and the beauty of Genova. "Genova" can serve as an extended tourism advertisement for the city, but not as a film to be enjoyed.As an adult I really did enjoy this one. I watched it with my 2 granddaughters and the 3 1/2 year old was fascinated and the 15 month old giggled at the mice.&lt;br /&gt;&lt;br /&gt;The music is fun and the animation is wonderful. This sequel does what Return to Neverland didn't accomplish. A good follow-up to the Cinderella story; but what becomes of Drusilla? Another sequel? I hope so!This may have been made for the hell of it, but it was most probably the worst film i've seen in years, The best thing about the entire DVD would be the case!!! I'm surprised that people took the time to make something so rubbish and yet spend money on it too, I'm glad i only rented. I suppose the real fans of this film would probably have to be sadistic and Gothic to care about it without taking in any CGI or any other effects for that matter, I hope Alex Chandon learnt a lesson about lighting and SFX to make a better film in the future, that is, if he is still in work.&lt;br /&gt;&lt;br /&gt;Notes to buyers this is extremely disappointing, DON'T BUY IT!!!!!There are no people like "Show People" Marion Davies (as Peggy Pepper) and William Haines (as Billy Boone). My introduction to Ms. Davies was a "clip" from this film; the delightfully spoofy one in which she lowers a scarf to reveal different emotions. My introduction to Mr. Haines was in viewing this film, presently; though, it's possible I've seen him in a less memorable role. Haines makes an incredible impression, when he joins Davies for a commissary meal - tossing his hat into the ring with some wonderful bits at the dining table. Indeed, Haines and Davies deliver</td>
    </tr>
    <tr>
      <th>3</th>
      <td>does. Is he right? Or is he a moron? Or is he just misguided by society? Find out all this and more when you watch {trumpet fanfare} ANCHORS AWEIGH!&lt;br /&gt;&lt;br /&gt;P.S. If you want to see Kathryn Grayson be anything but sickeningly sweet, try Kiss Me Kate (1953).Pathetic is the word. Bad acting, pathetic script, cheezy dialog and hip hop music &amp; fashion...what the hell was up with that? The directer of this movie acts as bad as the movie he made. If someone would have taken some time and effort to rework the whole thing, it may of had a chance. Bet the studios are still trying figure out how they could screw up up so badly.&lt;br /&gt;&lt;br /&gt;The absolute best thing about this movie was Stacey Dash...the Asian chick wasn't too bad neither. These too gals carried the whole movie. If it weren't for them I would have destroyed my copy of this movie.&lt;br /&gt;&lt;br /&gt;If any of those who have not seen this yet and had a notion to, don't waste your time...you'll only regret it later."What would you do?" is a question that will stick in your mind for weeks after watching the emotional Brokedown Palace. You will also be left wondering if Alice (Danes) was telling the truth or not - a issue that is left unresolved, and rightly so. This is a particularly well acted and beautifully shot film. Although it is slow at times, its pace is reflective of the story line - but a lot of the film will have you on the edge of your seat; wanting to know what happens next. The ending will also leave you imagining yourself in the shoes of the lead characters, which are brilliantly played by Kate Beckinsale and Claire Danes. Bill Pullman's performance is commendable, too.Wenders was great with Million $ Hotel.I don't know how he came up with this film! The idea of giving the situation after spt11 and the view of American Society is hopeful,that makes it 2 out of ten.But this is not a movie.Is that the best someone can do with a great idea(the west-east clash).There are important things going on in middle east and it is just issued on the screen of a MAC* with the fingers of an Amerian girl who is actually at the level of stupidity(because she is just ignorant about the</td>
      <td>does. Is he right? Or is he a moron? Or is he just misguided by society? Find out all this and more when you watch {trumpet fanfare} ANCHORS AWEIGH!&lt;br /&gt;&lt;br /&gt;P.S. If you want to see Kathryn Grayson be anything but sickeningly sweet, try Kiss Me Kate (1953).Pathetic is the word. Bad acting, pathetic script, cheezy dialog and hip hop music &amp; fashion...what the hell was up with that? The directer of this movie acts as bad as the movie he made. If someone would have taken some time and effort to rework the whole thing, it may of had a chance. Bet the studios are still trying figure out how they could screw up up so badly.&lt;br /&gt;&lt;br /&gt;The absolute best thing about this movie was Stacey Dash...the Asian chick wasn't too bad neither. These too gals carried the whole movie. If it weren't for them I would have destroyed my copy of this movie.&lt;br /&gt;&lt;br /&gt;If any of those who have not seen this yet and had a notion to, don't waste your time...you'll only regret it later."What would you do?" is a question that will stick in your mind for weeks after watching the emotional Brokedown Palace. You will also be left wondering if Alice (Danes) was telling the truth or not - a issue that is left unresolved, and rightly so. This is a particularly well acted and beautifully shot film. Although it is slow at times, its pace is reflective of the story line - but a lot of the film will have you on the edge of your seat; wanting to know what happens next. The ending will also leave you imagining yourself in the shoes of the lead characters, which are brilliantly played by Kate Beckinsale and Claire Danes. Bill Pullman's performance is commendable, too.Wenders was great with Million $ Hotel.I don't know how he came up with this film! The idea of giving the situation after spt11 and the view of American Society is hopeful,that makes it 2 out of ten.But this is not a movie.Is that the best someone can do with a great idea(the west-east clash).There are important things going on in middle east and it is just issued on the screen of a MAC* with the fingers of an Amerian girl who is actually at the level of stupidity(because she is just ignorant about the</td>
    </tr>
    <tr>
      <th>4</th>
      <td>to life alone after 45 years of marriage. He also has to solve the problem of the family milch cow, Tulip, which refuses to allow itself to be milked. Until, that is, he visualizes his wife who was the one who used to milk Tulip.&lt;br /&gt;&lt;br /&gt;Tulip is based on a real story told in Griffith's family, of her grandparents' generation. The film is a nostalgic look back at a disappearing way of life, one where people still felt some sense of responsibility for each other, set in the lush green Victorian (the Australian state, not the era) countryside.&lt;br /&gt;&lt;br /&gt;Writer and director Griffiths evidently has further ambitions in both areas, and this multiple award-winning 15-minute short is a fine beginning to her reel.How to Lose Friends &amp; Alienate People is in all honesty one of the best comedies I've seen this year along with Pineapple Express and Step Brothers. Its not one of those "gross out" comedies that heavily relies on fart jokes and toilet humor but instead moves at an affable pace and you will be easily attached to the unfolding narrative. Simon Pegg nails it in the coffin with his hilarious portrayal of a fish-out-of-water character and is quickly detaching himself from the tripod he once belonged to back in England (the other two would be Nick Frost and Edgar Wright). Getting yourself in the top of the Hollywood food chain is a hard thing to do as we can clearly see with Pegg, his first jab at the lead role was David Schwimmer's comedy Run Fatboy Run but it received lukewarm reviews from critics and audiences alike. His second try is this movie, got fairly positive reviews from the majority but was a flop in the box office. I, for one still haven't lost faith in him and I'll still be there whenever he wants to take that third shot for glory.&lt;br /&gt;&lt;br /&gt;Other characters were well cast from Jeff Bridges to Danny Huston and Gillian Anderson. Surprisingly, Kirsten Dunst in my opinion fared well in this movie as the love angle to Pegg's character however, the spark that I saw in Interview with the Vampire is still lost. She needs to find it, fast or she might suffer the consequences of being lost in the land of "rom-coms" forever."Look, I know this may suck right now, but pain is temporary, film is forever. Whatever you do right now is burned into celluloid for all</td>
      <td>to life alone after 45 years of marriage. He also has to solve the problem of the family milch cow, Tulip, which refuses to allow itself to be milked. Until, that is, he visualizes his wife who was the one who used to milk Tulip.&lt;br /&gt;&lt;br /&gt;Tulip is based on a real story told in Griffith's family, of her grandparents' generation. The film is a nostalgic look back at a disappearing way of life, one where people still felt some sense of responsibility for each other, set in the lush green Victorian (the Australian state, not the era) countryside.&lt;br /&gt;&lt;br /&gt;Writer and director Griffiths evidently has further ambitions in both areas, and this multiple award-winning 15-minute short is a fine beginning to her reel.How to Lose Friends &amp; Alienate People is in all honesty one of the best comedies I've seen this year along with Pineapple Express and Step Brothers. Its not one of those "gross out" comedies that heavily relies on fart jokes and toilet humor but instead moves at an affable pace and you will be easily attached to the unfolding narrative. Simon Pegg nails it in the coffin with his hilarious portrayal of a fish-out-of-water character and is quickly detaching himself from the tripod he once belonged to back in England (the other two would be Nick Frost and Edgar Wright). Getting yourself in the top of the Hollywood food chain is a hard thing to do as we can clearly see with Pegg, his first jab at the lead role was David Schwimmer's comedy Run Fatboy Run but it received lukewarm reviews from critics and audiences alike. His second try is this movie, got fairly positive reviews from the majority but was a flop in the box office. I, for one still haven't lost faith in him and I'll still be there whenever he wants to take that third shot for glory.&lt;br /&gt;&lt;br /&gt;Other characters were well cast from Jeff Bridges to Danny Huston and Gillian Anderson. Surprisingly, Kirsten Dunst in my opinion fared well in this movie as the love angle to Pegg's character however, the spark that I saw in Interview with the Vampire is still lost. She needs to find it, fast or she might suffer the consequences of being lost in the land of "rom-coms" forever."Look, I know this may suck right now, but pain is temporary, film is forever. Whatever you do right now is burned into celluloid for all</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>When training a language model, the input and output are made to be the exact same, so there isn't a shown noticable difference here.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Building-Tuner">Building <code>Tuner</code><a class="anchor-link" href="#Building-Tuner"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next we need to build a compatible <code>Tuner</code> for our problem. These tuners contain good defaults for our problem space, including loss functions and metrics.</p>
<p>First let's import the <a href="/adaptnlp/training.language_model.html#LanguageModelTuner"><code>LanguageModelTuner</code></a> and view it's documentation</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">LanguageModelTuner</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="LanguageModelTuner" class="doc_header"><code>class</code> <code>LanguageModelTuner</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/language_model.py#L228" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>LanguageModelTuner</code>(<strong><code>dls</code></strong>:<code>DataLoaders</code>, <strong><code>model_name</code></strong>, <strong><code>tokenizer</code></strong>=<em><code>None</code></em>, <strong><code>language_model_type</code></strong>:<code>LMType</code>=<em><code>'causal'</code></em>, <strong><code>loss_func</code></strong>=<em><code>CrossEntropyLoss()</code></em>, <strong><code>metrics</code></strong>=<em><code>[&lt;fastai.metrics.Perplexity object at 0x7f8b6b1b84c0&gt;]</code></em>, <strong><code>opt_func</code></strong>=<em><code>Adam</code></em>, <strong><code>additional_cbs</code></strong>=<em><code>None</code></em>, <strong><code>expose_fastai_api</code></strong>=<em><code>False</code></em>, <strong>**<code>kwargs</code></strong>) :: <a href="/adaptnlp/training.core.html#AdaptiveTuner"><code>AdaptiveTuner</code></a></p>
</blockquote>
<p>An <a href="/adaptnlp/training.core.html#AdaptiveTuner"><code>AdaptiveTuner</code></a> with good defaults for Language Model fine-tuning
<strong>Valid kwargs and defaults:</strong></p>
<ul>
<li><code>lr</code>:float = 0.001</li>
<li><code>splitter</code>:function = <code>trainable_params</code></li>
<li><code>cbs</code>:list = None</li>
<li><code>path</code>:Path = None</li>
<li><code>model_dir</code>:Path = 'models'</li>
<li><code>wd</code>:float = None</li>
<li><code>wd_bn_bias</code>:bool = False</li>
<li><code>train_bn</code>:bool = True</li>
<li><code>moms</code>: tuple(float) = (0.95, 0.85, 0.95)</li>
</ul>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>dls</code></strong> : <em><code>&lt;class 'fastai.data.core.DataLoaders'&gt;</code></em>   <p>A set of DataLoaders or AdaptiveDataLoaders</p></li>
</ul>
<ul>
<li><strong><code>model_name</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em>  <p>A HuggingFace model</p></li>
</ul>
<ul>
<li><strong><code>tokenizer</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em> <p>A HuggingFace tokenizer</p></li>
</ul>
<ul>
<li><strong><code>language_model_type</code></strong> : <em><code>&lt;class 'fastcore.basics.LMType'&gt;</code></em>, <em>optional</em> <p>The type of language model to use</p></li>
</ul>
<ul>
<li><strong><code>loss_func</code></strong> : <em><code>&lt;class 'fastai.losses.CrossEntropyLossFlat'&gt;</code></em>, <em>optional</em>   <p>A loss function</p></li>
</ul>
<ul>
<li><strong><code>metrics</code></strong> : <em><code>&lt;class 'list'&gt;</code></em>, <em>optional</em>   <p>Metrics to monitor the training with</p></li>
</ul>
<ul>
<li><strong><code>opt_func</code></strong> : <em><code>&lt;class 'function'&gt;</code></em>, <em>optional</em>  <p>A fastai or torch Optimizer</p></li>
</ul>
<ul>
<li><strong><code>additional_cbs</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em>    <p>Additional Callbacks to have always tied to the Tuner,</p></li>
</ul>
<ul>
<li><strong><code>expose_fastai_api</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em> <p>Whether to expose the fastai API</p></li>
</ul>
<ul>
<li><strong><code>kwargs</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next we'll pass in our <code>DataLoaders</code>, the name of our model, and the tokenizer:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include note.html content='If you are not using the data API (<a href="/adaptnlp/training.core.html#TaskDatasets"><code>TaskDatasets</code></a>, <a href="/adaptnlp/training.sequence_classification.html#SequenceClassificationDatasets"><code>SequenceClassificationDatasets</code></a>, etc), you need to pass in the tokenizer to the constructor as well with <code>tokenizer=tokenizer</code>' %}</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span> <span class="o">=</span> <span class="n">LanguageModelTuner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">dls</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>By default we can see that it used <code>CrossEntropyLoss</code> as our loss function, and <code>Perplexity</code> as our metric</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span><span class="o">.</span><span class="n">loss_func</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>FlattenedLoss of CrossEntropyLoss()</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="p">[</span><span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">tuner</span><span class="o">.</span><span class="n">metrics</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>perplexity
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally we just need to train our model!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Fine-Tuning">Fine-Tuning<a class="anchor-link" href="#Fine-Tuning"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To fine-tune, AdaptNLP's tuner class provides only a few functions to work with. The important ones are the <code>tune</code> and <code>lr_find</code> class.</p>
<p>As the <code>Tuner</code> uses <code>fastai</code> under the hood, <code>lr_find</code> calls fastai's Learning Rate Finder to help us pick a learning rate. Let's do that now:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="AdaptiveTuner.lr_find" class="doc_header"><code>AdaptiveTuner.lr_find</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/core.py#L385" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>AdaptiveTuner.lr_find</code>(<strong><code>start_lr</code></strong>=<em><code>1e-07</code></em>, <strong><code>end_lr</code></strong>=<em><code>10</code></em>, <strong><code>num_it</code></strong>=<em><code>100</code></em>, <strong><code>stop_div</code></strong>=<em><code>True</code></em>, <strong><code>show_plot</code></strong>=<em><code>True</code></em>, <strong><code>suggest_funcs</code></strong>=<em><code>valley</code></em>)</p>
</blockquote>
<p>Runs fastai's <code>LR Finder</code></p>
<p><strong>Parameters:</strong></p>
<ul>
<li><p><strong><code>start_lr</code></strong> : <em><code>&lt;class 'float'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>end_lr</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>num_it</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>stop_div</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>show_plot</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>suggest_funcs</code></strong> : <em><code>&lt;class 'function'&gt;</code></em>, <em>optional</em></p>
</li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/opt/venv/lib/python3.8/site-packages/fastai/callback/schedule.py:270: UserWarning: color is redundantly defined by the &#39;color&#39; keyword argument and the fmt string &#34;ro&#34; (-&gt; color=&#39;r&#39;). The keyword argument will take precedence.
  ax.plot(val, idx, &#39;ro&#39;, label=nm, c=color)
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>SuggestedLRs(valley=0.0003311311302240938)</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It recommends a learning rate of around 5e-5, so we will use that.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr</span> <span class="o">=</span> <span class="mf">5e-5</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's look at the documentation for <code>tune</code>:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="AdaptiveTuner.tune" class="doc_header"><code>AdaptiveTuner.tune</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/core.py#L371" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>AdaptiveTuner.tune</code>(<strong><code>epochs</code></strong>:<code>int</code>, <strong><code>lr</code></strong>:<code>float</code>=<em><code>None</code></em>, <strong><code>strategy</code></strong>:<code>Strategy</code>=<em><code>'fit_one_cycle'</code></em>, <strong><code>callbacks</code></strong>:<code>list</code>=<em><code>[]</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Fine tune <code>self.model</code> for <code>epochs</code> with an <code>lr</code> and <code>strategy</code></p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>epochs</code></strong> : <em><code>&lt;class 'int'&gt;</code></em> <p>Number of iterations to train for</p></li>
</ul>
<ul>
<li><strong><code>lr</code></strong> : <em><code>&lt;class 'float'&gt;</code></em>, <em>optional</em>   <p>If None, finds a new learning rate and uses suggestion_method</p></li>
</ul>
<ul>
<li><strong><code>strategy</code></strong> : <em><code>&lt;class 'fastcore.basics.Strategy'&gt;</code></em>, <em>optional</em>  <p>A fitting method</p></li>
</ul>
<ul>
<li><strong><code>callbacks</code></strong> : <em><code>&lt;class 'list'&gt;</code></em>, <em>optional</em> <p>Extra fastai Callbacks</p></li>
</ul>
<ul>
<li><strong><code>kwargs</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can pass in a number of epochs, a learning rate, a strategy, and additional fastai callbacks to call.</p>
<p>Valid strategies live in the <code>Strategy</code> namespace class, and consist of:</p>
<ul>
<li>OneCycle (Also called the <a href="https://docs.fast.ai/callback.schedule.html#Learner.fit_one_cycle">One-Cycle Policy</a>)</li>
<li><a href="https://docs.fast.ai/callback.schedule.html#Learner.fit_flat_cos">CosineAnnealing</a></li>
<li><a href="https://docs.fast.ai/callback.schedule.html#Learner.fit_sgdr">SGDR</a></li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">Strategy</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this tutorial we will train with the One-Cycle policy, as currently it is one of the best schedulers to use.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span><span class="o">.</span><span class="n">tune</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="n">Strategy</span><span class="o">.</span><span class="n">OneCycle</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>perplexity</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>4.060410</td>
      <td>3.894190</td>
      <td>49.116245</td>
      <td>00:56</td>
    </tr>
    <tr>
      <td>1</td>
      <td>3.961307</td>
      <td>3.877189</td>
      <td>48.288303</td>
      <td>00:55</td>
    </tr>
    <tr>
      <td>2</td>
      <td>3.893311</td>
      <td>3.877568</td>
      <td>48.306591</td>
      <td>00:54</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Saving-Model">Saving Model<a class="anchor-link" href="#Saving-Model"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now that we have a trained model, let's save those weights away.</p>
<p>Calling <code>tuner.save</code> will save both the model and the tokenizer in the same format as how HuggingFace does:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="AdaptiveTuner.save" class="doc_header"><code>AdaptiveTuner.save</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/core.py#L393" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>AdaptiveTuner.save</code>(<strong><code>save_directory</code></strong>)</p>
</blockquote>
<p>Save a pretrained model to a <code>save_directory</code></p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>save_directory</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em>  <p>A folder to save our model to</p></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;good_model&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&#39;good_model&#39;</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Performing-Inference">Performing Inference<a class="anchor-link" href="#Performing-Inference"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There are two ways to get predictions, the first is with the <code>.predict</code> method in our <code>tuner</code>. This is great for if you just finished training and want to see how your model performs on some new data!
The other method is with AdaptNLP's inference API, which we will show afterwards</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="In-Tuner">In Tuner<a class="anchor-link" href="#In-Tuner"> </a></h3><p>First let's write a sentence to test with</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sentence</span> <span class="o">=</span> <span class="s2">&quot;Hugh Jackman is a terrible &quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And then predict with it:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="LanguageModelTuner.predict" class="doc_header"><code>LanguageModelTuner.predict</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/language_model.py#L293" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>LanguageModelTuner.predict</code>(<strong><code>text</code></strong>:<code>Union</code>[<code>List</code>[<code>str</code>], <code>str</code>], <strong><code>bs</code></strong>:<code>int</code>=<em><code>64</code></em>, <strong><code>num_tokens_to_produce</code></strong>:<code>int</code>=<em><code>50</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Predict some <code>text</code> for sequence classification with the currently loaded model</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>text</code></strong> : <em><code>typing.Union[typing.List[str], str]</code></em> <p>Some text or list of texts to do inference with</p></li>
</ul>
<ul>
<li><strong><code>bs</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em> <p>A batch size to use for multiple texts</p></li>
</ul>
<ul>
<li><strong><code>num_tokens_to_produce</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em>  <p>Number of tokens to generate</p></li>
</ul>
<ul>
<li><strong><code>kwargs</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">num_tokens_to_produce</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

    <div>
        <style>
            /* Turns off some styling */
            progress {
                /* gets rid of default border in Firefox and Opera. */
                border: none;
                /* Needs to be in here for Safari polyfill so background images work as expected. */
                background-size: auto;
            }
            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
                background: #F44336;
            }
        </style>
      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>
      100.00% [1/1 00:00<00:00]
    </div>
    
</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;generated_text&#39;: [&#39;Hugh Jackman is a terrible icky, and very funny, character.&#39;]}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="With-the-Inference-API">With the Inference API<a class="anchor-link" href="#With-the-Inference-API"> </a></h3><p>Next we will use the <a href="/adaptnlp/text_generation.html#EasyTextGenerator"><code>EasyTextGenerator</code></a> class, which AdaptNLP offers:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">EasyTextGenerator</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We simply construct the class:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">classifier</span> <span class="o">=</span> <span class="n">EasyTextGenerator</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And call the <code>tag_text</code> method, passing in the sentence, the location of our saved model, and some names for our classes:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">classifier</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
    <span class="n">sentence</span><span class="p">,</span>
    <span class="n">model_name_or_path</span><span class="o">=</span><span class="s1">&#39;good_model&#39;</span><span class="p">,</span>
    <span class="n">num_tokens_to_produce</span><span class="o">=</span><span class="mi">8</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

    <div>
        <style>
            /* Turns off some styling */
            progress {
                /* gets rid of default border in Firefox and Opera. */
                border: none;
                /* Needs to be in here for Safari polyfill so background images work as expected. */
                background-size: auto;
            }
            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
                background: #F44336;
            }
        </style>
      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>
      100.00% [1/1 00:00<00:00]
    </div>
    
</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;generated_text&#39;: [&#39;Hugh Jackman is a terrible icky, and very funny, character.&#39;]}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And we got the exact same output!</p>

</div>
</div>
</div>
</div>
 

