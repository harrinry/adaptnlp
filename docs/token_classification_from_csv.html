---

title: Tutorial: Fine-Tuning Token Classification on CSV files with CoNLL 2003


keywords: fastai
sidebar: home_sidebar

summary: "Tuning a Token Classification (Named Entity Recognition) model on the CoNLL 2003 dataset"
description: "Tuning a Token Classification (Named Entity Recognition) model on the CoNLL 2003 dataset"
nb_path: "nbs/training_api_tutorials/token_classification/token_classification_from_csv.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/training_api_tutorials/token_classification/token_classification_from_csv.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Introduction">Introduction<a class="anchor-link" href="#Introduction"> </a></h2><p>In this tutorial we will be showing an end-to-end example of fine-tuning a Transformer for token classification on a custom dataset in CSV file format.</p>
<p>By the end of this you should be able to:</p>
<ol>
<li>Build a dataset with the <a href="/adaptnlp/training.token_classification.html#TokenClassificationDatasets"><code>TokenClassificationDatasets</code></a> class, and its DataLoaders</li>
<li>Build a <a href="/adaptnlp/training.token_classification.html#TokenClassificationTuner"><code>TokenClassificationTuner</code></a> quickly, find a good learning rate, and train with the One-Cycle Policy</li>
<li>Save that model away, to be used with deployment or other HuggingFace libraries</li>
<li>Apply inference using both the <code>Tuner</code>'s available function as well as with the <a href="/adaptnlp/token_classification.html#EasyTokenTagger"><code>EasyTokenTagger</code></a> class within AdaptNLP</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Installing-the-Library">Installing the Library<a class="anchor-link" href="#Installing-the-Library"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This tutorial utilizies the latest AdaptNLP version, as well as parts of the <code>fastai</code> library. Please run the below code to install them:</p>
<div class="highlight"><pre><span></span><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">adaptnlp</span> <span class="o">-</span><span class="n">U</span>
</pre></div>
<p>(or <code>pip3</code>)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Getting-the-Dataset">Getting the Dataset<a class="anchor-link" href="#Getting-the-Dataset"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>First we need a dataset. We will use the <code>HuggingFace</code> library to download the <code>conll2003</code> dataset and convert it to a CSV file. This may seem counterintuitive, but it works for demonstrational purposes. In practice you would use a custom CSV file.</p>
<p><code>CoNLL 2003</code> is a named entity recognition (NER) dataset which contains the following named entities: persons, locations, organizations, and names of miscellaneous entities that do not belong to the previous three groups. It follows the IOB2 tagging scheme.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>

<span class="n">dsets</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;conll2003&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Reusing dataset conll2003 (/home/ubuntu/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/40e7cb6bcc374f7c349c83acd1e9352a4f09474eb691f64f364ee62eb65d0ca6)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For the purpose of example, we'll take the train subset and convert it to CSV file. The <code>tokens</code> and <code>ner_tags</code> of the csv file will serve as the tokens and labels for our dataset.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dset</span> <span class="o">=</span> <span class="n">dsets</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span>

<span class="c1"># going through pandas to ensure data types are correct for the csv</span>
<span class="n">dset</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s1">&#39;pandas&#39;</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">dset</span><span class="p">[:]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;tokens&#39;</span><span class="p">,</span> <span class="s1">&#39;ner_tags&#39;</span><span class="p">]]</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;ner_tags&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;ner_tags&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;tokens&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;tokens&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;/tmp/conll2003.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now that we have the dataset, and we know the format it is in, let's pick a viable model to train with.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Picking-a-Model-with-the-Hub">Picking a Model with the Hub<a class="anchor-link" href="#Picking-a-Model-with-the-Hub"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>AdaptNLP has a <a href="/adaptnlp/model_hub.html#HFModelHub"><code>HFModelHub</code></a> class that allows you to communicate with the HuggingFace Hub and pick a model from it, as well as a namespace <code>HF_TASKS</code> class with a list of valid tasks we can search by.</p>
<p>Let's try and find one suitable for token classification.</p>
<p>First we need to import the class and generate an instance of it:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">HFModelHub</span><span class="p">,</span> <span class="n">HF_TASKS</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hub</span> <span class="o">=</span> <span class="n">HFModelHub</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next we can search for a model:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">models</span> <span class="o">=</span> <span class="n">hub</span><span class="o">.</span><span class="n">search_model_by_task</span><span class="p">(</span><span class="n">HF_TASKS</span><span class="o">.</span><span class="n">TOKEN_CLASSIFICATION</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's look at a few:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">models</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[Model Name: xlm-roberta-large-finetuned-conll03-english, Tasks: [token-classification],
 Model Name: xlm-roberta-large-finetuned-conll03-german, Tasks: [token-classification]]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>These are models specifically tagged with the <code>token-classification</code> tag, so you may not see a few models you would expect such as <code>bert_base_cased</code>.</p>
<p>Since both of these models have already been fine-tuned on the <code>CoNLL 2003</code> dataset, let's choose a basic pre-trained model <code>distilbert-base-uncased</code>:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model_name</span> <span class="o">=</span> <span class="s1">&#39;distilbert-base-uncased&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In general, if you don't need to go through the <a href="/adaptnlp/model_hub.html#HFModelHub"><code>HFModelHub</code></a> if you know which model you'd like to use already. You can always just pass in the string name of a model such as "bert-base-cased"</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Building-TaskDatasets-with-TokenClassificationDatasets">Building <a href="/adaptnlp/training.core.html#TaskDatasets"><code>TaskDatasets</code></a> with <a href="/adaptnlp/training.token_classification.html#TokenClassificationDatasets"><code>TokenClassificationDatasets</code></a><a class="anchor-link" href="#Building-TaskDatasets-with-TokenClassificationDatasets"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Each task has a high-level data wrapper around the <a href="/adaptnlp/training.core.html#TaskDatasets"><code>TaskDatasets</code></a> class. In our case this is the <a href="/adaptnlp/training.token_classification.html#TokenClassificationDatasets"><code>TokenClassificationDatasets</code></a> class:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">TokenClassificationDatasets</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There are multiple different constructors for the <a href="/adaptnlp/training.token_classification.html#TokenClassificationDatasets"><code>TokenClassificationDatasets</code></a> class, and you should never call the main constructor directly.</p>
<p>We will be using <code>from_csvs</code>:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="TokenClassificationDatasets.from_csvs" class="doc_header"><code>TokenClassificationDatasets.from_csvs</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/token_classification.py#L130" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>TokenClassificationDatasets.from_csvs</code>(<strong><code>train_csv</code></strong>:<code>Path</code>, <strong><code>token_col</code></strong>:<code>str</code>, <strong><code>tag_col</code></strong>:<code>str</code>, <strong><code>entity_mapping</code></strong>:<code>dict</code>, <strong><code>tokenizer_name</code></strong>:<code>str</code>, <strong><code>tokenize</code></strong>:<code>bool</code>=<em><code>True</code></em>, <strong><code>valid_csv</code></strong>:<code>Path</code>=<em><code>None</code></em>, <strong><code>split_func</code></strong>=<em><code>None</code></em>, <strong><code>split_pct</code></strong>=<em><code>0.2</code></em>, <strong><code>tokenize_kwargs</code></strong>:<code>dict</code>=<em><code>{}</code></em>, <strong><code>auto_kwargs</code></strong>:<code>dict</code>=<em><code>{}</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Builds <a href="/adaptnlp/training.sequence_classification.html#SequenceClassificationDatasets"><code>SequenceClassificationDatasets</code></a> from a single csv or set of csvs. A convience constructor for <code>from_dfs</code></p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>train_csv</code></strong> : <em><code>&lt;class 'pathlib.Path'&gt;</code></em> <p>A training csv file</p></li>
</ul>
<ul>
<li><strong><code>token_col</code></strong> : <em><code>&lt;class 'str'&gt;</code></em>  <p>The name of the token column</p></li>
</ul>
<ul>
<li><strong><code>tag_col</code></strong> : <em><code>&lt;class 'str'&gt;</code></em>    <p>The name of the tag column</p></li>
</ul>
<ul>
<li><strong><code>entity_mapping</code></strong> : <em><code>&lt;class 'dict'&gt;</code></em>    <p>A mapping of entity names to encoded labels</p></li>
</ul>
<ul>
<li><strong><code>tokenizer_name</code></strong> : <em><code>&lt;class 'str'&gt;</code></em> <p>The name of the tokenizer</p></li>
</ul>
<ul>
<li><strong><code>tokenize</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em>  <p>Whether to tokenize immediately</p></li>
</ul>
<ul>
<li><strong><code>valid_csv</code></strong> : <em><code>&lt;class 'pathlib.Path'&gt;</code></em>, <em>optional</em> <p>An optional validation csv</p></li>
</ul>
<ul>
<li><strong><code>split_func</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em>    <p>Optionally a splitting function similar to RandomSplitter</p></li>
</ul>
<ul>
<li><strong><code>split_pct</code></strong> : <em><code>&lt;class 'float'&gt;</code></em>, <em>optional</em>    <p>What % to split the train df</p></li>
</ul>
<ul>
<li><strong><code>tokenize_kwargs</code></strong> : <em><code>&lt;class 'dict'&gt;</code></em>, <em>optional</em>   <p>kwargs for the tokenize function</p></li>
</ul>
<ul>
<li><strong><code>auto_kwargs</code></strong> : <em><code>&lt;class 'dict'&gt;</code></em>, <em>optional</em>   <p>kwargs for the AutoTokenizer.from_pretrained constructor</p></li>
</ul>
<ul>
<li><strong><code>kwargs</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Anything you would normally pass to the tokenizer call (such as <code>max_length</code>, <code>padding</code>) should go in <code>tokenize_kwargs</code>, and anything going to the <code>AutoTokenizer.from_pretrained</code> constructor should be passed to the <code>auto_kwargs</code>.</p>
<p><strong>Important</strong>: Because our dataset is already tokenized, when we try to encode the tokens, we may end up with sub-tokens. This will cause our labels to no longer align with the number of tokens. In order to take this into account, the following arguments should be passed to the tokenizer:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tokenize_kwargs</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;truncation&#39;</span><span class="p">:</span><span class="kc">True</span><span class="p">,</span> 
    <span class="s1">&#39;is_split_into_words&#39;</span><span class="p">:</span><span class="kc">True</span><span class="p">,</span> 
    <span class="s1">&#39;padding&#39;</span><span class="p">:</span><span class="s1">&#39;max_length&#39;</span><span class="p">,</span> 
    <span class="s1">&#39;return_offsets_mapping&#39;</span><span class="p">:</span><span class="kc">True</span>
<span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We will also need to provide a mapping between the labels and the entities:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">entity_mapping</span> <span class="o">=</span> <span class="p">{</span>
    <span class="mi">0</span><span class="p">:</span> <span class="s1">&#39;O&#39;</span><span class="p">,</span>
    <span class="mi">1</span><span class="p">:</span> <span class="s1">&#39;B-PER&#39;</span><span class="p">,</span>
    <span class="mi">2</span><span class="p">:</span> <span class="s1">&#39;I-PER&#39;</span><span class="p">,</span>
    <span class="mi">3</span><span class="p">:</span> <span class="s1">&#39;B-ORG&#39;</span><span class="p">,</span>
    <span class="mi">4</span><span class="p">:</span> <span class="s1">&#39;I-ORG&#39;</span><span class="p">,</span>
    <span class="mi">5</span><span class="p">:</span> <span class="s1">&#39;B-LOC&#39;</span><span class="p">,</span>
    <span class="mi">6</span><span class="p">:</span> <span class="s1">&#39;I-LOC&#39;</span><span class="p">,</span>
    <span class="mi">7</span><span class="p">:</span> <span class="s1">&#39;B-MISC&#39;</span><span class="p">,</span>
    <span class="mi">8</span><span class="p">:</span> <span class="s1">&#39;I-MISC&#39;</span>
<span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In our case we only have a <code>train_csv</code>, so we should specify what percent to split into train and validation sets.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">ast</span> <span class="kn">import</span> <span class="n">literal_eval</span>

<span class="n">dsets</span> <span class="o">=</span> <span class="n">TokenClassificationDatasets</span><span class="o">.</span><span class="n">from_csvs</span><span class="p">(</span>
    <span class="s1">&#39;/tmp/conll2003.csv&#39;</span><span class="p">,</span>
    <span class="s1">&#39;tokens&#39;</span><span class="p">,</span>
    <span class="s1">&#39;ner_tags&#39;</span><span class="p">,</span>
    <span class="n">entity_mapping</span><span class="p">,</span>
    <span class="n">tokenizer_name</span> <span class="o">=</span> <span class="n">model_name</span><span class="p">,</span>
    <span class="n">tokenize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">tokenize_kwargs</span> <span class="o">=</span> <span class="n">tokenize_kwargs</span><span class="p">,</span>
    <span class="n">split_pct</span><span class="o">=</span><span class="mf">.2</span><span class="p">,</span>
    <span class="n">converters</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;tokens&#39;</span><span class="p">:</span> <span class="n">literal_eval</span><span class="p">,</span> <span class="s1">&#39;ner_tags&#39;</span><span class="p">:</span> <span class="n">literal_eval</span><span class="p">}</span>  <span class="c1"># kwarg to pd.read_csv</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>No value for `max_length` set, automatically adjusting to the size of the model and including truncation
Sequence length set to: 512


</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include note.html content='If you have a training and validation <code>CSVs</code>, simply pass in the validation <code>CSV</code> as <code>valid_csv=validation_csv</code> and do not pass in any <code>split_func</code> or <code>split_pct</code>. Everything else is the exact same' %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And finally turn it into some <a href="/adaptnlp/training.core.html#AdaptiveDataLoaders"><code>AdaptiveDataLoaders</code></a>.</p>
<p>These are just fastai's <code>DataLoaders</code> class, but it overrides a few functions to have it work nicely with HuggingFace's <code>Dataset</code> class</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="TokenClassificationDatasets.dataloaders" class="doc_header"><code>TokenClassificationDatasets.dataloaders</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/token_classification.py#L165" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>TokenClassificationDatasets.dataloaders</code>(<strong><code>batch_size</code></strong>:<code>int</code>=<em><code>16</code></em>, <strong><code>shuffle_train</code></strong>:<code>bool</code>=<em><code>True</code></em>, <strong><code>collate_fn</code></strong>:<code>callable</code>=<em><code>None</code></em>, <strong><code>path</code></strong>=<em><code>'.'</code></em>, <strong><code>device</code></strong>=<em><code>None</code></em>)</p>
</blockquote>
<p>Build DataLoaders from <code>self</code></p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>batch_size</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em> <p>A batch size</p></li>
</ul>
<ul>
<li><strong><code>shuffle_train</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em> <p>Whether to shuffle the training dataset</p></li>
</ul>
<ul>
<li><strong><code>collate_fn</code></strong> : <em><code>&lt;built-in function callable&gt;</code></em>, <em>optional</em>  <p>A custom collation function</p></li>
</ul>
<ul>
<li><p><strong><code>path</code></strong> : <em><code>&lt;class 'str'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>device</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em></p>
</li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally, let's view a batch of data with the <code>show_batch</code> function:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span><span class="o">.</span><span class="n">show_batch</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Input</th>
      <th>Labels</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>jakarta 1996 - 08 - 27</td>
      <td>[B-LOC, O]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>" i think we would have liked to have more of ingwe but it's the question of adding value.</td>
      <td>[O, O, O, O, O, O, O, O, O, O, O, B-ORG, O, O, O, O, O, O, O, O, O]</td>
    </tr>
    <tr>
      <th>2</th>
      <td>italian cabinet approves television decree.</td>
      <td>[B-MISC, O, O, O, O, O]</td>
    </tr>
    <tr>
      <th>3</th>
      <td>nottinghamshire 446 - 9 declared and 53 - 0.</td>
      <td>[B-ORG, O, O, O, O, O]</td>
    </tr>
    <tr>
      <th>4</th>
      <td>during the three - month trial, the court dealt mainly with issues of the nsdap - ao's " ns kampfruf " ( " national socialist battle cry " ) magazine, filled with references to aryan supremacy and defamatory statements about jews.</td>
      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, B-ORG, O, O, B-ORG, I-ORG, O, O, O, B-ORG, I-ORG, I-ORG, I-ORG, O, O, O, O, O, O, O, O, B-MISC, O, O, O, O, O, B-MISC, O]</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Building-Tuner">Building <code>Tuner</code><a class="anchor-link" href="#Building-Tuner"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next we need to build a compatible <code>Tuner</code> for our problem. These tuners contain good defaults for our problem space, including loss functions and metrics.</p>
<p>First let's import the <a href="/adaptnlp/training.token_classification.html#TokenClassificationTuner"><code>TokenClassificationTuner</code></a> and view it's documentation</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="TokenClassificationTuner" class="doc_header"><code>class</code> <code>TokenClassificationTuner</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/token_classification.py#L254" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>TokenClassificationTuner</code>(<strong><code>dls</code></strong>:<code>DataLoaders</code>, <strong><code>model_name</code></strong>:<code>str</code>, <strong><code>tokenizer</code></strong>=<em><code>None</code></em>, <strong><code>loss_func</code></strong>=<em><code>CrossEntropyLoss()</code></em>, <strong><code>metrics</code></strong>:<code>List</code>[<code>NERMetric</code>]=<em><code>['accuracy', 'f1']</code></em>, <strong><code>opt_func</code></strong>=<em><code>Adam</code></em>, <strong><code>additional_cbs</code></strong>=<em><code>None</code></em>, <strong><code>expose_fastai_api</code></strong>=<em><code>False</code></em>, <strong><code>num_classes</code></strong>:<code>int</code>=<em><code>None</code></em>, <strong><code>entity_mapping</code></strong>:<code>dict</code>=<em><code>None</code></em>, <strong>**<code>kwargs</code></strong>) :: <a href="/adaptnlp/training.core.html#AdaptiveTuner"><code>AdaptiveTuner</code></a></p>
</blockquote>
<p>An <a href="/adaptnlp/training.core.html#AdaptiveTuner"><code>AdaptiveTuner</code></a> with good defaults for Token Classification tasks</p>
<p><strong>Valid kwargs and defaults:</strong></p>
<ul>
<li><code>lr</code>:float = 0.001</li>
<li><code>splitter</code>:function = <code>trainable_params</code></li>
<li><code>cbs</code>:list = None</li>
<li><code>path</code>:Path = None</li>
<li><code>model_dir</code>:Path = 'models'</li>
<li><code>wd</code>:float = None</li>
<li><code>wd_bn_bias</code>:bool = False</li>
<li><code>train_bn</code>:bool = True</li>
<li><code>moms</code>: tuple(float) = (0.95, 0.85, 0.95)</li>
</ul>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>dls</code></strong> : <em><code>&lt;class 'fastai.data.core.DataLoaders'&gt;</code></em>   <p>A set of DataLoaders</p></li>
</ul>
<ul>
<li><strong><code>model_name</code></strong> : <em><code>&lt;class 'str'&gt;</code></em> <p>A HuggingFace model</p></li>
</ul>
<ul>
<li><strong><code>tokenizer</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em> <p>A HuggingFace tokenizer</p></li>
</ul>
<ul>
<li><strong><code>loss_func</code></strong> : <em><code>&lt;class 'fastai.losses.CrossEntropyLossFlat'&gt;</code></em>, <em>optional</em>   <p>A loss function</p></li>
</ul>
<ul>
<li><strong><code>metrics</code></strong> : <em><code>typing.List[fastcore.basics.NERMetric]</code></em>, <em>optional</em>   <p>Metrics to monitor the training with</p></li>
</ul>
<ul>
<li><strong><code>opt_func</code></strong> : <em><code>&lt;class 'function'&gt;</code></em>, <em>optional</em>  <p>A fastai or torch Optimizer</p></li>
</ul>
<ul>
<li><strong><code>additional_cbs</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em>    <p>Additional Callbacks to have always tied to the Tuner</p></li>
</ul>
<ul>
<li><strong><code>expose_fastai_api</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em> <p>Whether to expose the fastai API</p></li>
</ul>
<ul>
<li><strong><code>num_classes</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em>    <p>The number of classes</p></li>
</ul>
<ul>
<li><strong><code>entity_mapping</code></strong> : <em><code>&lt;class 'dict'&gt;</code></em>, <em>optional</em>    <p>A mapping of entity names to encoded labels</p></li>
</ul>
<ul>
<li><strong><code>kwargs</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next we'll pass in our <code>DataLoaders</code> and the name of our model:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include note.html content='If you are not using the data API (<a href="/adaptnlp/training.core.html#TaskDatasets"><code>TaskDatasets</code></a>, <a href="/adaptnlp/training.sequence_classification.html#SequenceClassificationDatasets"><code>SequenceClassificationDatasets</code></a>, etc), you need to pass in the tokenizer to the constructor as well with <code>tokenizer=tokenizer</code>' %}</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span> <span class="o">=</span> <span class="n">TokenClassificationTuner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">model_name</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForTokenClassification: [&#39;vocab_transform.bias&#39;, &#39;vocab_layer_norm.weight&#39;, &#39;vocab_transform.weight&#39;, &#39;vocab_layer_norm.bias&#39;, &#39;vocab_projector.weight&#39;, &#39;vocab_projector.bias&#39;]
- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: [&#39;classifier.bias&#39;, &#39;classifier.weight&#39;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>By default we can see that it used <code>CrossEntropyLoss</code> as our loss function, and both <code>accuracy</code> and <code>F1</code> as our metrics:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span><span class="o">.</span><span class="n">loss_func</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>FlattenedLoss of CrossEntropyLoss()</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="p">[</span><span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">tuner</span><span class="o">.</span><span class="n">metrics</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>accuracy
f1
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Important</strong>: By default, the <a href="/adaptnlp/training.token_classification.html#TokenClassificationTuner"><code>TokenClassificationTuner</code></a> class does not use <code>fastai</code> metrics (unlike the other <code>Tuner</code> classes). Instead it uses <code>HuggingFace</code>'s <code>seqeval</code> metric to compute accuracy, precision, recall, and/or F1 scores based on the requirements of multi-label classification. As a result, you will need to have <a href="https://github.com/chakki-works/seqeval">seqeval</a> installed in order to use the <a href="/adaptnlp/training.token_classification.html#TokenClassificationTuner"><code>TokenClassificationTuner</code></a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this tutorial, we will show how to use the metrics built into <a href="/adaptnlp/training.token_classification.html#TokenClassificationTuner"><code>TokenClassificationTuner</code></a>. Valid metrics can be found in the <code>NERMetric</code> namespace.</p>
<p>While <code>Accuracy</code> and <code>F1</code> are already defaults, we will specify all the available built-in metrics for clarity.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">NERMetric</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span> <span class="o">=</span> <span class="n">TokenClassificationTuner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">NERMetric</span><span class="o">.</span><span class="n">Accuracy</span><span class="p">,</span>
                                                           <span class="n">NERMetric</span><span class="o">.</span><span class="n">Precision</span><span class="p">,</span>
                                                           <span class="n">NERMetric</span><span class="o">.</span><span class="n">Recall</span><span class="p">,</span>
                                                           <span class="n">NERMetric</span><span class="o">.</span><span class="n">F1</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForTokenClassification: [&#39;vocab_transform.bias&#39;, &#39;vocab_layer_norm.weight&#39;, &#39;vocab_transform.weight&#39;, &#39;vocab_layer_norm.bias&#39;, &#39;vocab_projector.weight&#39;, &#39;vocab_projector.bias&#39;]
- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: [&#39;classifier.bias&#39;, &#39;classifier.weight&#39;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally we just need to train our model!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Fine-Tuning">Fine-Tuning<a class="anchor-link" href="#Fine-Tuning"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And all that's left is to <code>tune</code>. There are only 4 or 5 functions you can call on our <code>tuner</code> currently, and this is by design to make it simplistic. In case you don't want to be boxed in however, if you pass in <code>expose_fastai_api=True</code> to our earlier call, it will expose the entirety of <code>Learner</code> to you, so you can call <code>fit_one_cycle</code>, <code>lr_find</code>, and everything else as <code>Tuner</code> uses <code>fastai</code> under the hood.</p>
<p>First, let's call <code>lr_find</code>, which uses fastai's Learning Rate Finder to help us pick a learning rate.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="AdaptiveTuner.lr_find" class="doc_header"><code>AdaptiveTuner.lr_find</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/core.py#L415" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>AdaptiveTuner.lr_find</code>(<strong><code>start_lr</code></strong>=<em><code>1e-07</code></em>, <strong><code>end_lr</code></strong>=<em><code>10</code></em>, <strong><code>num_it</code></strong>=<em><code>100</code></em>, <strong><code>stop_div</code></strong>=<em><code>True</code></em>, <strong><code>show_plot</code></strong>=<em><code>True</code></em>, <strong><code>suggest_funcs</code></strong>=<em><code>valley</code></em>)</p>
</blockquote>
<p>Runs fastai's <code>LR Finder</code></p>
<p><strong>Parameters:</strong></p>
<ul>
<li><p><strong><code>start_lr</code></strong> : <em><code>&lt;class 'float'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>end_lr</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>num_it</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>stop_div</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>show_plot</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>suggest_funcs</code></strong> : <em><code>&lt;class 'function'&gt;</code></em>, <em>optional</em></p>
</li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr</span> <span class="o">=</span> <span class="n">tuner</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>█</pre>
</div>
</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It recommends a learning rate of around 1e-4, so we will use that.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's look at the documentation for <code>tune</code>:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="AdaptiveTuner.tune" class="doc_header"><code>AdaptiveTuner.tune</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/core.py#L401" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>AdaptiveTuner.tune</code>(<strong><code>epochs</code></strong>:<code>int</code>, <strong><code>lr</code></strong>:<code>float</code>=<em><code>None</code></em>, <strong><code>strategy</code></strong>:<code>Strategy</code>=<em><code>'fit_one_cycle'</code></em>, <strong><code>callbacks</code></strong>:<code>list</code>=<em><code>[]</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Fine tune <code>self.model</code> for <code>epochs</code> with an <code>lr</code> and <code>strategy</code></p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>epochs</code></strong> : <em><code>&lt;class 'int'&gt;</code></em> <p>Number of iterations to train for</p></li>
</ul>
<ul>
<li><strong><code>lr</code></strong> : <em><code>&lt;class 'float'&gt;</code></em>, <em>optional</em>   <p>If None, finds a new learning rate and uses suggestion_method</p></li>
</ul>
<ul>
<li><strong><code>strategy</code></strong> : <em><code>&lt;class 'fastcore.basics.Strategy'&gt;</code></em>, <em>optional</em>  <p>A fitting method</p></li>
</ul>
<ul>
<li><strong><code>callbacks</code></strong> : <em><code>&lt;class 'list'&gt;</code></em>, <em>optional</em> <p>Extra fastai Callbacks</p></li>
</ul>
<ul>
<li><strong><code>kwargs</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can pass in a number of epochs, a learning rate, a strategy, and additional fastai callbacks to call.</p>
<p>Valid strategies live in the <code>Strategy</code> namespace class, and consist of:</p>
<ul>
<li>OneCycle (Also called the <a href="https://docs.fast.ai/callback.schedule.html#Learner.fit_one_cycle">One-Cycle Policy</a>)</li>
<li><a href="https://docs.fast.ai/callback.schedule.html#Learner.fit_flat_cos">CosineAnnealing</a></li>
<li><a href="https://docs.fast.ai/callback.schedule.html#Learner.fit_sgdr">SGDR</a></li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">Strategy</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this tutorial we will train with the One-Cycle policy, as currently it is one of the best schedulers to use.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span><span class="o">.</span><span class="n">tune</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="n">Strategy</span><span class="o">.</span><span class="n">OneCycle</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>epoch     train_loss  valid_loss  accuracy  precision  recall    f1        time    
█</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>0         0.073525    0.059352    0.982763  0.895060   0.908902  0.900667  14:55     
1         0.034628    0.044417    0.987849  0.929728   0.940017  0.934077  14:57     
2         0.009520    0.045935    0.989362  0.943019   0.945272  0.943433  14:57     
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Saving-Model">Saving Model<a class="anchor-link" href="#Saving-Model"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now that we have a trained model, let's save those weights away.</p>
<p>Calling <code>tuner.save</code> will save both the model and the tokenizer in the same format as how HuggingFace does:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="AdaptiveTuner.save" class="doc_header"><code>AdaptiveTuner.save</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/core.py#L423" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>AdaptiveTuner.save</code>(<strong><code>save_directory</code></strong>)</p>
</blockquote>
<p>Save a pretrained model to a <code>save_directory</code></p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>save_directory</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em>  <p>A folder to save our model to</p></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;good_model&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&#39;good_model&#39;</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Performing-Inference">Performing Inference<a class="anchor-link" href="#Performing-Inference"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There are two ways to get predictions, the first is with the <code>.predict</code> method in our <code>tuner</code>. This is great for if you just finished training and want to see how your model performs on some new data!
The other method is with AdaptNLP's inference API, which we will show afterwards</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="In-Tuner">In Tuner<a class="anchor-link" href="#In-Tuner"> </a></h3><p>First let's write a sentence to test with</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sentence</span> <span class="o">=</span> <span class="s2">&quot;The company Novetta is based in McLean, Virgina.&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And then predict with it:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="TokenClassificationTuner.predict" class="doc_header"><code>TokenClassificationTuner.predict</code><a href="https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/token_classification.py#L317" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>TokenClassificationTuner.predict</code>(<strong><code>text</code></strong>:<code>Union</code>[<code>List</code>[<code>str</code>], <code>str</code>], <strong><code>bs</code></strong>:<code>int</code>=<em><code>64</code></em>, <strong><code>grouped_entities</code></strong>:<code>bool</code>=<em><code>True</code></em>, <strong><code>detail_level</code></strong>:<code>DetailLevel</code>=<em><code>'low'</code></em>)</p>
</blockquote>
<p>Predict some <code>text</code> for token classification with the currently loaded model</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>text</code></strong> : <em><code>typing.Union[typing.List[str], str]</code></em> <p>Some text or list of texts to do inference with</p></li>
</ul>
<ul>
<li><strong><code>bs</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em> <p>A batch size to use for multiple texts</p></li>
</ul>
<ul>
<li><strong><code>grouped_entities</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em>  <p>Return whole entity span strings</p></li>
</ul>
<ul>
<li><strong><code>detail_level</code></strong> : <em><code>&lt;class 'fastcore.basics.DetailLevel'&gt;</code></em>, <em>optional</em>   <p>A detail level to return on the predictions</p></li>
</ul>
<p><strong>Returns</strong>:</p>
<ul>
<li><em><code>&lt;class 'dict'&gt;</code></em>   <p>A dictionary of filtered predictions</p></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>█</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>OrderedDict([(&#39;tags&#39;,
              [[{&#39;entity&#39;: &#39;B-ORG&#39;,
                 &#39;score&#39;: 0.1850021630525589,
                 &#39;word&#39;: &#39;[CLS]&#39;},
                {&#39;entity&#39;: &#39;B-ORG&#39;, &#39;score&#39;: 0.997603714466095, &#39;word&#39;: &#39;nov&#39;},
                {&#39;entity&#39;: &#39;I-ORG&#39;,
                 &#39;score&#39;: 0.9754220247268677,
                 &#39;word&#39;: &#39;##etta&#39;},
                {&#39;entity&#39;: &#39;B-LOC&#39;,
                 &#39;score&#39;: 0.995358407497406,
                 &#39;word&#39;: &#39;mclean&#39;},
                {&#39;entity&#39;: &#39;B-LOC&#39;,
                 &#39;score&#39;: 0.9764575958251953,
                 &#39;word&#39;: &#39;virgin&#39;}]])])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="With-the-Inference-API">With the Inference API<a class="anchor-link" href="#With-the-Inference-API"> </a></h3><p>Next we will use the <a href="/adaptnlp/token_classification.html#EasyTokenTagger"><code>EasyTokenTagger</code></a> class, which AdaptNLP offers:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">EasyTokenTagger</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We simply construct the class:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">classifier</span> <span class="o">=</span> <span class="n">EasyTokenTagger</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And call the <code>tag_text</code> method, passing in the sentence, the location of our saved model, and some names for our classes:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">classifier</span><span class="o">.</span><span class="n">tag_text</span><span class="p">(</span>
    <span class="n">sentence</span><span class="p">,</span>
    <span class="n">model_name_or_path</span><span class="o">=</span><span class="s1">&#39;good_model&#39;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>2021-11-09 23:10:55,157 loading file good_model
█</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>OrderedDict([(&#39;tags&#39;,
              [[{&#39;entity&#39;: &#39;B-ORG&#39;,
                 &#39;score&#39;: 0.1850021630525589,
                 &#39;word&#39;: &#39;[CLS]&#39;},
                {&#39;entity&#39;: &#39;B-ORG&#39;, &#39;score&#39;: 0.997603714466095, &#39;word&#39;: &#39;nov&#39;},
                {&#39;entity&#39;: &#39;I-ORG&#39;,
                 &#39;score&#39;: 0.9754220247268677,
                 &#39;word&#39;: &#39;##etta&#39;},
                {&#39;entity&#39;: &#39;B-LOC&#39;,
                 &#39;score&#39;: 0.995358407497406,
                 &#39;word&#39;: &#39;mclean&#39;},
                {&#39;entity&#39;: &#39;B-LOC&#39;,
                 &#39;score&#39;: 0.9764575958251953,
                 &#39;word&#39;: &#39;virgin&#39;}]])])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And we got the exact same output and probabilities!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There are also different levels of predictions we can return (which is also the same with our earlier <code>predict</code> call).</p>
<p>These live in a namespace <code>DetailLevel</code> class, with a few examples below:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">DetailLevel</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">DetailLevel</span><span class="o">.</span><span class="n">Low</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&#39;low&#39;</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>While some Easy modules will not return different items at each level, most will return only a few specific outputs at the Low level, and everything possible at the High level:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">classifier</span><span class="o">.</span><span class="n">tag_text</span><span class="p">(</span>
    <span class="n">sentence</span><span class="p">,</span>
    <span class="n">model_name_or_path</span> <span class="o">=</span> <span class="s1">&#39;good_model&#39;</span><span class="p">,</span>
    <span class="n">detail_level</span><span class="o">=</span><span class="n">DetailLevel</span><span class="o">.</span><span class="n">Low</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>█</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>OrderedDict([(&#39;tags&#39;,
              [[{&#39;entity&#39;: &#39;B-ORG&#39;,
                 &#39;score&#39;: 0.1850021630525589,
                 &#39;word&#39;: &#39;[CLS]&#39;},
                {&#39;entity&#39;: &#39;B-ORG&#39;, &#39;score&#39;: 0.997603714466095, &#39;word&#39;: &#39;nov&#39;},
                {&#39;entity&#39;: &#39;I-ORG&#39;,
                 &#39;score&#39;: 0.9754220247268677,
                 &#39;word&#39;: &#39;##etta&#39;},
                {&#39;entity&#39;: &#39;B-LOC&#39;,
                 &#39;score&#39;: 0.995358407497406,
                 &#39;word&#39;: &#39;mclean&#39;},
                {&#39;entity&#39;: &#39;B-LOC&#39;,
                 &#39;score&#39;: 0.9764575958251953,
                 &#39;word&#39;: &#39;virgin&#39;}]])])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">classifier</span><span class="o">.</span><span class="n">tag_text</span><span class="p">(</span>
    <span class="n">sentence</span><span class="p">,</span>
    <span class="n">model_name_or_path</span> <span class="o">=</span> <span class="s1">&#39;good_model&#39;</span><span class="p">,</span>
    <span class="n">detail_level</span><span class="o">=</span><span class="n">DetailLevel</span><span class="o">.</span><span class="n">Medium</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>█</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>OrderedDict([(&#39;tags&#39;,
              [[{&#39;entity&#39;: &#39;B-ORG&#39;,
                 &#39;score&#39;: 0.1850021630525589,
                 &#39;word&#39;: &#39;[CLS]&#39;},
                {&#39;entity&#39;: &#39;B-ORG&#39;, &#39;score&#39;: 0.997603714466095, &#39;word&#39;: &#39;nov&#39;},
                {&#39;entity&#39;: &#39;I-ORG&#39;,
                 &#39;score&#39;: 0.9754220247268677,
                 &#39;word&#39;: &#39;##etta&#39;},
                {&#39;entity&#39;: &#39;B-LOC&#39;,
                 &#39;score&#39;: 0.995358407497406,
                 &#39;word&#39;: &#39;mclean&#39;},
                {&#39;entity&#39;: &#39;B-LOC&#39;,
                 &#39;score&#39;: 0.9764575958251953,
                 &#39;word&#39;: &#39;virgin&#39;}]])])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">classifier</span><span class="o">.</span><span class="n">tag_text</span><span class="p">(</span>
    <span class="n">sentence</span><span class="p">,</span>
    <span class="n">model_name_or_path</span> <span class="o">=</span> <span class="s1">&#39;good_model&#39;</span><span class="p">,</span>
    <span class="n">detail_level</span><span class="o">=</span><span class="n">DetailLevel</span><span class="o">.</span><span class="n">High</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>█</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>OrderedDict([(&#39;tags&#39;,
              [[{&#39;entity&#39;: &#39;B-ORG&#39;,
                 &#39;score&#39;: 0.1850021630525589,
                 &#39;word&#39;: &#39;[CLS]&#39;},
                {&#39;entity&#39;: &#39;B-ORG&#39;, &#39;score&#39;: 0.997603714466095, &#39;word&#39;: &#39;nov&#39;},
                {&#39;entity&#39;: &#39;I-ORG&#39;,
                 &#39;score&#39;: 0.9754220247268677,
                 &#39;word&#39;: &#39;##etta&#39;},
                {&#39;entity&#39;: &#39;B-LOC&#39;,
                 &#39;score&#39;: 0.995358407497406,
                 &#39;word&#39;: &#39;mclean&#39;},
                {&#39;entity&#39;: &#39;B-LOC&#39;,
                 &#39;score&#39;: 0.9764575958251953,
                 &#39;word&#39;: &#39;virgin&#39;}]])])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Code-Summary">Code Summary<a class="anchor-link" href="#Code-Summary"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>A quick one-cell code chunk with all the code used in this notebook, so the reader can quickly copy/paste this</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">TokenClassificationDatasets</span>
<span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">TokenClassificationTuner</span>
<span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">Strategy</span>
<span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">NERMetric</span>
<span class="kn">from</span> <span class="nn">ast</span> <span class="kn">import</span> <span class="n">literal_eval</span>

<span class="n">dsets</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;conll2003&#39;</span><span class="p">)</span>

<span class="n">dset</span> <span class="o">=</span> <span class="n">dsets</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span>

<span class="c1"># going through pandas to ensure data types are correct for the csv</span>
<span class="n">dset</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s1">&#39;pandas&#39;</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">dset</span><span class="p">[:]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;tokens&#39;</span><span class="p">,</span> <span class="s1">&#39;ner_tags&#39;</span><span class="p">]]</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;ner_tags&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;ner_tags&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;tokens&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;tokens&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;/tmp/conll2003.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">model_name</span> <span class="o">=</span> <span class="s1">&#39;distilbert-base-uncased&#39;</span>

<span class="n">tokenize_kwargs</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;truncation&#39;</span><span class="p">:</span><span class="kc">True</span><span class="p">,</span> 
    <span class="s1">&#39;is_split_into_words&#39;</span><span class="p">:</span><span class="kc">True</span><span class="p">,</span> 
    <span class="s1">&#39;padding&#39;</span><span class="p">:</span><span class="s1">&#39;max_length&#39;</span><span class="p">,</span> 
    <span class="s1">&#39;return_offsets_mapping&#39;</span><span class="p">:</span><span class="kc">True</span>
<span class="p">}</span>

<span class="n">entity_mapping</span> <span class="o">=</span> <span class="p">{</span>
    <span class="mi">0</span><span class="p">:</span> <span class="s1">&#39;O&#39;</span><span class="p">,</span>
    <span class="mi">1</span><span class="p">:</span> <span class="s1">&#39;B-PER&#39;</span><span class="p">,</span>
    <span class="mi">2</span><span class="p">:</span> <span class="s1">&#39;I-PER&#39;</span><span class="p">,</span>
    <span class="mi">3</span><span class="p">:</span> <span class="s1">&#39;B-ORG&#39;</span><span class="p">,</span>
    <span class="mi">4</span><span class="p">:</span> <span class="s1">&#39;I-ORG&#39;</span><span class="p">,</span>
    <span class="mi">5</span><span class="p">:</span> <span class="s1">&#39;B-LOC&#39;</span><span class="p">,</span>
    <span class="mi">6</span><span class="p">:</span> <span class="s1">&#39;I-LOC&#39;</span><span class="p">,</span>
    <span class="mi">7</span><span class="p">:</span> <span class="s1">&#39;B-MISC&#39;</span><span class="p">,</span>
    <span class="mi">8</span><span class="p">:</span> <span class="s1">&#39;I-MISC&#39;</span>
<span class="p">}</span>

<span class="n">dsets</span> <span class="o">=</span> <span class="n">TokenClassificationDatasets</span><span class="o">.</span><span class="n">from_csvs</span><span class="p">(</span>
    <span class="s1">&#39;/tmp/conll2003.csv&#39;</span><span class="p">,</span>
    <span class="s1">&#39;tokens&#39;</span><span class="p">,</span>
    <span class="s1">&#39;ner_tags&#39;</span><span class="p">,</span>
    <span class="n">entity_mapping</span><span class="p">,</span>
    <span class="n">tokenizer_name</span> <span class="o">=</span> <span class="n">model_name</span><span class="p">,</span>
    <span class="n">tokenize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">tokenize_kwargs</span> <span class="o">=</span> <span class="n">tokenize_kwargs</span><span class="p">,</span>
    <span class="n">split_pct</span><span class="o">=</span><span class="mf">.2</span><span class="p">,</span>
    <span class="n">converters</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;tokens&#39;</span><span class="p">:</span> <span class="n">literal_eval</span><span class="p">,</span> <span class="s1">&#39;ner_tags&#39;</span><span class="p">:</span> <span class="n">literal_eval</span><span class="p">}</span>  <span class="c1"># kwarg to pd.read_csv</span>
<span class="p">)</span>

<span class="n">dls</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

<span class="n">tuner</span> <span class="o">=</span> <span class="n">TokenClassificationTuner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">model_name</span><span class="p">)</span>

<span class="n">tuner</span> <span class="o">=</span> <span class="n">TokenClassificationTuner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">NERMetric</span><span class="o">.</span><span class="n">Accuracy</span><span class="p">,</span>
                                                           <span class="n">NERMetric</span><span class="o">.</span><span class="n">Precision</span><span class="p">,</span>
                                                           <span class="n">NERMetric</span><span class="o">.</span><span class="n">Recall</span><span class="p">,</span>
                                                           <span class="n">NERMetric</span><span class="o">.</span><span class="n">F1</span><span class="p">])</span>

<span class="n">lr</span> <span class="o">=</span> <span class="n">tuner</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>

<span class="n">tuner</span><span class="o">.</span><span class="n">tune</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="n">Strategy</span><span class="o">.</span><span class="n">OneCycle</span><span class="p">)</span>

<span class="n">tuner</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;good_model&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

</div>
 

