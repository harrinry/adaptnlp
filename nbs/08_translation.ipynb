{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp inference.translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation\n",
    "> Translation API for AdaptNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastcore.test import test_eq\n",
    "from nbverbose.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import logging\n",
    "from typing import List, Dict, Union\n",
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    PreTrainedTokenizer,\n",
    "    PreTrainedModel,\n",
    "    T5ForConditionalGeneration,\n",
    ")\n",
    "\n",
    "from adaptnlp.model import AdaptiveModel\n",
    "from adaptnlp.callback import GeneratorCallback\n",
    "\n",
    "from fastai.torch_core import apply, to_device\n",
    "\n",
    "from fastcore.basics import Self\n",
    "from adaptnlp.model_hub import HFModelResult, FlairModelResult, HFModelHub, FlairModelHub\n",
    "from adaptnlp.result import DetailLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TranslationResult:\n",
    "    \"A basic result class for Translation problems\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        inputs:List[str], # A list of input string sentences\n",
    "        input_lang:str, # A input language\n",
    "        output_lang:str, # An output language\n",
    "        translations:List[str] # A list of the translated sentences\n",
    "    ):\n",
    "        self.inputs = inputs\n",
    "        self.input_lang = input_lang\n",
    "        self.output_lang = output_lang\n",
    "        self.translations = translations\n",
    "    \n",
    "    def to_dict(\n",
    "        self, \n",
    "        detail_level:DetailLevel=DetailLevel.Low # A detail level to return\n",
    "    ):\n",
    "        \"Convert `self` to a filtered dictionary\"\n",
    "        o = OrderedDict()\n",
    "        o.update(\n",
    "            {'translations':self.translations,}\n",
    "        )\n",
    "        if detail_level == 'medium' or detail_level == 'high':\n",
    "            o.update({\n",
    "                'inputs': self.inputs,\n",
    "                'input_language': self.input_lang,\n",
    "                'output_language': self.output_lang\n",
    "            })\n",
    "        if detail_level == 'high':\n",
    "            print(\"Warning: There is no difference between `medium` and `high` for Translation tasks\")\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TranslationResult.to_dict\" class=\"doc_header\"><code>TranslationResult.to_dict</code><a href=\"__main__.py#L16\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TranslationResult.to_dict</code>(**`detail_level`**:`DetailLevel`=*`'low'`*)\n",
       "\n",
       "Convert `self` to a filtered dictionary\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`detail_level`** : *`<class 'fastcore.basics.DetailLevel'>`*, *optional*\t<p>A detail level to return</p>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TranslationResult.to_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TransformersTranslator(AdaptiveModel):\n",
    "    \"Adaptive model for Transformer's Conditional Generation or Language Models (Transformer's T5 and Bart conditional generation models have a language modeling head)\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        tokenizer: PreTrainedTokenizer, # A tokenizer object from Huggingface's transformers (TODO)and tokenizers\n",
    "        model: PreTrainedModel # A transformers Conditional Generation (Bart or T5) or Language model\n",
    "    ):\n",
    "        # Load up model and tokenizer\n",
    "        self.tokenizer = tokenizer\n",
    "        super().__init__()\n",
    "        \n",
    "        # Sets internal model\n",
    "        self.set_model(model)\n",
    "        \n",
    "        # Set inputs to come in as `dict`\n",
    "        super().set_as_dict(True)\n",
    "\n",
    "    @classmethod\n",
    "    def load(\n",
    "        cls, \n",
    "        model_name_or_path: str # A key string of one of Transformer's pre-trained translator Model\n",
    "    ) -> AdaptiveModel:\n",
    "        \"Class method for loading and constructing this classifier\"\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path)\n",
    "        translator = cls(tokenizer, model)\n",
    "        return translator\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        text: Union[List[str], str], # Sentences to run inference on\n",
    "        t5_prefix: str = 'translate English to German', # The pre-appended prefix for the specificied task. Only in use for T5-type models.\n",
    "        mini_batch_size: int = 32,  # Mini batch size\n",
    "        num_beams: int = 1, # Number of beams for beam search. Must be between 1 and infinity. 1 means no beam search\n",
    "        min_length: int = 0, # The min length of the sequence to be generated\n",
    "        max_length: int = 128, # The max length of the sequence to be generated. Between min_length and infinity\n",
    "        early_stopping: bool = True, # If set to `True` beam search is stopped when at least num_beams sentences finished per batch\n",
    "        detail_level:DetailLevel = DetailLevel.Low, # The level of detail to return\n",
    "        **kwargs, # Optional arguments for the Transformers `PreTrainedModel.generate()` method\n",
    "    ) -> List[str]: # A list of translated sentences\n",
    "        \"Predict method for running inference using the pre-trained sequence classifier model. Keyword arguments for parameters of the method `Transformers.PreTrainedModel.generate()` can be used as well\"\n",
    "        \n",
    "        # Make all inputs lists\n",
    "        if isinstance(text, str):\n",
    "            text = [text]\n",
    "        \n",
    "        # T5 requires 'translate: ' precursor text for pre-trained translator\n",
    "        if isinstance(self.model, T5ForConditionalGeneration):\n",
    "            text = [f'{t5_prefix}: {t}' for t in text]\n",
    "            \n",
    "        dataset = self._tokenize(text)\n",
    "        dl = DataLoader(dataset, batch_size=mini_batch_size)\n",
    "        translations = []\n",
    "        \n",
    "        logger.info(f'Running translator on {len(dataset)} text sequences')\n",
    "        logger.info(f'Batch size = {mini_batch_size}')\n",
    "        \n",
    "        cb = GeneratorCallback(num_beams, min_length, max_length, early_stopping, **kwargs)\n",
    "        \n",
    "        preds,_ = super().get_preds(dl=dl, cbs=[cb])\n",
    "        \n",
    "        preds = apply(Self.squeeze(0), preds)\n",
    "\n",
    "        for o in preds:\n",
    "            translations.append(\n",
    "                [\n",
    "                    self.tokenizer.decode(\n",
    "                        o,\n",
    "                        skip_special_tokens=True,\n",
    "                        clean_up_tokenization_spaces=False,\n",
    "                    )\n",
    "                ].pop()\n",
    "            )\n",
    "        \n",
    "        languages = t5_prefix.strip('translate ').split(' to ')\n",
    "        \n",
    "        res = TranslationResult(text, *languages, translations)\n",
    "\n",
    "        return res if detail_level is None else res.to_dict(detail_level)\n",
    "\n",
    "    def _tokenize(self, text: Union[List[str], str]) -> TensorDataset:\n",
    "        \"\"\" Batch tokenizes text and produces a `TensorDataset` with text \"\"\"\n",
    "\n",
    "        tokenized_text = self.tokenizer.batch_encode_plus(\n",
    "            text,\n",
    "            return_tensors='pt',\n",
    "            max_length=512,\n",
    "            padding='max_length',\n",
    "            add_special_tokens=True,\n",
    "        )\n",
    "\n",
    "        # Bart doesn't use `token_type_ids`\n",
    "        dataset = TensorDataset(\n",
    "            tokenized_text['input_ids'],\n",
    "            tokenized_text['attention_mask'],\n",
    "        )\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TransformersTranslator.load\" class=\"doc_header\"><code>TransformersTranslator.load</code><a href=\"__main__.py#L20\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TransformersTranslator.load</code>(**`model_name_or_path`**:`str`)\n",
       "\n",
       "Class method for loading and constructing this classifier\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`model_name_or_path`** : *`<class 'str'>`*\t<p>A key string of one of Transformer's pre-trained translator Model</p>\n",
       "\n",
       "\n",
       "\n",
       "**Returns**:\n",
       "\t\n",
       " * *`<class 'adaptnlp.model.AdaptiveModel'>`*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TransformersTranslator.load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TransformersTranslator.predict\" class=\"doc_header\"><code>TransformersTranslator.predict</code><a href=\"__main__.py#L40\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TransformersTranslator.predict</code>(**`text`**:`Union`\\[`List`\\[`str`\\], `str`\\], **`t5_prefix`**:`str`=*`'translate English to German'`*, **`mini_batch_size`**:`int`=*`32`*, **`num_beams`**:`int`=*`1`*, **`min_length`**:`int`=*`0`*, **`max_length`**:`int`=*`128`*, **`early_stopping`**:`bool`=*`True`*, **`detail_level`**:`DetailLevel`=*`'low'`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Predict method for running inference using the pre-trained sequence classifier model. Keyword arguments for parameters of the method `Transformers.PreTrainedModel.generate()` can be used as well\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`text`** : *`typing.Union[typing.List[str], str]`*\t<p>Sentences to run inference on</p>\n",
       "\n",
       "\n",
       " - **`t5_prefix`** : *`<class 'str'>`*, *optional*\t<p>The pre-appended prefix for the specificied task. Only in use for T5-type models.</p>\n",
       "\n",
       "\n",
       " - **`mini_batch_size`** : *`<class 'int'>`*, *optional*\t<p>Mini batch size</p>\n",
       "\n",
       "\n",
       " - **`num_beams`** : *`<class 'int'>`*, *optional*\t<p>Number of beams for beam search. Must be between 1 and infinity. 1 means no beam search</p>\n",
       "\n",
       "\n",
       " - **`min_length`** : *`<class 'int'>`*, *optional*\t<p>The min length of the sequence to be generated</p>\n",
       "\n",
       "\n",
       " - **`max_length`** : *`<class 'int'>`*, *optional*\t<p>The max length of the sequence to be generated. Between min_length and infinity</p>\n",
       "\n",
       "\n",
       " - **`early_stopping`** : *`<class 'bool'>`*, *optional*\t<p>If set to `True` beam search is stopped when at least num_beams sentences finished per batch</p>\n",
       "\n",
       "\n",
       " - **`detail_level`** : *`<class 'fastcore.basics.DetailLevel'>`*, *optional*\t<p>The level of detail to return</p>\n",
       "\n",
       "\n",
       " - **`kwargs`** : *`<class 'inspect._empty'>`*\n",
       "\n",
       "\n",
       "**Returns**:\n",
       "\t\n",
       " * *`typing.List[str]`*\t<p>A list of translated sentences</p>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TransformersTranslator.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EasyTranslator:\n",
    "    \"Translation Module\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.translators: Dict[AdaptiveModel] = defaultdict(bool)\n",
    "\n",
    "    def translate(\n",
    "        self,\n",
    "        text: Union[List[str], str], # Sentences to run inference on\n",
    "        model_name_or_path: str = \"t5-small\", # A model id or path to a pre-trained model repository or custom trained model directory\n",
    "        t5_prefix: str = \"translate English to German\", # The pre-appended prefix for the specificied task. Only in use for T5-type models\n",
    "        detail_level=DetailLevel.Low, # The level of detail to return\n",
    "        mini_batch_size: int = 32, # Mini batch size\n",
    "        num_beams: int = 1, # Number of beams for beam search. Must be between 1 and infinity. 1 means no beam search\n",
    "        min_length: int = 0, # The min length of the sequence to be generated\n",
    "        max_length: int = 128, # The max length of the sequence to be generated. Between min_length and infinity\n",
    "        early_stopping: bool = True, # If set to `True` beam search is stopped when at least num_beams sentences finished per batch\n",
    "        **kwargs, # Optional arguments for the Transformers `PreTrainedModel.generate()` method\n",
    "    ) -> List[str]: \n",
    "        \"Predict method for running inference using the pre-trained sequence classifier model. Keyword arguments for parameters of the method `Transformers.PreTrainedModel.generate()` can be used as well.\"\n",
    "        name = getattr(model_name_or_path, 'name', model_name_or_path)\n",
    "        if not self.translators[name]:\n",
    "            self.translators[name] = TransformersTranslator.load(\n",
    "                name\n",
    "            )\n",
    "\n",
    "        translator = self.translators[name]\n",
    "        return translator.predict(\n",
    "            text=text,\n",
    "            t5_prefix=t5_prefix,\n",
    "            mini_batch_size=mini_batch_size,\n",
    "            num_beams=num_beams,\n",
    "            min_length=min_length,\n",
    "            max_length=max_length,\n",
    "            early_stopping=early_stopping,\n",
    "            **kwargs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EasyTranslator.translate\" class=\"doc_header\"><code>EasyTranslator.translate</code><a href=\"__main__.py#L8\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EasyTranslator.translate</code>(**`text`**:`Union`\\[`List`\\[`str`\\], `str`\\], **`model_name_or_path`**:`str`=*`'t5-small'`*, **`t5_prefix`**:`str`=*`'translate English to German'`*, **`detail_level`**=*`'low'`*, **`mini_batch_size`**:`int`=*`32`*, **`num_beams`**:`int`=*`1`*, **`min_length`**:`int`=*`0`*, **`max_length`**:`int`=*`128`*, **`early_stopping`**:`bool`=*`True`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Predict method for running inference using the pre-trained sequence classifier model. Keyword arguments for parameters of the method `Transformers.PreTrainedModel.generate()` can be used as well.\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`text`** : *`typing.Union[typing.List[str], str]`*\t<p>Sentences to run inference on</p>\n",
       "\n",
       "\n",
       " - **`model_name_or_path`** : *`<class 'str'>`*, *optional*\t<p>A model id or path to a pre-trained model repository or custom trained model directory</p>\n",
       "\n",
       "\n",
       " - **`t5_prefix`** : *`<class 'str'>`*, *optional*\t<p>The pre-appended prefix for the specificied task. Only in use for T5-type models</p>\n",
       "\n",
       "\n",
       " - **`detail_level`** : *`<class 'str'>`*, *optional*\t<p>The level of detail to return</p>\n",
       "\n",
       "\n",
       " - **`mini_batch_size`** : *`<class 'int'>`*, *optional*\t<p>Mini batch size</p>\n",
       "\n",
       "\n",
       " - **`num_beams`** : *`<class 'int'>`*, *optional*\t<p>Number of beams for beam search. Must be between 1 and infinity. 1 means no beam search</p>\n",
       "\n",
       "\n",
       " - **`min_length`** : *`<class 'int'>`*, *optional*\t<p>The min length of the sequence to be generated</p>\n",
       "\n",
       "\n",
       " - **`max_length`** : *`<class 'int'>`*, *optional*\t<p>The max length of the sequence to be generated. Between min_length and infinity</p>\n",
       "\n",
       "\n",
       " - **`early_stopping`** : *`<class 'bool'>`*, *optional*\t<p>If set to `True` beam search is stopped when at least num_beams sentences finished per batch</p>\n",
       "\n",
       "\n",
       " - **`kwargs`** : *`<class 'inspect._empty'>`*\n",
       "\n",
       "\n",
       "**Returns**:\n",
       "\t\n",
       " * *`typing.List[str]`*\t<p>Optional arguments for the Transformers `PreTrainedModel.generate()` method</p>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EasyTranslator.translate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "text = [\"Machine learning will take over the world very soon.\",\n",
    "        \"Machines can speak in many languages.\",]\n",
    "\n",
    "translator = EasyTranslator()\n",
    "translations = translator.translate(text = text, t5_prefix=\"translate English to German\", model_name_or_path=\"t5-small\", mini_batch_size=1, min_length=0, max_length=100, early_stopping=True)\n",
    "test_eq(translations['translations'], ['Das Maschinenlernen wird die Welt in Kürze übernehmen.',\n",
    " 'Maschinen können in vielen Sprachen sprechen.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "hub = HFModelHub()\n",
    "model = hub.search_model_by_task(\"translation\")[-1]\n",
    "translations = translator.translate(text = text, t5_prefix=\"translate English to German\", model_name_or_path=model, mini_batch_size=1, min_length=0, max_length=100, early_stopping=True)\n",
    "test_eq(translations['translations'], ['Das Maschinenlernen wird die Welt in Kürze übernehmen.',\n",
    " 'Maschinen können in vielen Sprachen sprechen.'])"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
