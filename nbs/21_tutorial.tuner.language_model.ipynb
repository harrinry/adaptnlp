{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da54a4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e6e11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc18f09",
   "metadata": {},
   "source": [
    "## Tutorial: Language Model Tuning\n",
    "> A tutorial following the fine-tuning and data API for Langauge Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fe9c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptnlp.training.data import LanguageModelDatasets, RandomSplitter, ColReader\n",
    "from adaptnlp.training.tuner import LanguageModelTuner, Strategy, LMType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9856e2c",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this tutorial we will cover building a dataset with the AdaptNLP data API for language model fine-tuning, and fine-tune a model towards that dataset.\n",
    "\n",
    "Throughout the tutorial you will notice we call from `fastai`, this is because the tuning API is built upon their library\n",
    "\n",
    "> Note: Eventually this will change to `fastai_minima`\n",
    "\n",
    "For our task, we will use the `IMDB_SAMPLE` dataset to help us tune a BERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229bd1b9",
   "metadata": {},
   "source": [
    "## The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1619b947",
   "metadata": {},
   "source": [
    "The first thing we need to do is get some data. We will use fastai's handy `untar_data` function and the `URLs` class to download it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f575166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.external import untar_data, URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76735bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1) [Path('/root/.fastai/data/imdb_sample/texts.csv')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE); path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6695fe0",
   "metadata": {},
   "source": [
    "As you can see, we get a `Path` object showing where the data is stored. Let's open it in `pandas`, as currently the API only supports reading in through `DataFrame`'s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c131a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(path/'texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8ebbfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>Un-bleeping-believable! Meg Ryan doesn't even look her usual pert lovable self in this, which normally makes me forgive her shallow ticky acting schtick. Hard to believe she was the producer on this dog. Plus Kevin Kline: what kind of suicide trip has his career been on? Whoosh... Banzai!!! Finally this was directed by the guy who did Big Chill? Must be a replay of Jonestown - hollywood style. Wooofff!</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>This is a extremely well-made film. The acting, script and camera-work are all first-rate. The music is good, too, though it is mostly early in the film, when things are still relatively cheery. There are no really superstars in the cast, though several faces will be familiar. The entire cast does an excellent job with the script.&lt;br /&gt;&lt;br /&gt;But it is hard to watch, because there is no good end to a situation like the one presented. It is now fashionable to blame the British for setting Hindus and Muslims against each other, and then cruelly separating them into two countries. There is som...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>Every once in a long while a movie will come along that will be so awful that I feel compelled to warn people. If I labor all my days and I can save but one soul from watching this movie, how great will be my joy.&lt;br /&gt;&lt;br /&gt;Where to begin my discussion of pain. For starters, there was a musical montage every five minutes. There was no character development. Every character was a stereotype. We had swearing guy, fat guy who eats donuts, goofy foreign guy, etc. The script felt as if it were being written as the movie was being shot. The production value was so incredibly low that it felt li...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>Name just says it all. I watched this movie with my dad when it came out and having served in Korea he had great admiration for the man. The disappointing thing about this film is that it only concentrate on a short period of the man's life - interestingly enough the man's entire life would have made such an epic bio-pic that it is staggering to imagine the cost for production.&lt;br /&gt;&lt;br /&gt;Some posters elude to the flawed characteristics about the man, which are cheap shots. The theme of the movie \"Duty, Honor, Country\" are not just mere words blathered from the lips of a high-brassed offic...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>This movie succeeds at being one of the most unique movies you've seen. However this comes from the fact that you can't make heads or tails of this mess. It almost seems as a series of challenges set up to determine whether or not you are willing to walk out of the movie and give up the money you just paid. If you don't want to feel slighted you'll sit through this horrible film and develop a real sense of pity for the actors involved, they've all seen better days, but then you realize they actually got paid quite a bit of money to do this and you'll lose pity for them just like you've alr...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  \\\n",
       "0  negative   \n",
       "1  positive   \n",
       "2  negative   \n",
       "3  positive   \n",
       "4  negative   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0                                                                                                                                                                                                    Un-bleeping-believable! Meg Ryan doesn't even look her usual pert lovable self in this, which normally makes me forgive her shallow ticky acting schtick. Hard to believe she was the producer on this dog. Plus Kevin Kline: what kind of suicide trip has his career been on? Whoosh... Banzai!!! Finally this was directed by the guy who did Big Chill? Must be a replay of Jonestown - hollywood style. Wooofff!   \n",
       "1  This is a extremely well-made film. The acting, script and camera-work are all first-rate. The music is good, too, though it is mostly early in the film, when things are still relatively cheery. There are no really superstars in the cast, though several faces will be familiar. The entire cast does an excellent job with the script.<br /><br />But it is hard to watch, because there is no good end to a situation like the one presented. It is now fashionable to blame the British for setting Hindus and Muslims against each other, and then cruelly separating them into two countries. There is som...   \n",
       "2  Every once in a long while a movie will come along that will be so awful that I feel compelled to warn people. If I labor all my days and I can save but one soul from watching this movie, how great will be my joy.<br /><br />Where to begin my discussion of pain. For starters, there was a musical montage every five minutes. There was no character development. Every character was a stereotype. We had swearing guy, fat guy who eats donuts, goofy foreign guy, etc. The script felt as if it were being written as the movie was being shot. The production value was so incredibly low that it felt li...   \n",
       "3  Name just says it all. I watched this movie with my dad when it came out and having served in Korea he had great admiration for the man. The disappointing thing about this film is that it only concentrate on a short period of the man's life - interestingly enough the man's entire life would have made such an epic bio-pic that it is staggering to imagine the cost for production.<br /><br />Some posters elude to the flawed characteristics about the man, which are cheap shots. The theme of the movie \"Duty, Honor, Country\" are not just mere words blathered from the lips of a high-brassed offic...   \n",
       "4  This movie succeeds at being one of the most unique movies you've seen. However this comes from the fact that you can't make heads or tails of this mess. It almost seems as a series of challenges set up to determine whether or not you are willing to walk out of the movie and give up the money you just paid. If you don't want to feel slighted you'll sit through this horrible film and develop a real sense of pity for the actors involved, they've all seen better days, but then you realize they actually got paid quite a bit of money to do this and you'll lose pity for them just like you've alr...   \n",
       "\n",
       "   is_valid  \n",
       "0     False  \n",
       "1     False  \n",
       "2     False  \n",
       "3     False  \n",
       "4     False  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7c4131",
   "metadata": {},
   "source": [
    "We have a `label`, `text`, and `is_valid` column. Let's see how we can frame this into AdaptNLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3034bf63",
   "metadata": {},
   "source": [
    "## High Level API\n",
    "\n",
    "\n",
    "Each `*Tuner` class comes with a factory method to prepare your dataset and generate the `Tuner` class at once. If you want a more exposed API, the next section will introduce you to the mid-level API. Let's see the doc for our function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a54884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"LanguageModelTuner.from_df\" class=\"doc_header\"><code>LanguageModelTuner.from_df</code><a href=\"https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/tuner.py#L272\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>LanguageModelTuner.from_df</code>(**`df`**:`DataFrame`, **`text_col`**:`str`=*`'text'`*, **`model_name`**:`str`=*`None`*, **`language_model_type`**:`LMType`=*`'causal'`*, **`split_func`**:`callable`=*`_inner`*, **`loss_func`**=*`CrossEntropyLoss()`*, **`metrics`**=*`[<function accuracy at 0x7fe07ed1be50>, <fastai.metrics.Perplexity object at 0x7fe07ebfb430>]`*, **`batch_size`**=*`8`*, **`collate_fn`**=*`default_collate`*, **`opt_func`**=*`Adam`*, **`additional_cbs`**=*`None`*, **`expose_fastai_api`**=*`False`*, **`dataset_kwargs`**=*`{}`*, **`tokenize_kwargs`**=*`{}`*, **`lr`**=*`0.001`*, **`splitter`**=*`trainable_params`*, **`cbs`**=*`None`*, **`path`**=*`None`*, **`model_dir`**=*`'models'`*, **`wd`**=*`None`*, **`wd_bn_bias`**=*`False`*, **`train_bn`**=*`True`*, **`moms`**=*`(0.95, 0.85, 0.95)`*)\n",
       "\n",
       "Convience method to build a [`SequenceClassificationTuner`](/adaptnlptraining.tuner.html#SequenceClassificationTuner) from a Pandas Dataframe"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(LanguageModelTuner.from_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58289e02",
   "metadata": {},
   "source": [
    "We can see it wants a `DataFrame`, the name of our text column, the name of a transformers model, the **type** of language model we are training, potentially a way to split the data, and some other configurable bits for training (such as loss function, optimizer, etc).\n",
    "\n",
    "The defaults for the high-level API will work out of the box for their task. In this case our loss function is CrossEntropy, we have `accuracy` and `Perplexity` as our metrics, and our optimizer is `Adam`. Let's use these defaults to build a tuner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a52451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "744c5e2a771a4d4e9c250db0986de392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "464e7c6d1ed64d64905cd2c487c618c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de8d486ce56048269d1932740c26e3d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc43e6eee7ba4913a0cbe5afcf725fbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tuner = LanguageModelTuner.from_df(\n",
    "    df, \n",
    "    text_col='text',\n",
    "    model_name='distilgpt2',\n",
    "    language_model_type=LMType.Causal,\n",
    "    split_func=RandomSplitter(valid_pct=0.1),\n",
    "    tokenize_kwargs = {'max_length':1024, 'truncation':True},\n",
    "    use_fast=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1863877",
   "metadata": {},
   "source": [
    "What this did for us is first tokenize our datasets into a `transformers.Dataset`, then it built our `DataLoaders`, before finally setting up a causal language model for us to tune with. \n",
    "\n",
    "All that's left now is to train! \n",
    "\n",
    "We can use the `lr_find` method to find a good learning rate to use, and the use `tune` to train for a few epochs:\n",
    "\n",
    "> Note: `lr_find` is fastai's Learning Rate Finder, you can read the documentation on it [here](https://docs.fast.ai/callback.schedule#Learner.lr_find)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902b6cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.8/site-packages/fastai/callback/schedule.py:270: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"ro\" (-> color='r'). The keyword argument will take precedence.\n",
      "  ax.plot(val, idx, 'ro', label=nm, c=color)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = tuner.lr_find()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2befa537",
   "metadata": {},
   "source": [
    "We can then see the recommended learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0984e554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(valley=tensor(0.0001))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb4a493",
   "metadata": {},
   "source": [
    "And now let's use it and tune:\n",
    "\n",
    "> Note: By default it will use the `OneCyclePolicy`, but `CosineAnnealing` and `SGDR` are also available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37c1f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.064009</td>\n",
       "      <td>3.978340</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>53.428291</td>\n",
       "      <td>00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.008184</td>\n",
       "      <td>3.956380</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>52.267792</td>\n",
       "      <td>00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.971029</td>\n",
       "      <td>3.954938</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>52.192478</td>\n",
       "      <td>00:55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuner.tune(\n",
    "    epochs=3,\n",
    "    lr=2e-5,\n",
    "    strategy=Strategy.OneCycle,\n",
    "    wd=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c577461c",
   "metadata": {},
   "source": [
    "And now you're done, with only three lines of code! Let's try and convert that over to the mid-level API, and remove some of that (heavy) abstraction next:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432c42d1",
   "metadata": {},
   "source": [
    "## Mid-Level API\n",
    "\n",
    "Let's see how we can recreate the high level API with `Datasets` and `Tuner` APIs.\n",
    "\n",
    "We'll use the `LanguageModelDatasets.from_df` helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9fd2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method from_df in module adaptnlp.training.data:\n",
      "\n",
      "from_df(df: pandas.core.frame.DataFrame, text_col: str = 'text', splits=None, block_size: int = 512, tokenizer_name: str = None, tokenize: bool = True) method of builtins.type instance\n",
      "    Builds `SequenceClassificationDatasets` from a `DataFrame` or file path\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(LanguageModelDatasets.from_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb588a6",
   "metadata": {},
   "source": [
    "It expects a `DataFrame`, a text column name, some splits, the block size our language model should expect, and a tokenizer model.\n",
    "\n",
    "First let's look at how to write our splits.\n",
    "\n",
    "These should be in the format of a list of indicies, dictating what goes to the training, and what goes to the validation sets such as: `[[0,1,2],[3,4,5]]`.\n",
    "\n",
    "We'll bring in fastai's `RandomSplitter` like earlier, which will randomly split the data 80/20 between train and validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a3d35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = RandomSplitter(valid_pct=0.1)(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a843679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#900) [806,265,502,12,441,229,817,822,534,640...],\n",
       " (#100) [800,135,258,808,73,682,29,146,793,972...])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b56bf5",
   "metadata": {},
   "source": [
    "Now that we have some splits, let's build and tokenize the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b2ca99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "916e53fe2c334a6898fa1aaceb648c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8603e715c2674348995dc5466c3d32f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ee353997c8446489d750f72929c57d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47d1240b826043d1807b049b0d4c478f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dset = LanguageModelDatasets.from_df(\n",
    "    df = df,\n",
    "    text_col = 'text',\n",
    "    splits=splits,\n",
    "    block_size=128,\n",
    "    tokenizer_name='bert-base-uncased',\n",
    "    tokenize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146c6f58",
   "metadata": {},
   "source": [
    "Once we have our tokenized `Dataset`, all we need to do is build our `DataLoaders`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd94bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dset.dataloaders(batch_size=8, shuffle_train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc91852c",
   "metadata": {},
   "source": [
    "Let's make sure a batch looks okay:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96862c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]),\n",
       " 'input_ids': tensor([[ 101, 2062, 5501,  ..., 2016, 7719, 2091],\n",
       "         [2425, 1012, 2175,  ...,    0,    0,    0],\n",
       "         [2140, 2000, 3087,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [   0,    0,    0,  ...,    0,    0,    0],\n",
       "         [2086, 2790, 3492,  ...,    0,    0,    0],\n",
       "         [   0,    0,    0,  ...,    0,    0,    0]]),\n",
       " 'labels': tensor([[ 101, 2062, 5501,  ..., 2016, 7719, 2091],\n",
       "         [2425, 1012, 2175,  ...,    0,    0,    0],\n",
       "         [2140, 2000, 3087,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [   0,    0,    0,  ...,    0,    0,    0],\n",
       "         [2086, 2790, 3492,  ...,    0,    0,    0],\n",
       "         [   0,    0,    0,  ...,    0,    0,    0]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dls[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fa1a31",
   "metadata": {},
   "source": [
    "Now let's Tune:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b114f7d0",
   "metadata": {},
   "source": [
    "## Tuning a Model\n",
    "\n",
    "Next we need to tune a model to our dataset. We'll use the `LanguageModelTuner` class for this, which as some good defaults for our task such as metrics and a loss function to use:\n",
    "\n",
    "> Note: We need to specify the type of language model we are fine-tuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7550932b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tuner = LanguageModelTuner(\n",
    "    dls, \n",
    "    model_name = 'bert-base-uncased', \n",
    "    language_model_type = LMType.Masked\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db205786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = tuner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c8e45d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      33.33% [1/3 01:58<03:56]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.029909</td>\n",
       "      <td>0.014674</td>\n",
       "      <td>0.997617</td>\n",
       "      <td>1.014782</td>\n",
       "      <td>01:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='90' class='' max='450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      20.00% [90/450 00:22<01:30 0.0109]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-7b40de8323fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m tuner.tune(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalley\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mstrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mStrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOneCycle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m/home/jovyan/adaptnlp/adaptnlp/training/tuner.py\u001b[0m in \u001b[0;36mtune\u001b[0;34m(self, epochs, lr, strategy, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m'epochs,lr,cbs'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdelegates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_find\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.8/site-packages/fastai/callback/schedule.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    111\u001b[0m     scheds = {'lr': combined_cos(pct_start, lr_max/div, lr_max, lr_max/div_final),\n\u001b[1;32m    112\u001b[0m               'mom': combined_cos(pct_start, *(self.moms if moms is None else moms))}\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mParamScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_hypers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelFitException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_end_cleanup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_end_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_one_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'batch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelBatchException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jovyan/adaptnlp/adaptnlp/training/tuner.py\u001b[0m in \u001b[0;36m_do_one_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;31m# See if `to_device` fixes this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'logits'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_pred'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1309\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1310\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    969\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         )\n\u001b[0;32m--> 971\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    972\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    566\u001b[0m                 )\n\u001b[1;32m    567\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    569\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    457\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     ):\n\u001b[0;32m--> 387\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    388\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    307\u001b[0m                 \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrelative_position_scores_query\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrelative_position_scores_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;31m# Apply the attention mask is (precomputed for all layers in BertModel forward() function)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner.tune(\n",
    "    epochs = 3,\n",
    "    lr = float(lr.valley),\n",
    "    strategy=Strategy.OneCycle\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf7b247",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
