{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp inference.embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings\n",
    "> AdaptNLP Embeddings Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import test_eq\n",
    "from fastcore.xtras import is_listy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import logging, torch\n",
    "from typing import List, Dict, Union\n",
    "from fastcore.basics import listify\n",
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "from fastcore.basics import mk_class\n",
    "from fastcore.xtras import dict2obj\n",
    "from fastcore.dispatch import typedispatch\n",
    "from flair.data import Sentence\n",
    "from flair.embeddings import (\n",
    "    Embeddings,\n",
    "    WordEmbeddings,\n",
    "    StackedEmbeddings,\n",
    "    FlairEmbeddings,\n",
    "    DocumentPoolEmbeddings,\n",
    "    DocumentRNNEmbeddings,\n",
    "    TransformerWordEmbeddings,\n",
    ")\n",
    "\n",
    "from adaptnlp.model_hub import FlairModelResult, HFModelResult, HFModelHub, FlairModelHub\n",
    "\n",
    "from adaptnlp.result import SentenceResult, DetailLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_flair_hub = FlairModelHub()\n",
    "_hf_hub = HFModelHub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "@typedispatch\n",
    "def _make_sentences(text:str, as_list=False) -> Union[List[Sentence], Sentence]:\n",
    "    return [Sentence(text)] if as_list else Sentence(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_sentences = 'a,b,c'.split(',')\n",
    "out = [_make_sentences(o) for o in test_sentences]\n",
    "tst_out = [Sentence('a'), Sentence('b'), Sentence('c')]\n",
    "for o,t in zip(out, tst_out):\n",
    "    test_eq(o[0].text, t[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "@typedispatch\n",
    "def _make_sentences(text:list, as_list=False) -> Union[List[Sentence], Sentence]:\n",
    "    if all(isinstance(t,str) for t in text):\n",
    "        return [Sentence(t) for t in text]\n",
    "    elif all(isinstance(t, Sentence) for t in text):\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_sentence = 'My name is Zach'\n",
    "out = _make_sentences(test_sentence, as_list=True)\n",
    "tst_out = [Sentence(test_sentence)]\n",
    "for o,t in zip(out, tst_out):\n",
    "    test_eq(o[0].text, t[0].text)\n",
    "test_eq(is_listy(out), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "@typedispatch\n",
    "def _make_sentences(text:Sentence, as_list=False) -> Union[List[Sentence], Sentence]:\n",
    "    return [text] if as_list else text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_sentence = Sentence('Me')\n",
    "out = _make_sentences(test_sentence)\n",
    "test_eq(test_sentence[0].text, out[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "@typedispatch\n",
    "def _get_embedding_model(model_name_or_path:HFModelResult) -> TransformerWordEmbeddings:\n",
    "    return TransformerWordEmbeddings(model_name_or_path.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "@typedispatch\n",
    "def _get_embedding_model(model_name_or_path:FlairModelResult) -> Union[FlairEmbeddings, WordEmbeddings]:\n",
    "    nm = model_name_or_path.name\n",
    "    try:\n",
    "        return WordEmbeddings(nm.strip('flairNLP/'))\n",
    "    except:\n",
    "        return FlairEmbeddings(nm.strip('flairNLP/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "@typedispatch\n",
    "def _get_embedding_model(model_name_or_path:str) -> Union[TransformerWordEmbeddings, WordEmbeddings, FlairEmbeddings]:\n",
    "    res = _flair_hub.search_model_by_name(model_name_or_path, user_uploaded=True)\n",
    "    if len(res) < 1:\n",
    "        # No models found\n",
    "        res = _hf_hub.search_model_by_name(model_name_or_path, user_uploaded=True)\n",
    "        if len(res) < 1:\n",
    "            raise ValueError(f'Embeddings not found for the model key: {model_name_or_path}, check documentation or custom model path to verify specified model')\n",
    "        else:\n",
    "            return TransformerWordEmbeddings(res[0].name) # Returning the first should always be the non-fast option\n",
    "    else:\n",
    "        nm = res[0].name\n",
    "        try:\n",
    "            return WordEmbeddings(nm.strip('flairNLP/'))\n",
    "        except:\n",
    "            return FlairEmbeddings(nm.strip('flairNLP/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EmbeddingResult(SentenceResult):\n",
    "    \"\"\"\n",
    "    A result class designed for Embedding models\n",
    "    \"\"\"\n",
    "    def __init__(self, sentences:List[Sentence]): super().__init__(sentences)\n",
    "    \n",
    "    @property\n",
    "    def sentence_embeddings(self) -> List[torch.tensor]:\n",
    "        \"\"\"\n",
    "        All embeddings in `sentences` (if available)\n",
    "        \"\"\"\n",
    "        return [s.get_embedding() for s in self._sentences]\n",
    "    \n",
    "    @property\n",
    "    def token_embeddings(self) -> List[torch.tensor]:\n",
    "        \"\"\"\n",
    "        All embeddings from the individual tokens in `sentence` with original order in shape (n, embed_dim)\n",
    "        \"\"\"\n",
    "        return [torch.stack([tok.get_embedding() for tok in s], dim=0) for s in self._sentences]\n",
    "    \n",
    "    def to_dict(self, detail_level:DetailLevel=DetailLevel.Low):\n",
    "        o = OrderedDict()\n",
    "        o.update({'inputs':self.inputs,\n",
    "                  'sentence_embeddings':self.sentence_embeddings,\n",
    "                 'token_embeddings':self.token_embeddings})\n",
    "        if detail_level == \"low\": return o\n",
    "        if detail_level == 'medium' or detail_level == 'high':\n",
    "            # Return embeddings/word pairs and indicies, and the tokenized input\n",
    "            for s in self._sentences:\n",
    "                o.update({\n",
    "                    tok.text:{\n",
    "                        'embeddings':tok.get_embedding(),\n",
    "                        'word_idx':tok.idx\n",
    "                    } for tok in s\n",
    "                })\n",
    "            o.update({\n",
    "                'tokenized_inputs':self.tokenized_inputs\n",
    "            })\n",
    "        if detail_level == 'high':\n",
    "            # Return embeddings/word pairs, indicies, and the original Sentences objects\n",
    "            for s in self._sentences:\n",
    "                o.update({tok.text:{\n",
    "                    'embeddings':tok.get_embedding(),\n",
    "                    'word_idx':tok.idx\n",
    "                    } for tok in s})\n",
    "            o.update({'sentences':self._sentences})\n",
    "        return o\n",
    "    \n",
    "    def __repr__(self):\n",
    "        s = f\"{self.__class__.__name__}:\" + \" {\"\n",
    "        s += f'\\n\\tInputs: {self.inputs}'\n",
    "        if self.token_embeddings is not None: s += f'\\n\\tToken Embeddings Shapes: {[f.shape for f in self.token_embeddings]}'\n",
    "        if self.sentence_embeddings is not None: s += f'\\n\\tSentence Embeddings Shapes: {[f.shape for f in self.sentence_embeddings]}'\n",
    "        return s + '\\n}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EasyWordEmbeddings:\n",
    "    \"\"\"Word embeddings from the latest language models\n",
    "\n",
    "    Usage:\n",
    "\n",
    "    ```python\n",
    "    >>> embeddings = adaptnlp.EasyWordEmbeddings()\n",
    "    >>> embeddings.embed_text(\"text you want embeddings for\", model_name_or_path=\"bert-base-cased\")\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.models: Dict[Embeddings] = defaultdict(bool)\n",
    "\n",
    "    def embed_text(\n",
    "        self,\n",
    "        text: Union[List[Sentence], Sentence, List[str], str], # Text input, it can be a string or any of Flair's `Sentence` input formats\n",
    "        model_name_or_path: Union[str, HFModelResult, FlairModelResult] = \"bert-base-cased\", # The hosted model name key, model path, or an instance of either `HFModelResult` or `FlairModelResult`\n",
    "        detail_level:DetailLevel = DetailLevel.Low, # A level of detail to return. By default is None, which returns a EmbeddingResult, otherwise will return a dict\n",
    "        raw:bool=False # Whether to return the raw outputs\n",
    "    ) -> List[EmbeddingResult]:\n",
    "        \"\"\"Produces embeddings for text\n",
    "        \n",
    "        **Return**:\n",
    "        * A list of either EmbeddingResult's or dictionaries with information\n",
    "        \"\"\"\n",
    "        # Convert into sentences\n",
    "        sentences = _make_sentences(text)\n",
    "\n",
    "        # Load correct Embeddings module\n",
    "        if model_name_or_path not in self.models.keys():\n",
    "            self.models[model_name_or_path] = _get_embedding_model(model_name_or_path)\n",
    "        embedding = self.models[model_name_or_path]\n",
    "        embeds = embedding.embed(sentences)\n",
    "        \n",
    "        if not raw:\n",
    "            res = EmbeddingResult(listify(embeds))\n",
    "            return res.to_dict(detail_level) if detail_level is not None else res\n",
    "        else:\n",
    "            return listify(embeds)\n",
    "\n",
    "    def embed_all(\n",
    "        self,\n",
    "        text: Union[List[Sentence], Sentence, List[str], str], # Text input, it can be a string or any of Flair's `Sentence` input formats\n",
    "        model_names_or_paths:List[str] = [], # A list of model names\n",
    "        detail_level:DetailLevel=DetailLevel.Low, # A level of detail to return. By default is None, which returns a EmbeddingResult, otherwise will return a dict\n",
    "    ) -> List[EmbeddingResult]:\n",
    "        \"\"\"Embeds text with all embedding models loaded\n",
    "        \n",
    "        **Return**:\n",
    "        * A list of either EmbeddingResult's or dictionaries with information\n",
    "        \"\"\"\n",
    "        # Convert into sentences\n",
    "        sentences = _make_sentences(text)\n",
    "\n",
    "        if model_names_or_paths:\n",
    "            for embedding_name in model_names_or_paths:\n",
    "                sentences = self.embed_text(\n",
    "                    sentences, model_name_or_path=embedding_name, raw=True\n",
    "                )\n",
    "        else:\n",
    "            for embedding_name in self.models.keys():\n",
    "                sentences = self.embed_text(\n",
    "                    sentences, model_name_or_path=embedding_name, raw=True\n",
    "                )\n",
    "        res = EmbeddingResult(listify(sentences))\n",
    "        return res.to_dict(detail_level) if detail_level is not None else res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased-finetuned-mrpc were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "import torch\n",
    "embeddings = EasyWordEmbeddings()\n",
    "res = embeddings.embed_text(\"text you want embeddings for\", model_name_or_path=\"bert-base-cased\")\n",
    "test_eq(res['token_embeddings'][0].shape, torch.Size([5, 768]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EasyWordEmbeddings.embed_text\" class=\"doc_header\"><code>EasyWordEmbeddings.embed_text</code><a href=\"__main__.py#L16\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EasyWordEmbeddings.embed_text</code>(**`text`**:`Union`\\[`List`\\[`Sentence`\\], `Sentence`, `List`\\[`str`\\], `str`\\], **`model_name_or_path`**:`Union`\\[`str`, [`HFModelResult`](/adaptnlpmodel_hub.html#HFModelResult), [`FlairModelResult`](/adaptnlpmodel_hub.html#FlairModelResult)\\]=*`'bert-base-cased'`*, **`detail_level`**:`DetailLevel`=*`'low'`*, **`raw`**:`bool`=*`False`*)\n",
       "\n",
       "Produces embeddings for text\n",
       "\n",
       "**Return**:\n",
       "* A list of either EmbeddingResult's or dictionaries with information\n",
       "\n",
       "**Function Arguments**:\n",
       "* `text` (`Union[List[Sentence]`, `Sentence`, `List[str]`, `str]`): Text input, it can be a string or any of Flair's `Sentence` input formats\n",
       "* `model_name_or_path` (`Union[str`, `HFModelResult`, `FlairModelResult]`): The hosted model name key, model path, or an instance of either `HFModelResult` or `FlairModelResult`\n",
       "* `detail_level` (`DetailLevel`): A level of detail to return. By default is None, which returns a EmbeddingResult, otherwise will return a dict\n",
       "* `raw` (`bool`): Whether to return the raw outputs\n",
       "\n",
       "\n",
       "**Usage Examples:**\n",
       "\n",
       "<b><a href=https://nbviewer.jupyter.org/github/novetta/adaptnlp/tree/master/nbs/04_embeddings.ipynb>Source</a></b>\n",
       "```python\n",
       "#hide\n",
       "import torch\n",
       "embeddings = EasyWordEmbeddings()\n",
       "res = embeddings.embed_text(\"text you want embeddings for\", model_name_or_path=\"bert-base-cased\")\n",
       "test_eq(res['token_embeddings'][0].shape, torch.Size([5, 768]))\n",
       "```\n",
       "<b><a href=https://nbviewer.jupyter.org/github/novetta/adaptnlp/tree/master/nbs/04a_tutorial.embeddings.ipynb>Source</a></b>\n",
       "```python\n",
       "embeddings = EasyWordEmbeddings()\n",
       "res = embeddings.embed_text(example_text, model_name_or_path=model)\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EasyWordEmbeddings.embed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "res = embeddings.embed_all(['text you want embeddings for', 'My name is Zach'],\n",
    "                           ['bert-base-cased', 'xlnet-base-cased'])\n",
    "test_eq(res['token_embeddings'][0].shape, torch.Size([5,1536]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EasyWordEmbeddings.embed_all\" class=\"doc_header\"><code>EasyWordEmbeddings.embed_all</code><a href=\"__main__.py#L43\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EasyWordEmbeddings.embed_all</code>(**`text`**:`Union`\\[`List`\\[`Sentence`\\], `Sentence`, `List`\\[`str`\\], `str`\\], **`model_names_or_paths`**:`List`\\[`str`\\]=*`[]`*, **`detail_level`**:`DetailLevel`=*`'low'`*)\n",
       "\n",
       "Embeds text with all embedding models loaded\n",
       "\n",
       "**Return**:\n",
       "* A list of either EmbeddingResult's or dictionaries with information\n",
       "\n",
       "**Function Arguments**:\n",
       "* `text` (`Union[List[Sentence]`, `Sentence`, `List[str]`, `str]`): Text input, it can be a string or any of Flair's `Sentence` input formats\n",
       "* `model_names_or_paths` (`List[str]`): A list of model names\n",
       "* `detail_level` (`DetailLevel`): A level of detail to return. By default is None, which returns a EmbeddingResult, otherwise will return a dict\n",
       "\n",
       "\n",
       "**Usage Examples:**\n",
       "\n",
       "<b><a href=https://nbviewer.jupyter.org/github/novetta/adaptnlp/tree/master/nbs/04_embeddings.ipynb>Source</a></b>\n",
       "```python\n",
       "#hide\n",
       "import torch\n",
       "embeddings = EasyWordEmbeddings()\n",
       "res = embeddings.embed_text(\"text you want embeddings for\", model_name_or_path=\"bert-base-cased\")\n",
       "test_eq(res['token_embeddings'][0].shape, torch.Size([5, 768]))\n",
       "#hide\n",
       "res = embeddings.embed_all(['text you want embeddings for', 'My name is Zach'],\n",
       "                           ['bert-base-cased', 'xlnet-base-cased'])\n",
       "test_eq(res['token_embeddings'][0].shape, torch.Size([5,1536]))\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EasyWordEmbeddings.embed_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EasyStackedEmbeddings:\n",
    "    \"\"\"Word Embeddings that have been concatenated and \"stacked\" as specified by flair\n",
    "\n",
    "    Usage:\n",
    "\n",
    "    ```python\n",
    "    >>> embeddings = adaptnlp.EasyStackedEmbeddings(\"bert-base-cased\", \"gpt2\", \"xlnet-base-cased\")\n",
    "    ```\n",
    "\n",
    "    **Parameters:**\n",
    "\n",
    "    * `embeddings` - Non-keyword variable number of strings specifying the embeddings you want to stack\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *embeddings: str):\n",
    "        print(\"May need a couple moments to instantiate...\")\n",
    "        self.embedding_stack = []\n",
    "\n",
    "        # Load correct Embeddings module\n",
    "        for model_name_or_path in embeddings:\n",
    "            self.embedding_stack.append(_get_embedding_model(model_name_or_path))\n",
    "\n",
    "        assert len(self.embedding_stack) != 0\n",
    "        self.stacked_embeddings = StackedEmbeddings(embeddings=self.embedding_stack)\n",
    "\n",
    "    def embed_text(\n",
    "        self,\n",
    "        text: Union[List[Sentence], Sentence, List[str], str], # Text input, it can be a string or any of Flair's `Sentence` input formats\n",
    "        detail_level:DetailLevel = DetailLevel.Low # A level of detail to return. By default is None, which returns a EmbeddingResult, otherwise will return a dict\n",
    "    ) -> List[EmbeddingResult]:\n",
    "        \"\"\"Stacked embeddings\n",
    "        \n",
    "        **Return**:\n",
    "        * A list of either EmbeddingResult's or dictionaries with information\n",
    "        \"\"\"\n",
    "        # Convert into sentences\n",
    "        sentences = _make_sentences(text, as_list=True)\n",
    "\n",
    "        # Unlike flair embeddings modules, stacked embeddings do not return a list of sentences\n",
    "        self.stacked_embeddings.embed(sentences)\n",
    "        \n",
    "        res = EmbeddingResult(listify(sentences))\n",
    "        return res.to_dict(detail_level) if detail_level is not None else res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "May need a couple moments to instantiate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased-finetuned-mrpc were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "embeddings = EasyStackedEmbeddings(\"bert-base-cased\", \"xlnet-base-cased\")\n",
    "sentences = embeddings.embed_text(\"This is Albert.  My last name is Einstein.  I like physics and atoms.\")\n",
    "test_eq(sentences['token_embeddings'][0].shape, torch.Size([16,1536]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EasyStackedEmbeddings.embed_text\" class=\"doc_header\"><code>EasyStackedEmbeddings.embed_text</code><a href=\"__main__.py#L27\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EasyStackedEmbeddings.embed_text</code>(**`text`**:`Union`\\[`List`\\[`Sentence`\\], `Sentence`, `List`\\[`str`\\], `str`\\], **`detail_level`**:`DetailLevel`=*`'low'`*)\n",
       "\n",
       "Stacked embeddings\n",
       "\n",
       "**Return**:\n",
       "* A list of either EmbeddingResult's or dictionaries with information\n",
       "\n",
       "**Function Arguments**:\n",
       "* `text` (`Union[List[Sentence]`, `Sentence`, `List[str]`, `str]`): Text input, it can be a string or any of Flair's `Sentence` input formats\n",
       "* `detail_level` (`DetailLevel`): A level of detail to return. By default is None, which returns a EmbeddingResult, otherwise will return a dict\n",
       "\n",
       "\n",
       "**Usage Examples:**\n",
       "\n",
       "<b><a href=https://nbviewer.jupyter.org/github/novetta/adaptnlp/tree/master/nbs/04_embeddings.ipynb>Source</a></b>\n",
       "```python\n",
       "#hide\n",
       "embeddings = EasyStackedEmbeddings(\"bert-base-cased\", \"xlnet-base-cased\")\n",
       "sentences = embeddings.embed_text(\"This is Albert.  My last name is Einstein.  I like physics and atoms.\")\n",
       "test_eq(sentences['token_embeddings'][0].shape, torch.Size([16,1536]))\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EasyStackedEmbeddings.embed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EasyDocumentEmbeddings:\n",
    "    \"\"\"Document Embeddings generated by pool and rnn methods applied to the word embeddings of text\n",
    "\n",
    "    Usage:\n",
    "\n",
    "    ```python\n",
    "    >>> embeddings = adaptnlp.EasyDocumentEmbeddings(\"bert-base-cased\", \"xlnet-base-cased\", methods[\"rnn\"])\n",
    "    ```\n",
    "\n",
    "    **Parameters:**\n",
    "\n",
    "    * `embeddings` - Non-keyword variable number of strings referring to model names or paths\n",
    "    * `methods` - A list of strings to specify which document embeddings to use i.e. [\"rnn\", \"pool\"] (avoids unncessary loading of models if only using one)\n",
    "    * `configs` - A dictionary of configurations for flair's rnn and pool document embeddings\n",
    "    ```python\n",
    "    >>> example_configs = {\"pool_configs\": {\"fine_tune_mode\": \"linear\", \"pooling\": \"mean\", },\n",
    "    ...                   \"rnn_configs\": {\"hidden_size\": 512,\n",
    "    ...                                   \"rnn_layers\": 1,\n",
    "    ...                                   \"reproject_words\": True,\n",
    "    ...                                   \"reproject_words_dimension\": 256,\n",
    "    ...                                   \"bidirectional\": False,\n",
    "    ...                                   \"dropout\": 0.5,\n",
    "    ...                                   \"word_dropout\": 0.0,\n",
    "    ...                                   \"locked_dropout\": 0.0,\n",
    "    ...                                   \"rnn_type\": \"GRU\",\n",
    "    ...                                   \"fine_tune\": True, },\n",
    "    ...                  }\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    __allowed_methods = [\"rnn\", \"pool\"]\n",
    "    __allowed_configs = (\"pool_configs\", \"rnn_configs\")\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *embeddings: str,\n",
    "        methods: List[str] = [\"rnn\", \"pool\"],\n",
    "        configs: Dict = {\n",
    "            \"pool_configs\": {\"fine_tune_mode\": \"linear\", \"pooling\": \"mean\"},\n",
    "            \"rnn_configs\": {\n",
    "                \"hidden_size\": 512,\n",
    "                \"rnn_layers\": 1,\n",
    "                \"reproject_words\": True,\n",
    "                \"reproject_words_dimension\": 256,\n",
    "                \"bidirectional\": False,\n",
    "                \"dropout\": 0.5,\n",
    "                \"word_dropout\": 0.0,\n",
    "                \"locked_dropout\": 0.0,\n",
    "                \"rnn_type\": \"GRU\",\n",
    "                \"fine_tune\": True,\n",
    "            },\n",
    "        },\n",
    "    ):\n",
    "        print(\"May need a couple moments to instantiate...\")\n",
    "        self.embedding_stack = []\n",
    "\n",
    "        # Check methods\n",
    "        for m in methods:\n",
    "            assert m in self.__class__.__allowed_methods\n",
    "\n",
    "        # Set configs for pooling and rnn parameters\n",
    "        for k, v in configs.items():\n",
    "            assert k in self.__class__.__allowed_configs\n",
    "            setattr(self, k, v)\n",
    "\n",
    "        # Load correct Embeddings module\n",
    "        for model_name_or_path in embeddings:\n",
    "            self.embedding_stack.append(_get_embedding_model(model_name_or_path))\n",
    "\n",
    "        assert len(self.embedding_stack) != 0\n",
    "        if \"pool\" in methods:\n",
    "            self.pool_embeddings = DocumentPoolEmbeddings(\n",
    "                self.embedding_stack, **self.pool_configs\n",
    "            )\n",
    "            print(\"Pooled embedding loaded\")\n",
    "        if \"rnn\" in methods:\n",
    "            self.rnn_embeddings = DocumentRNNEmbeddings(\n",
    "                self.embedding_stack, **self.rnn_configs\n",
    "            )\n",
    "            print(\"RNN embeddings loaded\")\n",
    "\n",
    "    def embed_pool(\n",
    "        self,\n",
    "        text: Union[List[Sentence], Sentence, List[str], str],\n",
    "        detail_level:DetailLevel = DetailLevel.Low,\n",
    "    ) -> List[EmbeddingResult]:\n",
    "        \"\"\"Generate stacked embeddings with `DocumentPoolEmbeddings`\n",
    "\n",
    "        **Parameters**:\n",
    "        * `text` - Text input, it can be a string or any of Flair's `Sentence` input formats\n",
    "        * `detail_level` - A level of detail to return. By default is None, which returns a EmbeddingResult, otherwise will return a dict\n",
    "\n",
    "        **Return**:\n",
    "        * A list of either EmbeddingResult's or dictionaries with information\n",
    "        \"\"\"\n",
    "        sentences = _make_sentences(text, as_list=True)\n",
    "        self.pool_embeddings.embed(sentences)\n",
    "        res = EmbeddingResult(listify(sentences))\n",
    "        return res.to_dict(detail_level) if detail_level is not None else res\n",
    "\n",
    "    def embed_rnn(\n",
    "        self,\n",
    "        text: Union[List[Sentence], Sentence, List[str], str],\n",
    "        detail_level:DetailLevel = DetailLevel.Low,\n",
    "    ) -> List[Sentence]:\n",
    "        \"\"\"Generate stacked embeddings with `DocumentRNNEmbeddings`\n",
    "\n",
    "        **Parameters**:\n",
    "        * `text` - Text input, it can be a string or any of Flair's `Sentence` input formats\n",
    "        * `detail_level` - A level of detail to return. By default is None, which returns a EmbeddingResult, otherwise will return a dict\n",
    "\n",
    "        **Return**:\n",
    "        * A list of either EmbeddingResult's or dictionaries with information\n",
    "        \"\"\"\n",
    "        sentences = _make_sentences(text, as_list=True)\n",
    "        self.rnn_embeddings.embed(sentences)\n",
    "        res = EmbeddingResult(listify(sentences))\n",
    "        return res.to_dict(detail_level) if detail_level is not None else res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "May need a couple moments to instantiate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased-finetuned-mrpc were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled embedding loaded\n",
      "RNN embeddings loaded\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "embeddings = EasyDocumentEmbeddings(\"bert-base-cased\", \"xlnet-base-cased\")\n",
    "res = embeddings.embed_pool(\"This is Albert.  My last name is Einstein.  I like physics and atoms.\")\n",
    "test_eq(res['sentence_embeddings'][0].shape, torch.Size([1536]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "res = embeddings.embed_rnn(\"This is Albert.  My last name is Einstein.  I like physics and atoms.\")\n",
    "test_eq(res['sentence_embeddings'][0].shape, torch.Size([512]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EasyDocumentEmbeddings.embed_pool\" class=\"doc_header\"><code>EasyDocumentEmbeddings.embed_pool</code><a href=\"__main__.py#L83\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EasyDocumentEmbeddings.embed_pool</code>(**`text`**:`Union`\\[`List`\\[`Sentence`\\], `Sentence`, `List`\\[`str`\\], `str`\\], **`detail_level`**:`DetailLevel`=*`'low'`*)\n",
       "\n",
       "Generate stacked embeddings with `DocumentPoolEmbeddings`\n",
       "\n",
       "**Parameters**:\n",
       "* `text` - Text input, it can be a string or any of Flair's `Sentence` input formats\n",
       "* `detail_level` - A level of detail to return. By default is None, which returns a EmbeddingResult, otherwise will return a dict\n",
       "\n",
       "**Return**:\n",
       "* A list of either EmbeddingResult's or dictionaries with information\n",
       "\n",
       "\n",
       "\n",
       "**Usage Examples:**\n",
       "\n",
       "<b><a href=https://nbviewer.jupyter.org/github/novetta/adaptnlp/tree/master/nbs/04_embeddings.ipynb>Source</a></b>\n",
       "```python\n",
       "#hide\n",
       "embeddings = EasyDocumentEmbeddings(\"bert-base-cased\", \"xlnet-base-cased\")\n",
       "res = embeddings.embed_pool(\"This is Albert.  My last name is Einstein.  I like physics and atoms.\")\n",
       "test_eq(res['sentence_embeddings'][0].shape, torch.Size([1536]))\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EasyDocumentEmbeddings.embed_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EasyDocumentEmbeddings.embed_rnn\" class=\"doc_header\"><code>EasyDocumentEmbeddings.embed_rnn</code><a href=\"__main__.py#L102\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EasyDocumentEmbeddings.embed_rnn</code>(**`text`**:`Union`\\[`List`\\[`Sentence`\\], `Sentence`, `List`\\[`str`\\], `str`\\], **`detail_level`**:`DetailLevel`=*`'low'`*)\n",
       "\n",
       "Generate stacked embeddings with `DocumentRNNEmbeddings`\n",
       "\n",
       "**Parameters**:\n",
       "* `text` - Text input, it can be a string or any of Flair's `Sentence` input formats\n",
       "* `detail_level` - A level of detail to return. By default is None, which returns a EmbeddingResult, otherwise will return a dict\n",
       "\n",
       "**Return**:\n",
       "* A list of either EmbeddingResult's or dictionaries with information\n",
       "\n",
       "\n",
       "\n",
       "**Usage Examples:**\n",
       "\n",
       "<b><a href=https://nbviewer.jupyter.org/github/novetta/adaptnlp/tree/master/nbs/04_embeddings.ipynb>Source</a></b>\n",
       "```python\n",
       "#hide\n",
       "embeddings = EasyDocumentEmbeddings(\"bert-base-cased\", \"xlnet-base-cased\")\n",
       "res = embeddings.embed_pool(\"This is Albert.  My last name is Einstein.  I like physics and atoms.\")\n",
       "test_eq(res['sentence_embeddings'][0].shape, torch.Size([1536]))\n",
       "#hide\n",
       "res = embeddings.embed_rnn(\"This is Albert.  My last name is Einstein.  I like physics and atoms.\")\n",
       "test_eq(res['sentence_embeddings'][0].shape, torch.Size([512]))\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EasyDocumentEmbeddings.embed_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
