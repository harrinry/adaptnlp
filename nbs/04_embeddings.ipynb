{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings\n",
    "> AdaptNLP Embeddings Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import test_eq\n",
    "from fastcore.xtras import is_listy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "import logging\n",
    "from typing import List, Dict, Union\n",
    "from collections import defaultdict\n",
    "\n",
    "from fastcore.dispatch import typedispatch\n",
    "from flair.data import Sentence\n",
    "from flair.embeddings import (\n",
    "    Embeddings,\n",
    "    WordEmbeddings,\n",
    "    StackedEmbeddings,\n",
    "    FlairEmbeddings,\n",
    "    DocumentPoolEmbeddings,\n",
    "    DocumentRNNEmbeddings,\n",
    "    TransformerWordEmbeddings,\n",
    ")\n",
    "\n",
    "from adaptnlp.model_hub import FlairModelHub, HFModelHub, FlairModelResult, HFModelResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_flair_hub = FlairModelHub()\n",
    "_hf_hub = HFModelHub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "@typedispatch\n",
    "def _make_sentences(text:str, as_list=False) -> Union[List[Sentence], Sentence]:\n",
    "    return [Sentence(text)] if as_list else Sentence(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_sentences = 'a,b,c'.split(',')\n",
    "out = _make_sentences(test_sentences)\n",
    "tst_out = [Sentence('a'), Sentence('b'), Sentence('c')]\n",
    "for o,t in zip(out, tst_out):\n",
    "    test_eq(o[0].text, t[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "@typedispatch\n",
    "def _make_sentences(text:list, as_list=False) -> Union[List[Sentence], Sentence]:\n",
    "    if all(isinstance(t,str) for t in text):\n",
    "        return [Sentence(t) for t in text]\n",
    "    elif all(isinstance(t, Sentence) for t in text):\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_sentence = 'My name is Zach'\n",
    "out = _make_sentences(test_sentence, as_list=True)\n",
    "tst_out = [Sentence(test_sentence)]\n",
    "for o,t in zip(out, tst_out):\n",
    "    test_eq(o[0].text, t[0].text)\n",
    "test_eq(is_listy(out), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "@typedispatch\n",
    "def _make_sentences(text:Sentence, as_list=False) -> Union[List[Sentence], Sentence]:\n",
    "    return [text] if as_list else text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_sentence = Sentence('Me')\n",
    "out = _make_sentences(test_sentence)\n",
    "test_eq(test_sentence[0].text, out[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "@typedispatch\n",
    "def _get_embedding_model(model_name_or_path:HFModelResult) -> TransformerWordEmbeddings:\n",
    "    return TransformerWordEmbeddings(model_name_or_path.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "@typedispatch\n",
    "def _get_embedding_model(model_name_or_path:FlairModelResult) -> Union[FlairEmbeddings, WordEmbeddings]:\n",
    "    nm = model_name_or_path.name\n",
    "    try:\n",
    "        return WordEmbeddings(nm.strip('flairNLP/'))\n",
    "    except:\n",
    "        return FlairEmbeddings(nm.strip('flairNLP/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "@typedispatch\n",
    "def _get_embedding_model(model_name_or_path:str) -> Union[TransformerWordEmbeddings, WordEmbeddings, FlairEmbeddings]:\n",
    "    res = _flair_hub.search_model_by_name(model_name_or_path, user_uploaded=True)\n",
    "    if len(res) < 1:\n",
    "        # No models found\n",
    "        res = _hf_hub.search_model_by_name(model_name_or_path, user_uploaded=True)\n",
    "        if len(res) < 1:\n",
    "            raise ValueError(f'Embeddings not found for the model key: {model_name_or_path}, check documentation or custom model path to verify specified model')\n",
    "        else:\n",
    "            return TransformerWordEmbeddings(res[0].name) # Returning the first should always be the non-fast option\n",
    "    else:\n",
    "        nm = res[0].name\n",
    "        try:\n",
    "            return WordEmbeddings(nm.strip('flairNLP/'))\n",
    "        except:\n",
    "            return FlairEmbeddings(nm.strip('flairNLP/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EasyWordEmbeddings:\n",
    "    \"\"\"Word embeddings from the latest language models\n",
    "\n",
    "    Usage:\n",
    "\n",
    "    ```python\n",
    "    >>> embeddings = adaptnlp.EasyWordEmbeddings()\n",
    "    >>> embeddings.embed_text(\"text you want embeddings for\", model_name_or_path=\"bert-base-cased\")\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.models: Dict[Embeddings] = defaultdict(bool)\n",
    "\n",
    "    def embed_text(\n",
    "        self,\n",
    "        text: Union[List[Sentence], Sentence, List[str], str],\n",
    "        model_name_or_path: Union[str, HFModelResult, FlairModelResult] = \"bert-base-cased\",\n",
    "    ) -> List[Sentence]:\n",
    "        \"\"\"Produces embeddings for text\n",
    "\n",
    "        **Parameters**:\n",
    "        * `text` - Text input, it can be a string or any of Flair's `Sentence` input formats\n",
    "        * `model_name_or_path` - The hosted model name key, model path, or an instance of either `HFModelResult` or `FlairModelResult`\n",
    "\n",
    "        **Return**:\n",
    "        * A list of Flair's `Sentence`s\n",
    "        \"\"\"\n",
    "        # Convert into sentences\n",
    "        sentences = _make_sentences(text)\n",
    "\n",
    "        # Load correct Embeddings module\n",
    "        if model_name_or_path not in self.models.keys():\n",
    "            self.models[model_name_or_path] = _get_embedding_model(model_name_or_path)\n",
    "        embedding = self.models[model_name_or_path]\n",
    "        return embedding.embed(sentences)\n",
    "\n",
    "    def embed_all(\n",
    "        self,\n",
    "        text: Union[List[Sentence], Sentence, List[str], str],\n",
    "        *model_names_or_paths: str,\n",
    "    ) -> List[Sentence]:\n",
    "        \"\"\"Embeds text with all embedding models loaded\n",
    "\n",
    "        **Parameters**:\n",
    "        * `text` - Text input, it can be a string or any of Flair's `Sentence` input formats\n",
    "        * `model_names_or_paths` -  A variable input of model names or paths to embed\n",
    "\n",
    "        **Return**:\n",
    "        * A list of Flair's `Sentence`s\n",
    "        \"\"\"\n",
    "        # Convert into sentences\n",
    "        sentences = _make_sentences(text)\n",
    "\n",
    "        if model_names_or_paths:\n",
    "            for embedding_name in model_names_or_paths:\n",
    "                sentences = self.embed_text(\n",
    "                    sentences, model_name_or_path=embedding_name\n",
    "                )\n",
    "        else:\n",
    "            for embedding_name in self.models.keys():\n",
    "                sentences = self.embed_text(\n",
    "                    sentences, model_name_or_path=embedding_name\n",
    "                )\n",
    "        return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "290a0b1c29514084aedaf37b147e20ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6658994753344b3397d9288d734489f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a60d788b156048baa36e608fb1a98941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435797.0, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3215cf5ad5294ef8bd7a114afafc3bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=29.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55c8f63f8ccc401bb6d8cb5939088af4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433297515.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased-finetuned-mrpc were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "import torch\n",
    "embeddings = EasyWordEmbeddings()\n",
    "res = embeddings.embed_text(\"text you want embeddings for\", model_name_or_path=\"bert-base-cased\")\n",
    "test_eq(res[0][1].get_embedding().shape, torch.Size([768]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from transformers import pipeline\n",
    "import timeit\n",
    "\n",
    "from fastcore.test import test, test_close\n",
    "import operator as op\n",
    "\n",
    "# Ensure that speeds are comparible with that of raw HuggingFace\n",
    "\n",
    "def performance_test(\n",
    "    func_a:str, # A string of a function to time using AdaptNLP\n",
    "    func_b:str, # A string of a function to time using HuggingFace,\n",
    "    globals_a:dict, # A dict of globals `func_a` should expect\n",
    "    globals_b:dict, # A dict of globals `func_b` should expect\n",
    "    iterations:int=10, # Number of iterations\n",
    "    repeat:int=5, # Number of times to repeat `number` iterations,\n",
    "    thresh:float=0.01 # Threshold for `test_close`\n",
    "):\n",
    "    \"Tests the performance of `func_a` vs `func_b` and checks they either are close, or a is faster\"\n",
    "    time_adapt = timeit.repeat(func_a, globals=globals_a, number=iterations, repeat=repeat)\n",
    "    time_hf = timeit.repeat(func_b, globals=globals_b, number=iterations, repeat=repeat)\n",
    "    avg_a, avg_b = sum(time_adapt)/repeat, sum(time_hf)/repeat\n",
    "    # Test the performance\n",
    "    try:\n",
    "        test(avg_a, avg_b, op.lt)\n",
    "    except:\n",
    "        try:\n",
    "            test_close(avg_a, avg_b, thresh)\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"\"\"\n",
    "            HuggingFace was comparitively faster than AdaptNLP. Functions used:\n",
    "            -------------------------------------------------------------------\n",
    "            \n",
    "            AdaptNLP:\n",
    "            \\tFunction:{func_a}\n",
    "            \n",
    "            -------------------------------------------------------------------\n",
    "            \n",
    "            HuggingFace:\n",
    "            \\tFunction:{func_b}\n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "text = \"text you want embeddings for\"\n",
    "pipe = pipeline('feature-extraction', 'bert-base-cased')\n",
    "func_a = '_ = _embeddings.embed_text(\"text you want embeddings for\", model_name_or_path=\"bert-base-cased\")'\n",
    "glob_a = {'_embeddings':embeddings}\n",
    "func_b = '_ = _pipe(_text)'\n",
    "glob_b = {'_pipe':pipe, '_text':text}\n",
    "number=10\n",
    "\n",
    "performance_test(func_a, func_b, glob_a, glob_b, iterations=number, thresh=0.1) # Keep thresh within a tenth of a second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EasyStackedEmbeddings:\n",
    "    \"\"\"Word Embeddings that have been concatenated and \"stacked\" as specified by flair\n",
    "\n",
    "    Usage:\n",
    "\n",
    "    ```python\n",
    "    >>> embeddings = adaptnlp.EasyStackedEmbeddings(\"bert-base-cased\", \"gpt2\", \"xlnet-base-cased\")\n",
    "    ```\n",
    "\n",
    "    **Parameters:**\n",
    "\n",
    "    * `&ast;embeddings` - Non-keyword variable number of strings specifying the embeddings you want to stack\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *embeddings: str):\n",
    "        print(\"May need a couple moments to instantiate...\")\n",
    "        self.embedding_stack = []\n",
    "\n",
    "        # Load correct Embeddings module\n",
    "        for model_name_or_path in embeddings:\n",
    "            self.embedding_stack.append(_get_embedding_model(model_name_or_path))\n",
    "\n",
    "        assert len(self.embedding_stack) != 0\n",
    "        self.stacked_embeddings = StackedEmbeddings(embeddings=self.embedding_stack)\n",
    "\n",
    "    def embed_text(\n",
    "        self,\n",
    "        text: Union[List[Sentence], Sentence, List[str], str],\n",
    "    ) -> List[Sentence]:\n",
    "        \"\"\"Stacked embeddings\n",
    "\n",
    "        **Parameters**:\n",
    "        * `text` - Text input, it can be a string or any of Flair's `Sentence` input formats\n",
    "\n",
    "        **Return**:\n",
    "        * A list of Flair's `Sentence`s\n",
    "        \"\"\"\n",
    "        # Convert into sentences\n",
    "        sentences = _make_sentences(text, as_list=True)\n",
    "\n",
    "        # Unlike flair embeddings modules, stacked embeddings do not return a list of sentences\n",
    "        self.stacked_embeddings.embed(sentences)\n",
    "        return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "May need a couple moments to instantiate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased-finetuned-mrpc were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "embeddings = EasyStackedEmbeddings(\"bert-base-cased\", \"xlnet-base-cased\")\n",
    "sentences = embeddings.embed_text(\"This is Albert.  My last name is Einstein.  I like physics and atoms.\")\n",
    "test_eq(sentences[0][0].get_embedding().shape, torch.Size([1536]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EasyDocumentEmbeddings:\n",
    "    \"\"\"Document Embeddings generated by pool and rnn methods applied to the word embeddings of text\n",
    "\n",
    "    Usage:\n",
    "\n",
    "    ```python\n",
    "    >>> embeddings = adaptnlp.EasyDocumentEmbeddings(\"bert-base-cased\", \"xlnet-base-cased\", methods[\"rnn\"])\n",
    "    ```\n",
    "\n",
    "    **Parameters:**\n",
    "\n",
    "    * **`embeddings`** - Non-keyword variable number of strings referring to model names or paths\n",
    "    * `methods` - A list of strings to specify which document embeddings to use i.e. [\"rnn\", \"pool\"] (avoids unncessary loading of models if only using one)\n",
    "    * `configs` - A dictionary of configurations for flair's rnn and pool document embeddings\n",
    "    ```python\n",
    "    >>> example_configs = {\"pool_configs\": {\"fine_tune_mode\": \"linear\", \"pooling\": \"mean\", },\n",
    "    ...                   \"rnn_configs\": {\"hidden_size\": 512,\n",
    "    ...                                   \"rnn_layers\": 1,\n",
    "    ...                                   \"reproject_words\": True,\n",
    "    ...                                   \"reproject_words_dimension\": 256,\n",
    "    ...                                   \"bidirectional\": False,\n",
    "    ...                                   \"dropout\": 0.5,\n",
    "    ...                                   \"word_dropout\": 0.0,\n",
    "    ...                                   \"locked_dropout\": 0.0,\n",
    "    ...                                   \"rnn_type\": \"GRU\",\n",
    "    ...                                   \"fine_tune\": True, },\n",
    "    ...                  }\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    __allowed_methods = [\"rnn\", \"pool\"]\n",
    "    __allowed_configs = (\"pool_configs\", \"rnn_configs\")\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *embeddings: str,\n",
    "        methods: List[str] = [\"rnn\", \"pool\"],\n",
    "        configs: Dict = {\n",
    "            \"pool_configs\": {\"fine_tune_mode\": \"linear\", \"pooling\": \"mean\"},\n",
    "            \"rnn_configs\": {\n",
    "                \"hidden_size\": 512,\n",
    "                \"rnn_layers\": 1,\n",
    "                \"reproject_words\": True,\n",
    "                \"reproject_words_dimension\": 256,\n",
    "                \"bidirectional\": False,\n",
    "                \"dropout\": 0.5,\n",
    "                \"word_dropout\": 0.0,\n",
    "                \"locked_dropout\": 0.0,\n",
    "                \"rnn_type\": \"GRU\",\n",
    "                \"fine_tune\": True,\n",
    "            },\n",
    "        },\n",
    "    ):\n",
    "        print(\"May need a couple moments to instantiate...\")\n",
    "        self.embedding_stack = []\n",
    "\n",
    "        # Check methods\n",
    "        for m in methods:\n",
    "            assert m in self.__class__.__allowed_methods\n",
    "\n",
    "        # Set configs for pooling and rnn parameters\n",
    "        for k, v in configs.items():\n",
    "            assert k in self.__class__.__allowed_configs\n",
    "            setattr(self, k, v)\n",
    "\n",
    "        # Load correct Embeddings module\n",
    "        for model_name_or_path in embeddings:\n",
    "            self.embedding_stack.append(_get_embedding_model(model_name_or_path))\n",
    "\n",
    "        assert len(self.embedding_stack) != 0\n",
    "        if \"pool\" in methods:\n",
    "            self.pool_embeddings = DocumentPoolEmbeddings(\n",
    "                self.embedding_stack, **self.pool_configs\n",
    "            )\n",
    "            print(\"Pooled embedding loaded\")\n",
    "        if \"rnn\" in methods:\n",
    "            self.rnn_embeddings = DocumentRNNEmbeddings(\n",
    "                self.embedding_stack, **self.rnn_configs\n",
    "            )\n",
    "            print(\"RNN embeddings loaded\")\n",
    "\n",
    "    def embed_pool(\n",
    "        self,\n",
    "        text: Union[List[Sentence], Sentence, List[str], str],\n",
    "    ) -> List[Sentence]:\n",
    "        \"\"\"Generate stacked embeddings with `DocumentPoolEmbeddings`\n",
    "\n",
    "        **Parameters**:\n",
    "        * `text` - Text input, it can be a string or any of Flair's `Sentence` input formats\n",
    "\n",
    "        **Return**:\n",
    "        * A list of Flair's `Sentence`s\n",
    "        \"\"\"\n",
    "        sentences = _make_sentences(text, as_list=True)\n",
    "        self.pool_embeddings.embed(sentences)\n",
    "        return sentences\n",
    "\n",
    "    def embed_rnn(\n",
    "        self,\n",
    "        text: Union[List[Sentence], Sentence, List[str], str],\n",
    "    ) -> List[Sentence]:\n",
    "        \"\"\"Generate stacked embeddings with `DocumentRNNEmbeddings`\n",
    "\n",
    "        **Parameters**:\n",
    "        * `text` - Text input, it can be a string or any of Flair's `Sentence` input formats\n",
    "\n",
    "        **Return**:\n",
    "        * A list of Flair's `Sentence`s\n",
    "        \"\"\"\n",
    "        sentences = _make_sentences(text, as_list=True)\n",
    "        self.rnn_embeddings.embed(sentences)\n",
    "        return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "May need a couple moments to instantiate...\n",
      "Pooled embedding loaded\n",
      "RNN embeddings loaded\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "embeddings = EasyDocumentEmbeddings(\"bert-base-cased\", \"xlnet-base-cased\")\n",
    "text = embeddings.embed_pool(\"This is Albert.  My last name is Einstein.  I like physics and atoms.\")\n",
    "test_eq(text[0].get_embedding().shape, torch.Size([1536]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "text = embeddings.embed_rnn(\"This is Albert.  My last name is Einstein.  I like physics and atoms.\")\n",
    "test_eq(text[0].get_embedding().shape, torch.Size([512]))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
