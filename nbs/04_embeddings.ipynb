{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp inference.embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings\n",
    "> AdaptNLP Embeddings Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbverbose.showdoc import *\n",
    "from fastcore.test import test_eq\n",
    "from fastcore.xtras import is_listy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import logging, torch\n",
    "from typing import List, Dict, Union\n",
    "from fastcore.basics import listify\n",
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "from fastcore.basics import mk_class\n",
    "from fastcore.xtras import dict2obj\n",
    "from fastcore.dispatch import typedispatch\n",
    "from flair.data import Sentence\n",
    "from flair.embeddings import (\n",
    "    Embeddings,\n",
    "    WordEmbeddings,\n",
    "    StackedEmbeddings,\n",
    "    FlairEmbeddings,\n",
    "    DocumentPoolEmbeddings,\n",
    "    DocumentRNNEmbeddings,\n",
    "    TransformerWordEmbeddings,\n",
    ")\n",
    "\n",
    "from adaptnlp.model_hub import FlairModelResult, HFModelResult, HFModelHub, FlairModelHub\n",
    "\n",
    "from adaptnlp.result import SentenceResult, DetailLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_flair_hub = FlairModelHub()\n",
    "_hf_hub = HFModelHub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "@typedispatch\n",
    "def _make_sentences(text:str, as_list=False) -> Union[List[Sentence], Sentence]:\n",
    "    return [Sentence(text)] if as_list else Sentence(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_sentences = 'a,b,c'.split(',')\n",
    "out = [_make_sentences(o) for o in test_sentences]\n",
    "tst_out = [Sentence('a'), Sentence('b'), Sentence('c')]\n",
    "for o,t in zip(out, tst_out):\n",
    "    test_eq(o[0].text, t[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "@typedispatch\n",
    "def _make_sentences(text:list, as_list=False) -> Union[List[Sentence], Sentence]:\n",
    "    if all(isinstance(t,str) for t in text):\n",
    "        return [Sentence(t) for t in text]\n",
    "    elif all(isinstance(t, Sentence) for t in text):\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_sentence = 'My name is Zach'\n",
    "out = _make_sentences(test_sentence, as_list=True)\n",
    "tst_out = [Sentence(test_sentence)]\n",
    "for o,t in zip(out, tst_out):\n",
    "    test_eq(o[0].text, t[0].text)\n",
    "test_eq(is_listy(out), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "@typedispatch\n",
    "def _make_sentences(text:Sentence, as_list=False) -> Union[List[Sentence], Sentence]:\n",
    "    return [text] if as_list else text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_sentence = Sentence('Me')\n",
    "out = _make_sentences(test_sentence)\n",
    "test_eq(test_sentence[0].text, out[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "@typedispatch\n",
    "def _get_embedding_model(model_name_or_path:HFModelResult) -> TransformerWordEmbeddings:\n",
    "    return TransformerWordEmbeddings(model_name_or_path.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "@typedispatch\n",
    "def _get_embedding_model(model_name_or_path:FlairModelResult) -> Union[FlairEmbeddings, WordEmbeddings]:\n",
    "    nm = model_name_or_path.name\n",
    "    try:\n",
    "        return WordEmbeddings(nm.strip('flairNLP/'))\n",
    "    except:\n",
    "        return FlairEmbeddings(nm.strip('flairNLP/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "@typedispatch\n",
    "def _get_embedding_model(model_name_or_path:str) -> Union[TransformerWordEmbeddings, WordEmbeddings, FlairEmbeddings]:\n",
    "    res = _flair_hub.search_model_by_name(model_name_or_path, user_uploaded=True)\n",
    "    if len(res) < 1:\n",
    "        # No models found\n",
    "        res = _hf_hub.search_model_by_name(model_name_or_path, user_uploaded=True)\n",
    "        if len(res) < 1:\n",
    "            raise ValueError(f'Embeddings not found for the model key: {model_name_or_path}, check documentation or custom model path to verify specified model')\n",
    "        else:\n",
    "            return TransformerWordEmbeddings(res[0].name) # Returning the first should always be the non-fast option\n",
    "    else:\n",
    "        nm = res[0].name\n",
    "        try:\n",
    "            return WordEmbeddings(nm.strip('flairNLP/'))\n",
    "        except:\n",
    "            return FlairEmbeddings(nm.strip('flairNLP/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EmbeddingResult(SentenceResult):\n",
    "    \"A result class designed for Embedding models\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        sentences:List[Sentence] # A list of Flair `Sentence`s\n",
    "    ): super().__init__(sentences)\n",
    "    \n",
    "    @property\n",
    "    def sentence_embeddings(self) -> List[torch.tensor]:\n",
    "        \"All embeddings in `sentences` (if available)\"\n",
    "        return [s.get_embedding() for s in self._sentences]\n",
    "    \n",
    "    @property\n",
    "    def token_embeddings(self) -> List[torch.tensor]:\n",
    "        \"All embeddings from the individual tokens in `sentence` with original order in shape (n, embed_dim)\"\n",
    "        return [torch.stack([tok.get_embedding() for tok in s], dim=0) for s in self._sentences]\n",
    "    \n",
    "    def to_dict(\n",
    "        self, \n",
    "        detail_level:DetailLevel=DetailLevel.Low # A level of detail to return\n",
    "    ):\n",
    "        \"Returns `self` as a dictionary\"\n",
    "        o = OrderedDict()\n",
    "        o.update({'inputs':self.inputs,\n",
    "                  'sentence_embeddings':self.sentence_embeddings,\n",
    "                 'token_embeddings':self.token_embeddings})\n",
    "        if detail_level == \"low\": return o\n",
    "        if detail_level == 'medium' or detail_level == 'high':\n",
    "            # Return embeddings/word pairs and indicies, and the tokenized input\n",
    "            for s in self._sentences:\n",
    "                o.update({\n",
    "                    tok.text:{\n",
    "                        'embeddings':tok.get_embedding(),\n",
    "                        'word_idx':tok.idx\n",
    "                    } for tok in s\n",
    "                })\n",
    "            o.update({\n",
    "                'tokenized_inputs':self.tokenized_inputs\n",
    "            })\n",
    "        if detail_level == 'high':\n",
    "            # Return embeddings/word pairs, indicies, and the original Sentences objects\n",
    "            for s in self._sentences:\n",
    "                o.update({tok.text:{\n",
    "                    'embeddings':tok.get_embedding(),\n",
    "                    'word_idx':tok.idx\n",
    "                    } for tok in s})\n",
    "            o.update({'sentences':self._sentences})\n",
    "        return o\n",
    "    \n",
    "    def __repr__(self):\n",
    "        s = f\"{self.__class__.__name__}:\" + \" {\"\n",
    "        s += f'\\n\\tInputs: {self.inputs}'\n",
    "        if self.token_embeddings is not None: s += f'\\n\\tToken Embeddings Shapes: {[f.shape for f in self.token_embeddings]}'\n",
    "        if self.sentence_embeddings is not None: s += f'\\n\\tSentence Embeddings Shapes: {[f.shape for f in self.sentence_embeddings]}'\n",
    "        return s + '\\n}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EmbeddingResult.sentence_embeddings\" class=\"doc_header\"><code>EmbeddingResult.sentence_embeddings</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "All embeddings in `sentences` (if available)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EmbeddingResult.sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EmbeddingResult.token_embeddings\" class=\"doc_header\"><code>EmbeddingResult.token_embeddings</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "All embeddings from the individual tokens in `sentence` with original order in shape (n, embed_dim)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EmbeddingResult.token_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EmbeddingResult.to_dict\" class=\"doc_header\"><code>EmbeddingResult.to_dict</code><a href=\"__main__.py#L19\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EmbeddingResult.to_dict</code>(**`detail_level`**:`DetailLevel`=*`'low'`*)\n",
       "\n",
       "Returns `self` as a dictionary\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`detail_level`** : *`<class 'fastcore.basics.DetailLevel'>`*, *optional*\t<p>A level of detail to return</p>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EmbeddingResult.to_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EasyWordEmbeddings:\n",
    "    \"\"\"Word embeddings from the latest language models\n",
    "\n",
    "    Usage:\n",
    "\n",
    "    ```python\n",
    "    >>> embeddings = adaptnlp.EasyWordEmbeddings()\n",
    "    >>> embeddings.embed_text(\"text you want embeddings for\", model_name_or_path=\"bert-base-cased\")\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.models: Dict[Embeddings] = defaultdict(bool)\n",
    "\n",
    "    def embed_text(\n",
    "        self,\n",
    "        text: Union[List[Sentence], Sentence, List[str], str], # Text input, it can be a string or any of Flair's `Sentence` input formats\n",
    "        model_name_or_path: Union[str, HFModelResult, FlairModelResult] = \"bert-base-cased\", # The hosted model name key, model path, or an instance of either `HFModelResult` or `FlairModelResult`\n",
    "        detail_level:DetailLevel = DetailLevel.Low, # A level of detail to return. By default is None, which returns a EmbeddingResult, otherwise will return a dict\n",
    "        raw:bool=False # Whether to return the raw outputs\n",
    "    ) -> List[EmbeddingResult]: # A list of either `EmbeddingResult`s or dictionaries with information\n",
    "        \"Produces embeddings for text\"\n",
    "        # Convert into sentences\n",
    "        sentences = _make_sentences(text)\n",
    "\n",
    "        # Load correct Embeddings module\n",
    "        if model_name_or_path not in self.models.keys():\n",
    "            self.models[model_name_or_path] = _get_embedding_model(model_name_or_path)\n",
    "        embedding = self.models[model_name_or_path]\n",
    "        embeds = embedding.embed(sentences)\n",
    "        \n",
    "        if not raw:\n",
    "            res = EmbeddingResult(listify(embeds))\n",
    "            return res.to_dict(detail_level) if detail_level is not None else res\n",
    "        else:\n",
    "            return listify(embeds)\n",
    "\n",
    "    def embed_all(\n",
    "        self,\n",
    "        text: Union[List[Sentence], Sentence, List[str], str], # Text input, it can be a string or any of Flair's `Sentence` input formats\n",
    "        model_names_or_paths:List[str] = [], # A list of model names\n",
    "        detail_level:DetailLevel=DetailLevel.Low, # A level of detail to return. By default is None, which returns a EmbeddingResult, otherwise will return a dict\n",
    "    ) -> List[EmbeddingResult]: # A list of either `EmbeddingResult`s or dictionaries with information\n",
    "        \"Embeds text with all embedding models loaded\"\n",
    "        # Convert into sentences\n",
    "        sentences = _make_sentences(text)\n",
    "\n",
    "        if model_names_or_paths:\n",
    "            for embedding_name in model_names_or_paths:\n",
    "                sentences = self.embed_text(\n",
    "                    sentences, model_name_or_path=embedding_name, raw=True\n",
    "                )\n",
    "        else:\n",
    "            for embedding_name in self.models.keys():\n",
    "                sentences = self.embed_text(\n",
    "                    sentences, model_name_or_path=embedding_name, raw=True\n",
    "                )\n",
    "        res = EmbeddingResult(listify(sentences))\n",
    "        return res.to_dict(detail_level) if detail_level is not None else res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased-finetuned-mrpc were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "import torch\n",
    "embeddings = EasyWordEmbeddings()\n",
    "res = embeddings.embed_text(\"text you want embeddings for\", model_name_or_path=\"bert-base-cased\")\n",
    "test_eq(res['token_embeddings'][0].shape, torch.Size([5, 768]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EasyWordEmbeddings.embed_text\" class=\"doc_header\"><code>EasyWordEmbeddings.embed_text</code><a href=\"__main__.py#L16\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EasyWordEmbeddings.embed_text</code>(**`text`**:`Union`\\[`List`\\[`Sentence`\\], `Sentence`, `List`\\[`str`\\], `str`\\], **`model_name_or_path`**:`Union`\\[`str`, [`HFModelResult`](/adaptnlp/model_hub.html#HFModelResult), [`FlairModelResult`](/adaptnlp/model_hub.html#FlairModelResult)\\]=*`'bert-base-cased'`*, **`detail_level`**:`DetailLevel`=*`'low'`*, **`raw`**:`bool`=*`False`*)\n",
       "\n",
       "Produces embeddings for text\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`text`** : *`typing.Union[typing.List[flair.data.Sentence], flair.data.Sentence, typing.List[str], str]`*\t<p>Text input, it can be a string or any of Flair's `Sentence` input formats</p>\n",
       "\n",
       "\n",
       " - **`model_name_or_path`** : *`typing.Union[str, adaptnlp.model_hub.HFModelResult, adaptnlp.model_hub.FlairModelResult]`*, *optional*\t<p>The hosted model name key, model path, or an instance of either `HFModelResult` or `FlairModelResult`</p>\n",
       "\n",
       "\n",
       " - **`detail_level`** : *`<class 'fastcore.basics.DetailLevel'>`*, *optional*\t<p>A level of detail to return. By default is None, which returns a EmbeddingResult, otherwise will return a dict</p>\n",
       "\n",
       "\n",
       " - **`raw`** : *`<class 'bool'>`*, *optional*\t<p>Whether to return the raw outputs</p>\n",
       "\n",
       "\n",
       "\n",
       "**Returns**:\n",
       "\t\n",
       " * *`typing.List[__main__.EmbeddingResult]`*\t<p>A list of either `EmbeddingResult`s or dictionaries with information</p>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EasyWordEmbeddings.embed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "res = embeddings.embed_all(['text you want embeddings for', 'My name is Zach'],\n",
    "                           ['bert-base-cased', 'xlnet-base-cased'])\n",
    "test_eq(res['token_embeddings'][0].shape, torch.Size([5,1536]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EasyWordEmbeddings.embed_all\" class=\"doc_header\"><code>EasyWordEmbeddings.embed_all</code><a href=\"__main__.py#L39\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EasyWordEmbeddings.embed_all</code>(**`text`**:`Union`\\[`List`\\[`Sentence`\\], `Sentence`, `List`\\[`str`\\], `str`\\], **`model_names_or_paths`**:`List`\\[`str`\\]=*`[]`*, **`detail_level`**:`DetailLevel`=*`'low'`*)\n",
       "\n",
       "Embeds text with all embedding models loaded\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`text`** : *`typing.Union[typing.List[flair.data.Sentence], flair.data.Sentence, typing.List[str], str]`*\t<p>Text input, it can be a string or any of Flair's `Sentence` input formats</p>\n",
       "\n",
       "\n",
       " - **`model_names_or_paths`** : *`typing.List[str]`*, *optional*\t<p>A list of model names</p>\n",
       "\n",
       "\n",
       " - **`detail_level`** : *`<class 'fastcore.basics.DetailLevel'>`*, *optional*\t<p>A level of detail to return. By default is None, which returns a EmbeddingResult, otherwise will return a dict</p>\n",
       "\n",
       "\n",
       "\n",
       "**Returns**:\n",
       "\t\n",
       " * *`typing.List[__main__.EmbeddingResult]`*\t<p>A list of either `EmbeddingResult`s or dictionaries with information</p>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EasyWordEmbeddings.embed_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EasyStackedEmbeddings:\n",
    "    \"Word Embeddings that have been concatenated and 'stacked' as specified by Flair\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        *embeddings: str \n",
    "    ):\n",
    "        print(\"May need a couple moments to instantiate...\")\n",
    "        self.embedding_stack = []\n",
    "\n",
    "        # Load correct Embeddings module\n",
    "        for model_name_or_path in embeddings:\n",
    "            self.embedding_stack.append(_get_embedding_model(model_name_or_path))\n",
    "\n",
    "        assert len(self.embedding_stack) != 0\n",
    "        self.stacked_embeddings = StackedEmbeddings(embeddings=self.embedding_stack)\n",
    "\n",
    "    def embed_text(\n",
    "        self,\n",
    "        text: Union[List[Sentence], Sentence, List[str], str], # Text input, it can be a string or any of Flair's `Sentence` input formats\n",
    "        detail_level:DetailLevel = DetailLevel.Low # A level of detail to return. By default is None, which returns a EmbeddingResult, otherwise will return a dict\n",
    "    ) -> List[EmbeddingResult]: # A list of either EmbeddingResult's or dictionaries with information\n",
    "        \"Stacked embeddings\"\n",
    "        # Convert into sentences\n",
    "        sentences = _make_sentences(text, as_list=True)\n",
    "\n",
    "        # Unlike flair embeddings modules, stacked embeddings do not return a list of sentences\n",
    "        self.stacked_embeddings.embed(sentences)\n",
    "        \n",
    "        res = EmbeddingResult(listify(sentences))\n",
    "        return res.to_dict(detail_level) if detail_level is not None else res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "May need a couple moments to instantiate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased-finetuned-mrpc were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "embeddings = EasyStackedEmbeddings(\"bert-base-cased\", \"xlnet-base-cased\")\n",
    "sentences = embeddings.embed_text(\"This is Albert.  My last name is Einstein.  I like physics and atoms.\")\n",
    "test_eq(sentences['token_embeddings'][0].shape, torch.Size([16,1536]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EasyStackedEmbeddings.embed_text\" class=\"doc_header\"><code>EasyStackedEmbeddings.embed_text</code><a href=\"__main__.py#L19\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EasyStackedEmbeddings.embed_text</code>(**`text`**:`Union`\\[`List`\\[`Sentence`\\], `Sentence`, `List`\\[`str`\\], `str`\\], **`detail_level`**:`DetailLevel`=*`'low'`*)\n",
       "\n",
       "Stacked embeddings\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`text`** : *`typing.Union[typing.List[flair.data.Sentence], flair.data.Sentence, typing.List[str], str]`*\t<p>Text input, it can be a string or any of Flair's `Sentence` input formats</p>\n",
       "\n",
       "\n",
       " - **`detail_level`** : *`<class 'fastcore.basics.DetailLevel'>`*, *optional*\t<p>A level of detail to return. By default is None, which returns a EmbeddingResult, otherwise will return a dict</p>\n",
       "\n",
       "\n",
       "\n",
       "**Returns**:\n",
       "\t\n",
       " * *`typing.List[__main__.EmbeddingResult]`*\t<p>A list of either EmbeddingResult's or dictionaries with information</p>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EasyStackedEmbeddings.embed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EasyDocumentEmbeddings:\n",
    "    \"Document Embeddings generated by pool and rnn methods applied to the word embeddings of text\"\n",
    "\n",
    "    __allowed_methods = [\"rnn\", \"pool\"]\n",
    "    __allowed_configs = (\"pool_configs\", \"rnn_configs\")\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *embeddings: str, # Variable number of strings referring to model names or paths\n",
    "        methods: List[str] = [\"rnn\", \"pool\"], # A list of strings to specify which document embeddings to use i.e. [\"rnn\", \"pool\"] (avoids unncessary loading of models if only using one)\n",
    "        configs: Dict = {\n",
    "            \"pool_configs\": {\"fine_tune_mode\": \"linear\", \"pooling\": \"mean\"},\n",
    "            \"rnn_configs\": {\n",
    "                \"hidden_size\": 512,\n",
    "                \"rnn_layers\": 1,\n",
    "                \"reproject_words\": True,\n",
    "                \"reproject_words_dimension\": 256,\n",
    "                \"bidirectional\": False,\n",
    "                \"dropout\": 0.5,\n",
    "                \"word_dropout\": 0.0,\n",
    "                \"locked_dropout\": 0.0,\n",
    "                \"rnn_type\": \"GRU\",\n",
    "                \"fine_tune\": True,\n",
    "            }, \n",
    "        }, # A dictionary of configurations for flair's rnn and pool document embeddings\n",
    "    ):\n",
    "        print(\"May need a couple moments to instantiate...\")\n",
    "        self.embedding_stack = []\n",
    "\n",
    "        # Check methods\n",
    "        for m in methods:\n",
    "            assert m in self.__class__.__allowed_methods\n",
    "\n",
    "        # Set configs for pooling and rnn parameters\n",
    "        for k, v in configs.items():\n",
    "            assert k in self.__class__.__allowed_configs\n",
    "            setattr(self, k, v)\n",
    "\n",
    "        # Load correct Embeddings module\n",
    "        for model_name_or_path in embeddings:\n",
    "            self.embedding_stack.append(_get_embedding_model(model_name_or_path))\n",
    "\n",
    "        assert len(self.embedding_stack) != 0\n",
    "        if \"pool\" in methods:\n",
    "            self.pool_embeddings = DocumentPoolEmbeddings(\n",
    "                self.embedding_stack, **self.pool_configs\n",
    "            )\n",
    "            print(\"Pooled embedding loaded\")\n",
    "        if \"rnn\" in methods:\n",
    "            self.rnn_embeddings = DocumentRNNEmbeddings(\n",
    "                self.embedding_stack, **self.rnn_configs\n",
    "            )\n",
    "            print(\"RNN embeddings loaded\")\n",
    "\n",
    "    def embed_pool(\n",
    "        self,\n",
    "        text: Union[List[Sentence], Sentence, List[str], str], # Text input, it can be a string or any of Flair's `Sentence` input formats\n",
    "        detail_level:DetailLevel = DetailLevel.Low, # A level of detail to return. By default is None, which returns a EmbeddingResult, otherwise will return a dict\n",
    "    ) -> List[EmbeddingResult]: # A list of either EmbeddingResult's or dictionaries with information\n",
    "        \"Generate stacked embeddings with `DocumentPoolEmbeddings`\"\n",
    "        sentences = _make_sentences(text, as_list=True)\n",
    "        self.pool_embeddings.embed(sentences)\n",
    "        res = EmbeddingResult(listify(sentences))\n",
    "        return res.to_dict(detail_level) if detail_level is not None else res\n",
    "\n",
    "    def embed_rnn(\n",
    "        self,\n",
    "        text: Union[List[Sentence], Sentence, List[str], str], # Text input, it can be a string or any of Flair's `Sentence` input formats\n",
    "        detail_level:DetailLevel = DetailLevel.Low, # A level of detail to return. By default is None, which returns a EmbeddingResult, otherwise will return a dict\n",
    "    ) -> List[Sentence]: # A list of either EmbeddingResult's or dictionaries with information\n",
    "        \"Generate stacked embeddings with `DocumentRNNEmbeddings`\"\n",
    "        sentences = _make_sentences(text, as_list=True)\n",
    "        self.rnn_embeddings.embed(sentences)\n",
    "        res = EmbeddingResult(listify(sentences))\n",
    "        return res.to_dict(detail_level) if detail_level is not None else res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "May need a couple moments to instantiate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased-finetuned-mrpc were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled embedding loaded\n",
      "RNN embeddings loaded\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "embeddings = EasyDocumentEmbeddings(\"bert-base-cased\", \"xlnet-base-cased\")\n",
    "res = embeddings.embed_pool(\"This is Albert.  My last name is Einstein.  I like physics and atoms.\")\n",
    "test_eq(res['sentence_embeddings'][0].shape, torch.Size([1536]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "res = embeddings.embed_rnn(\"This is Albert.  My last name is Einstein.  I like physics and atoms.\")\n",
    "test_eq(res['sentence_embeddings'][0].shape, torch.Size([512]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EasyDocumentEmbeddings.embed_pool\" class=\"doc_header\"><code>EasyDocumentEmbeddings.embed_pool</code><a href=\"__main__.py#L56\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EasyDocumentEmbeddings.embed_pool</code>(**`text`**:`Union`\\[`List`\\[`Sentence`\\], `Sentence`, `List`\\[`str`\\], `str`\\], **`detail_level`**:`DetailLevel`=*`'low'`*)\n",
       "\n",
       "Generate stacked embeddings with `DocumentPoolEmbeddings`\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`text`** : *`typing.Union[typing.List[flair.data.Sentence], flair.data.Sentence, typing.List[str], str]`*\t<p>Text input, it can be a string or any of Flair's `Sentence` input formats</p>\n",
       "\n",
       "\n",
       " - **`detail_level`** : *`<class 'fastcore.basics.DetailLevel'>`*, *optional*\t<p>A level of detail to return. By default is None, which returns a EmbeddingResult, otherwise will return a dict</p>\n",
       "\n",
       "\n",
       "\n",
       "**Returns**:\n",
       "\t\n",
       " * *`typing.List[__main__.EmbeddingResult]`*\t<p>A list of either EmbeddingResult's or dictionaries with information</p>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EasyDocumentEmbeddings.embed_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EasyDocumentEmbeddings.embed_rnn\" class=\"doc_header\"><code>EasyDocumentEmbeddings.embed_rnn</code><a href=\"__main__.py#L67\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EasyDocumentEmbeddings.embed_rnn</code>(**`text`**:`Union`\\[`List`\\[`Sentence`\\], `Sentence`, `List`\\[`str`\\], `str`\\], **`detail_level`**:`DetailLevel`=*`'low'`*)\n",
       "\n",
       "Generate stacked embeddings with `DocumentRNNEmbeddings`\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`text`** : *`typing.Union[typing.List[flair.data.Sentence], flair.data.Sentence, typing.List[str], str]`*\t<p>Text input, it can be a string or any of Flair's `Sentence` input formats</p>\n",
       "\n",
       "\n",
       " - **`detail_level`** : *`<class 'fastcore.basics.DetailLevel'>`*, *optional*\t<p>A level of detail to return. By default is None, which returns a EmbeddingResult, otherwise will return a dict</p>\n",
       "\n",
       "\n",
       "\n",
       "**Returns**:\n",
       "\t\n",
       " * *`typing.List[flair.data.Sentence]`*\t<p>A list of either EmbeddingResult's or dictionaries with information</p>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EasyDocumentEmbeddings.embed_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
