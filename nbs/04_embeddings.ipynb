{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings\n",
    "> AdaptNLP Embeddings Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import test_eq\n",
    "from fastcore.xtras import is_listy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "import logging\n",
    "from typing import List, Dict, Union\n",
    "from collections import defaultdict\n",
    "\n",
    "from fastcore.dispatch import typedispatch\n",
    "from flair.data import Sentence\n",
    "from flair.embeddings import (\n",
    "    Embeddings,\n",
    "    WordEmbeddings,\n",
    "    StackedEmbeddings,\n",
    "    FlairEmbeddings,\n",
    "    DocumentPoolEmbeddings,\n",
    "    DocumentRNNEmbeddings,\n",
    "    TransformerWordEmbeddings,\n",
    ")\n",
    "\n",
    "from adaptnlp.model_hub import FlairModelHub, HFModelHub, FlairModelResult, HFModelResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_flair_hub = FlairModelHub()\n",
    "_hf_hub = HFModelHub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "@typedispatch\n",
    "def _make_sentences(text:str, as_list=False) -> Union[List[Sentence], Sentence]:\n",
    "    return [Sentence(text)] if as_list else Sentence(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_sentences = 'a,b,c'.split(',')\n",
    "out = _make_sentences(test_sentences)\n",
    "tst_out = [Sentence('a'), Sentence('b'), Sentence('c')]\n",
    "for o,t in zip(out, tst_out):\n",
    "    test_eq(o[0].text, t[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "@typedispatch\n",
    "def _make_sentences(text:list, as_list=False) -> Union[List[Sentence], Sentence]:\n",
    "    if all(isinstance(t,str) for t in text):\n",
    "        return [Sentence(t) for t in text]\n",
    "    elif all(isinstance(t, Sentence) for t in text):\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_sentence = 'My name is Zach'\n",
    "out = _make_sentences(test_sentence, as_list=True)\n",
    "tst_out = [Sentence(test_sentence)]\n",
    "for o,t in zip(out, tst_out):\n",
    "    test_eq(o[0].text, t[0].text)\n",
    "test_eq(is_listy(out), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "@typedispatch\n",
    "def _make_sentences(text:Sentence, as_list=False) -> Union[List[Sentence], Sentence]:\n",
    "    return [text] if as_list else text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_sentence = Sentence('Me')\n",
    "out = _make_sentences(test_sentence)\n",
    "test_eq(test_sentence[0].text, out[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def _get_embedding_model(model_name_or_path:Union[str, HFModelResult, FlairModelResult]) -> Union[FlairEmbeddings, WordEmbeddings, TransformerWordEmbeddings, Sentence]:\n",
    "    \"Load the proper `Embeddings` model from `model_name_or_path`\"\n",
    "    if isinstance(model_name_or_path, FlairModelResult): \n",
    "        nm = model_name_or_path.name\n",
    "        try:\n",
    "            return WordEmbeddings(nm.strip('flairNLP/'))\n",
    "        except:\n",
    "            return FlairEmbeddings(nm.strip('flairNLP/'))\n",
    "    \n",
    "    elif isinstance(model_name_or_path, HFModelResult): return TransformerWordEmbeddings(model_name_or_path.name)\n",
    "    else:\n",
    "        res = _flair_hub.search_model_by_name(model_name_or_path, user_uploaded=True)\n",
    "        if len(res) < 1:\n",
    "            # No models found\n",
    "            res = _hf_hub.search_model_by_name(model_name_or_path, user_uploaded=True)\n",
    "            if len(res) < 1:\n",
    "                raise ValueError(f'Embeddings not found for the model key: {model_name_or_path}, check documentation or custom model path to verify specified model')\n",
    "            else:\n",
    "                return TransformerWordEmbeddings(res[0].name) # Returning the first should always be the non-fast option\n",
    "        else:\n",
    "            nm = res[0].name\n",
    "            try:\n",
    "                return WordEmbeddings(nm.strip('flairNLP/'))\n",
    "            except:\n",
    "                return FlairEmbeddings(nm.strip('flairNLP/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EasyWordEmbeddings:\n",
    "    \"Word embeddings from the latest language models\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.models: Dict[Embeddings] = defaultdict(bool)\n",
    "\n",
    "    def embed_text(\n",
    "        self,\n",
    "        text: Union[List[Sentence], Sentence, List[str], str], # Text input, it can be a string or any of Flair's `Sentence` input formats\n",
    "        model_name_or_path: Union[str, HFModelResult, FlairModelResult] = \"bert-base-cased\", # The hosted model name key, model path, or an instance of either `HFModelResult` or `FlairModelResult`\n",
    "    ) -> List[Sentence]:\n",
    "        \"\"\"Produces embeddings for text\n",
    "        \n",
    "        **Return**:\n",
    "        * A list of Flair's `Sentence`s\n",
    "        \"\"\"\n",
    "        # Convert into sentences\n",
    "        sentences = _make_sentences(text)\n",
    "\n",
    "        # Load correct Embeddings module\n",
    "        self.models[model_name_or_path] = _get_embedding_model(model_name_or_path)\n",
    "        embedding = self.models[model_name_or_path]\n",
    "        return embedding.embed(sentences)\n",
    "\n",
    "    def embed_all(\n",
    "        self,\n",
    "        text: Union[List[Sentence], Sentence, List[str], str], # Text input, it can be a string or any of Flair's `Sentence` input formats\n",
    "        *model_names_or_paths: str, # A variable input of model names or paths to embed\n",
    "    ) -> List[Sentence]:\n",
    "        \"\"\"Embeds text with all embedding models loaded\n",
    "\n",
    "        **Return**:\n",
    "        * A list of Flair's `Sentence`s\n",
    "        \"\"\"\n",
    "        # Convert into sentences\n",
    "        sentences = _make_sentences(text)\n",
    "\n",
    "        if model_names_or_paths:\n",
    "            for embedding_name in model_names_or_paths:\n",
    "                sentences = self.embed_text(\n",
    "                    sentences, model_name_or_path=embedding_name\n",
    "                )\n",
    "        else:\n",
    "            for embedding_name in self.models.keys():\n",
    "                sentences = self.embed_text(\n",
    "                    sentences, model_name_or_path=embedding_name\n",
    "                )\n",
    "        return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased-finetuned-mrpc were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "import torch\n",
    "embeddings = EasyWordEmbeddings()\n",
    "res = embeddings.embed_text(\"text you want embeddings for\", model_name_or_path=\"bert-base-cased\")\n",
    "test_eq(res[0][1].get_embedding().shape, torch.Size([768]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EasyWordEmbeddings.embed_text\" class=\"doc_header\"><code>EasyWordEmbeddings.embed_text</code><a href=\"__main__.py#L8\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EasyWordEmbeddings.embed_text</code>(**`text`**:`Union`\\[`List`\\[`Sentence`\\], `Sentence`, `List`\\[`str`\\], `str`\\], **`model_name_or_path`**:`Union`\\[`str`, [`HFModelResult`](/adaptnlp/model_hub.html#HFModelResult), [`FlairModelResult`](/adaptnlp/model_hub.html#FlairModelResult)\\]=*`'bert-base-cased'`*)\n",
       "\n",
       "Produces embeddings for text\n",
       "\n",
       "**Return**:\n",
       "* A list of Flair's `Sentence`s"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EasyWordEmbeddings.embed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EasyWordEmbeddings.embed_all\" class=\"doc_header\"><code>EasyWordEmbeddings.embed_all</code><a href=\"__main__.py#L26\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EasyWordEmbeddings.embed_all</code>(**`text`**:`Union`\\[`List`\\[`Sentence`\\], `Sentence`, `List`\\[`str`\\], `str`\\], **\\*`model_names_or_paths`**:`str`)\n",
       "\n",
       "Embeds text with all embedding models loaded\n",
       "\n",
       "**Return**:\n",
       "* A list of Flair's `Sentence`s"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EasyWordEmbeddings.embed_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EasyStackedEmbeddings:\n",
    "    \"\"\"Word Embeddings that have been concatenated and \"stacked\" as specified by flair\n",
    "\n",
    "    Usage:\n",
    "\n",
    "    ```python\n",
    "    >>> embeddings = adaptnlp.EasyStackedEmbeddings(\"bert-base-cased\", \"gpt2\", \"xlnet-base-cased\")\n",
    "    ```\n",
    "\n",
    "    **Parameters:**\n",
    "\n",
    "    * `&ast;embeddings` - Non-keyword variable number of strings specifying the embeddings you want to stack\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *embeddings: str):\n",
    "        print(\"May need a couple moments to instantiate...\")\n",
    "        self.embedding_stack = []\n",
    "\n",
    "        # Load correct Embeddings module\n",
    "        for model_name_or_path in embeddings:\n",
    "            self.embedding_stack.append(_get_embedding_model(model_name_or_path))\n",
    "\n",
    "        assert len(self.embedding_stack) != 0\n",
    "        self.stacked_embeddings = StackedEmbeddings(embeddings=self.embedding_stack)\n",
    "\n",
    "    def embed_text(\n",
    "        self,\n",
    "        text: Union[List[Sentence], Sentence, List[str], str],\n",
    "    ) -> List[Sentence]:\n",
    "        \"\"\"Stacked embeddings\n",
    "\n",
    "        **Parameters**:\n",
    "        * `text` - Text input, it can be a string or any of Flair's `Sentence` input formats\n",
    "\n",
    "        **Return**:\n",
    "        * A list of Flair's `Sentence`s\n",
    "        \"\"\"\n",
    "        # Convert into sentences\n",
    "        sentences = _make_sentences(text, as_list=True)\n",
    "\n",
    "        # Unlike flair embeddings modules, stacked embeddings do not return a list of sentences\n",
    "        self.stacked_embeddings.embed(sentences)\n",
    "        return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "May need a couple moments to instantiate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased-finetuned-mrpc were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "embeddings = EasyStackedEmbeddings(\"bert-base-cased\", \"xlnet-base-cased\")\n",
    "sentences = embeddings.embed_text(\"This is Albert.  My last name is Einstein.  I like physics and atoms.\")\n",
    "test_eq(sentences[0][0].get_embedding().shape, torch.Size([1536]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EasyStackedEmbeddings.embed_text\" class=\"doc_header\"><code>EasyStackedEmbeddings.embed_text</code><a href=\"__main__.py#L27\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EasyStackedEmbeddings.embed_text</code>(**`text`**:`Union`\\[`List`\\[`Sentence`\\], `Sentence`, `List`\\[`str`\\], `str`\\])\n",
       "\n",
       "Stacked embeddings\n",
       "\n",
       "**Parameters**:\n",
       "* `text` - Text input, it can be a string or any of Flair's `Sentence` input formats\n",
       "\n",
       "**Return**:\n",
       "* A list of Flair's `Sentence`s"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EasyStackedEmbeddings.embed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EasyDocumentEmbeddings:\n",
    "    \"Document Embeddings generated by pool and rnn methods applied to the word embeddings of text\"\n",
    "\n",
    "    __allowed_methods = [\"rnn\", \"pool\"]\n",
    "    __allowed_configs = (\"pool_configs\", \"rnn_configs\")\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *embeddings: str, # Non-keyword variable number of strings referring to model names or paths\n",
    "        methods: List[str] = [\"rnn\", \"pool\"], # A list of strings to specify which document embeddings to use i.e. [\"rnn\", \"pool\"] (avoids unncessary loading of models if only using one)\n",
    "        configs: Dict = {\n",
    "            \"pool_configs\": {\"fine_tune_mode\": \"linear\", \"pooling\": \"mean\"},\n",
    "            \"rnn_configs\": {\n",
    "                \"hidden_size\": 512,\n",
    "                \"rnn_layers\": 1,\n",
    "                \"reproject_words\": True,\n",
    "                \"reproject_words_dimension\": 256,\n",
    "                \"bidirectional\": False,\n",
    "                \"dropout\": 0.5,\n",
    "                \"word_dropout\": 0.0,\n",
    "                \"locked_dropout\": 0.0,\n",
    "                \"rnn_type\": \"GRU\",\n",
    "                \"fine_tune\": True,\n",
    "            },\n",
    "        },\n",
    "    ):\n",
    "        print(\"May need a couple moments to instantiate...\")\n",
    "        self.embedding_stack = []\n",
    "\n",
    "        # Check methods\n",
    "        for m in methods:\n",
    "            assert m in self.__class__.__allowed_methods\n",
    "\n",
    "        # Set configs for pooling and rnn parameters\n",
    "        for k, v in configs.items():\n",
    "            assert k in self.__class__.__allowed_configs\n",
    "            setattr(self, k, v)\n",
    "\n",
    "        # Load correct Embeddings module\n",
    "        for model_name_or_path in embeddings:\n",
    "            self.embedding_stack.append(_get_embedding_model(model_name_or_path))\n",
    "\n",
    "        assert len(self.embedding_stack) != 0\n",
    "        if \"pool\" in methods:\n",
    "            self.pool_embeddings = DocumentPoolEmbeddings(\n",
    "                self.embedding_stack, **self.pool_configs\n",
    "            )\n",
    "            print(\"Pooled embedding loaded\")\n",
    "        if \"rnn\" in methods:\n",
    "            self.rnn_embeddings = DocumentRNNEmbeddings(\n",
    "                self.embedding_stack, **self.rnn_configs\n",
    "            )\n",
    "            print(\"RNN embeddings loaded\")\n",
    "\n",
    "    def embed_pool(\n",
    "        self,\n",
    "        text: Union[List[Sentence], Sentence, List[str], str], # Text input, it can be a string or any of Flair's `Sentence` input formats\n",
    "    ) -> List[Sentence]:\n",
    "        \"\"\"Generate stacked embeddings with `DocumentPoolEmbeddings`\n",
    "\n",
    "        **Return**:\n",
    "        * A list of Flair's `Sentence`s\n",
    "        \"\"\"\n",
    "        sentences = _make_sentences(text, as_list=True)\n",
    "        self.pool_embeddings.embed(sentences)\n",
    "        return sentences\n",
    "\n",
    "    def embed_rnn(\n",
    "        self,\n",
    "        text: Union[List[Sentence], Sentence, List[str], str], # Text input, it can be a string or any of Flair's `Sentence` input formats\n",
    "    ) -> List[Sentence]: \n",
    "        \"\"\"Generate stacked embeddings with `DocumentRNNEmbeddings`\n",
    "\n",
    "        **Return**:\n",
    "        * A list of Flair's `Sentence`s\n",
    "        \"\"\"\n",
    "        sentences = _make_sentences(text, as_list=True)\n",
    "        self.rnn_embeddings.embed(sentences)\n",
    "        return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "May need a couple moments to instantiate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased-finetuned-mrpc were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled embedding loaded\n",
      "RNN embeddings loaded\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "embeddings = EasyDocumentEmbeddings(\"bert-base-cased\", \"xlnet-base-cased\")\n",
    "text = embeddings.embed_pool(\"This is Albert.  My last name is Einstein.  I like physics and atoms.\")\n",
    "test_eq(text[0].get_embedding().shape, torch.Size([1536]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "text = embeddings.embed_rnn(\"This is Albert.  My last name is Einstein.  I like physics and atoms.\")\n",
    "test_eq(text[0].get_embedding().shape, torch.Size([512]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EasyDocumentEmbeddings.embed_pool\" class=\"doc_header\"><code>EasyDocumentEmbeddings.embed_pool</code><a href=\"__main__.py#L56\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EasyDocumentEmbeddings.embed_pool</code>(**`text`**:`Union`\\[`List`\\[`Sentence`\\], `Sentence`, `List`\\[`str`\\], `str`\\])\n",
       "\n",
       "Generate stacked embeddings with `DocumentPoolEmbeddings`\n",
       "\n",
       "**Return**:\n",
       "* A list of Flair's `Sentence`s"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EasyDocumentEmbeddings.embed_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EasyDocumentEmbeddings.embed_rnn\" class=\"doc_header\"><code>EasyDocumentEmbeddings.embed_rnn</code><a href=\"__main__.py#L69\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EasyDocumentEmbeddings.embed_rnn</code>(**`text`**:`Union`\\[`List`\\[`Sentence`\\], `Sentence`, `List`\\[`str`\\], `str`\\])\n",
       "\n",
       "Generate stacked embeddings with `DocumentRNNEmbeddings`\n",
       "\n",
       "**Return**:\n",
       "* A list of Flair's `Sentence`s"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EasyDocumentEmbeddings.embed_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
