{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp inference.sequence_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Classification\n",
    "> Sequence Classification API for Transformers and Flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbverbose.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import logging\n",
    "from typing import List, Dict, Union, Tuple, Callable\n",
    "from collections import defaultdict, OrderedDict\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import datasets\n",
    "from datasets import ClassLabel\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from flair.data import Sentence, DataPoint\n",
    "from flair.models import TextClassifier\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    PreTrainedTokenizer,\n",
    "    PreTrainedModel,\n",
    "    BertPreTrainedModel,\n",
    "    DistilBertPreTrainedModel,\n",
    "    XLMPreTrainedModel,\n",
    "    XLNetPreTrainedModel,\n",
    "    ElectraPreTrainedModel,\n",
    "    BertForSequenceClassification,\n",
    "    XLNetForSequenceClassification,\n",
    "    AlbertForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "\n",
    "from adaptnlp.model import AdaptiveModel\n",
    "from adaptnlp.model_hub import HFModelResult, FlairModelResult\n",
    "\n",
    "from fastcore.basics import risinstance\n",
    "from fastcore.xtras import Path\n",
    "from adaptnlp.result import DetailLevel, SentenceResult\n",
    "\n",
    "from torch import tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SequenceResult(SentenceResult):\n",
    "    \"A result class designed for Sequence Classification models\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        sentences:List[Sentence], # A list of flair `Sentence`'s\n",
    "        class_names:list = None # A potential list of class names\n",
    "    ):\n",
    "        super().__init__(sentences)\n",
    "        self.classes = sentences[0].get_label_names()\n",
    "        self.class_names = class_names\n",
    "\n",
    "    @property\n",
    "    def probabilities(self) -> List[List[tensor]]:\n",
    "        \"\"\"\n",
    "        The probabilities returned for each classification\n",
    "        \"\"\"\n",
    "        return torch.stack([tensor(list(map(lambda x: x.score, i.get_labels()))) for i in self._sentences], dim=0)\n",
    "\n",
    "    @property\n",
    "    def predictions(self) -> List[str]:\n",
    "        \"\"\"\n",
    "        A list of the best classification for each input\n",
    "        \"\"\"\n",
    "        if self.class_names is not None:\n",
    "            return [self.class_names[p.argmax()] for p in self.probabilities]\n",
    "        return [max(s.labels, key=lambda x: x.score).value for s in self._sentences]\n",
    "\n",
    "    def to_dict(\n",
    "        self, \n",
    "        detail_level:DetailLevel=DetailLevel.Low # A level of detail to return\n",
    "    ) -> dict:\n",
    "        \"Return `self` as a dictionary\"\n",
    "        o = {\n",
    "            'sentences':self.inputs,\n",
    "            'predictions':self.predictions,\n",
    "            'probs':self.probabilities\n",
    "        }\n",
    "        if detail_level == 'medium' or detail_level == 'high':\n",
    "            # Add a dictionary of sentence and probabilities, and return the vocab\n",
    "            o['pairings'] = OrderedDict({\n",
    "                s:probs for (s,probs) in zip(self.inputs, self.probabilities)\n",
    "            })\n",
    "            o['classes'] = self.classes\n",
    "\n",
    "        if detail_level == 'high':\n",
    "            # Add original `Sentences`\n",
    "            o['sentences'] = self._sentences\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"SequenceResult.probabilities\" class=\"doc_header\"><code>SequenceResult.probabilities</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "The probabilities returned for each classification"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(SequenceResult.probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"SequenceResult.predictions\" class=\"doc_header\"><code>SequenceResult.predictions</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "A list of the best classification for each input"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(SequenceResult.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"SequenceResult.to_dict\" class=\"doc_header\"><code>SequenceResult.to_dict</code><a href=\"__main__.py#L29\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>SequenceResult.to_dict</code>(**`detail_level`**:`DetailLevel`=*`'low'`*)\n",
       "\n",
       "Return `self` as a dictionary\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`detail_level`** : *`<class 'fastcore.basics.DetailLevel'>`*, *optional*\t<p>A level of detail to return</p>\n",
       "\n",
       "\n",
       "\n",
       "**Returns**:\n",
       "\t\n",
       " * *`<class 'dict'>`*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(SequenceResult.to_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TransformersSequenceClassifier(AdaptiveModel):\n",
    "    \"Adaptive model for Transformer's Sequence Classification Model\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        tokenizer: PreTrainedTokenizer, # A tokenizer object from Huggingface's transformers (TODO)and tokenizers\n",
    "        model: PreTrainedModel # A transformers Sequence Classification model\n",
    "    ):\n",
    "        # Load up model and tokenizer\n",
    "        self.tokenizer = tokenizer\n",
    "        super().__init__()\n",
    "        self.set_model(model)\n",
    "\n",
    "        # Load empty trainer\n",
    "        self.trainer = None\n",
    "\n",
    "        # Setup cuda and automatic allocation of model\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    @classmethod\n",
    "    def load(\n",
    "        cls, \n",
    "        model_name_or_path: Union[HFModelResult, str] # A key string of one of Transformer's pre-trained Sequence Classifier Model or a `HFModelResult`\n",
    "    ) -> AdaptiveModel:\n",
    "        \"Class method for loading and constructing this classifier\"\n",
    "        if isinstance(model_name_or_path, HFModelResult): model_name_or_path = model_name_or_path.name\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path)\n",
    "        classifier = cls(tokenizer, model)\n",
    "        return classifier\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        text: Union[List[Sentence], Sentence, List[str], str], # Sentences to run inference on\n",
    "        mini_batch_size: int = 32, # Mini batch size\n",
    "        **kwargs, # Optional arguments for the Transformers classifier\n",
    "    ) -> List[Sentence]: # Returns a list of `Sentence` predictions\n",
    "        \"Predict method for running inference using the pre-trained sequence classifier model\"\n",
    "        id2label = self.model.config.id2label\n",
    "        sentences = text\n",
    "        results: List[Sentence] = []\n",
    "\n",
    "        if not sentences: return sentences\n",
    "\n",
    "        if risinstance([DataPoint, str], sentences):\n",
    "            sentences = [sentences]\n",
    "\n",
    "        # filter empty sentences\n",
    "        if isinstance(sentences[0], Sentence):\n",
    "            sentences = [sentence for sentence in sentences if len(sentence) > 0]\n",
    "        if len(sentences) == 0:\n",
    "            return sentences\n",
    "\n",
    "        # reverse sort all sequences by their length\n",
    "        rev_order_len_index = sorted(\n",
    "            range(len(sentences)), key=lambda k: len(sentences[k]), reverse=True\n",
    "        )\n",
    "        original_order_index = sorted(\n",
    "            range(len(rev_order_len_index)), key=lambda k: rev_order_len_index[k]\n",
    "        )\n",
    "\n",
    "        reordered_sentences: List[Union[DataPoint, str]] = [\n",
    "            sentences[index] for index in rev_order_len_index\n",
    "        ]\n",
    "\n",
    "        # Turn all Sentence objects into strings\n",
    "        if isinstance(reordered_sentences[0], Sentence):\n",
    "            str_reordered_sentences = [\n",
    "                sentence.to_original_text() for sentence in sentences\n",
    "            ]\n",
    "        else:\n",
    "            str_reordered_sentences = reordered_sentences\n",
    "\n",
    "        dataset = self._tokenize(str_reordered_sentences)\n",
    "        dl = DataLoader(dataset, batch_size=mini_batch_size)\n",
    "        predictions: List[Tuple[str, float]] = []\n",
    "\n",
    "        outputs, _ = super().get_preds(dl=dl)\n",
    "        logits = torch.cat([o['logits'] for o in outputs])\n",
    "        predictions = torch.softmax(logits, dim=1).tolist()\n",
    "\n",
    "        for text, pred in zip(str_reordered_sentences, predictions):\n",
    "            # Initialize and assign labels to each class in each datapoint prediction\n",
    "            text_sent = Sentence(text)\n",
    "            for k, v in id2label.items():\n",
    "                text_sent.add_label(typename='sc', value=v, score=pred[k])\n",
    "            results.append(text_sent)\n",
    "\n",
    "        # Order results back into original order\n",
    "        results = [results[index] for index in original_order_index]\n",
    "\n",
    "        return results\n",
    "\n",
    "    def _tokenize(\n",
    "        self, sentences: Union[List[Sentence], Sentence, List[str], str]\n",
    "    ) -> TensorDataset:\n",
    "        \"\"\" Batch tokenizes text and produces a `TensorDataset` with them \"\"\"\n",
    "\n",
    "        # TODO: __call__ from tokenizer base class in the transformers library could automate/handle this\n",
    "        tokenized_text = self.tokenizer.batch_encode_plus(\n",
    "            sentences,\n",
    "            return_tensors='pt',\n",
    "            max_length=None,\n",
    "            add_special_tokens=True,\n",
    "        )\n",
    "\n",
    "        # Bart, XLM, DistilBERT, RoBERTa, and XLM-RoBERTa don't use token_type_ids\n",
    "        if isinstance(\n",
    "            self.model,\n",
    "            (\n",
    "                BertForSequenceClassification,\n",
    "                XLNetForSequenceClassification,\n",
    "                AlbertForSequenceClassification,\n",
    "            ),\n",
    "        ):\n",
    "            dataset = TensorDataset(\n",
    "                tokenized_text['input_ids'],\n",
    "                tokenized_text['attention_mask'],\n",
    "                tokenized_text['token_type_ids'],\n",
    "            )\n",
    "        else:\n",
    "            dataset = TensorDataset(\n",
    "                tokenized_text['input_ids'], tokenized_text['attention_mask']\n",
    "            )\n",
    "\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a1584a1c37b4c9ea2ef82259fedb749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=39.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ab4cfdd3ab49f8be34f1b65d9ea354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=953.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3295eaf634ef4332aca6ebe3164efc6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=871891.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2310e518b8694c7eb60d4e8b062328ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccdadadc7b734716bec73d6b6bb45c43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=669491321.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "import flair\n",
    "example_text = \"This didn't work at all\"\n",
    "\n",
    "classifier = TransformersSequenceClassifier.load(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "\n",
    "sentences = classifier.predict(text=example_text,mini_batch_size=1,\n",
    ")\n",
    "\n",
    "preds = sentences[0].get_labels()\n",
    "\n",
    "truth_lbls = [\n",
    "    flair.data.Label('1 star', 0.8421),\n",
    "    flair.data.Label('2 stars', 0.1379),\n",
    "    flair.data.Label('3 stars', 0.018),\n",
    "    flair.data.Label('4 stars', 0.0012),\n",
    "    flair.data.Label('5 stars', 0.0007)\n",
    "]\n",
    "\n",
    "for pred, truth in zip(preds, truth_lbls):\n",
    "    test_eq(pred.value, truth.value)\n",
    "    test_close(pred.score, truth.score, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TransformersSequenceClassifier.load\" class=\"doc_header\"><code>TransformersSequenceClassifier.load</code><a href=\"__main__.py#L22\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TransformersSequenceClassifier.load</code>(**`model_name_or_path`**:`Union`\\[[`HFModelResult`](/adaptnlp/model_hub.html#HFModelResult), `str`\\])\n",
       "\n",
       "Class method for loading and constructing this classifier\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`model_name_or_path`** : *`typing.Union[adaptnlp.model_hub.HFModelResult, str]`*\t<p>A key string of one of Transformer's pre-trained Sequence Classifier Model or a `HFModelResult`</p>\n",
       "\n",
       "\n",
       "\n",
       "**Returns**:\n",
       "\t\n",
       " * *`<class 'adaptnlp.model.AdaptiveModel'>`*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TransformersSequenceClassifier.load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TransformersSequenceClassifier.predict\" class=\"doc_header\"><code>TransformersSequenceClassifier.predict</code><a href=\"__main__.py#L34\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TransformersSequenceClassifier.predict</code>(**`text`**:`Union`\\[`List`\\[`Sentence`\\], `Sentence`, `List`\\[`str`\\], `str`\\], **`mini_batch_size`**:`int`=*`32`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Predict method for running inference using the pre-trained sequence classifier model\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`text`** : *`typing.Union[typing.List[flair.data.Sentence], flair.data.Sentence, typing.List[str], str]`*\t<p>Sentences to run inference on</p>\n",
       "\n",
       "\n",
       " - **`mini_batch_size`** : *`<class 'int'>`*, *optional*\t<p>Mini batch size</p>\n",
       "\n",
       "\n",
       " - **`kwargs`** : *`<class 'inspect._empty'>`*\n",
       "\n",
       "\n",
       "**Returns**:\n",
       "\t\n",
       " * *`typing.List[flair.data.Sentence]`*\t<p>Returns a list of `Sentence` predictions</p>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TransformersSequenceClassifier.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FlairSequenceClassifier(AdaptiveModel):\n",
    "    \"Adaptive Model for Flair's Sequence Classifier\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        model_name_or_path: str # A key string of one of Flair's pre-trained Sequence Classifier Model\n",
    "    ):\n",
    "        self.classifier = TextClassifier.load(model_name_or_path)\n",
    "\n",
    "    @classmethod\n",
    "    def load(\n",
    "        cls, \n",
    "        model_name_or_path: Union[HFModelResult, FlairModelResult, str] # A key string of one of Flair's pre-trained Sequence Classifier Model or a `HFModelResult`\n",
    "    ) -> AdaptiveModel:\n",
    "        \"Class method for loading a constructing this classifier\"\n",
    "        if risinstance([HFModelResult, FlairModelResult], model_name_or_path): \n",
    "            model_name_or_path = model_name_or_path.name\n",
    "        classifier = cls(model_name_or_path)\n",
    "        return classifier\n",
    "\n",
    "    def predict(\n",
    "        self, \n",
    "        text: Union[List[Sentence], Sentence, List[str], str], # Sentences to run inference on\n",
    "        mini_batch_size: int = 32, # Mini batch size\n",
    "        **kwargs, # Optional arguments for the Flair classifier\n",
    "    ) -> List[Sentence]: # A list of predicted `Sentence`s\n",
    "        \"Predict method for running inference using the pre-trained sequence classifier model\"\n",
    "        if isinstance(text, (Sentence, str)):\n",
    "            text = [text]\n",
    "        if isinstance(text[0], str):\n",
    "            text = [Sentence(s) for s in text]\n",
    "\n",
    "        self.classifier.predict(\n",
    "            sentences=text,\n",
    "            mini_batch_size=mini_batch_size,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-09 18:15:16,657 https://nlp.informatik.hu-berlin.de/resources/models/sentiment-curated-distilbert/sentiment-en-mix-distillbert_4.pt not found in cache, downloading to /tmp/tmp774a70_a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265512723/265512723 [00:12<00:00, 21322484.77B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-09 18:15:29,669 copying /tmp/tmp774a70_a to cache at /root/.flair/models/sentiment-en-mix-distillbert_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-09 18:15:29,923 removing temp file /tmp/tmp774a70_a\n",
      "2021-08-09 18:15:29,950 loading file /root/.flair/models/sentiment-en-mix-distillbert_4.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65853707b9d64df39f04b4705336fc40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "385eee2577a44125a2d7d41309fe4114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41664686066840f29c34d3154511f962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63720943c47244b9b550145033f8ca76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "import flair\n",
    "example_text = \"This didn't work at all\"\n",
    "\n",
    "\n",
    "classifier = FlairSequenceClassifier.load('sentiment')\n",
    "\n",
    "sentences = classifier.predict(text=example_text,mini_batch_size=1,\n",
    ")\n",
    "\n",
    "pred = sentences[0].get_labels()[0]\n",
    "\n",
    "test_eq(pred.value, 'NEGATIVE')\n",
    "test_close(pred.score, 0.999, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"FlairSequenceClassifier.load\" class=\"doc_header\"><code>FlairSequenceClassifier.load</code><a href=\"__main__.py#L11\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>FlairSequenceClassifier.load</code>(**`model_name_or_path`**:`Union`\\[[`HFModelResult`](/adaptnlp/model_hub.html#HFModelResult), [`FlairModelResult`](/adaptnlp/model_hub.html#FlairModelResult), `str`\\])\n",
       "\n",
       "Class method for loading a constructing this classifier\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`model_name_or_path`** : *`typing.Union[adaptnlp.model_hub.HFModelResult, adaptnlp.model_hub.FlairModelResult, str]`*\t<p>A key string of one of Flair's pre-trained Sequence Classifier Model or a `HFModelResult`</p>\n",
       "\n",
       "\n",
       "\n",
       "**Returns**:\n",
       "\t\n",
       " * *`<class 'adaptnlp.model.AdaptiveModel'>`*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(FlairSequenceClassifier.load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"FlairSequenceClassifier.predict\" class=\"doc_header\"><code>FlairSequenceClassifier.predict</code><a href=\"__main__.py#L22\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>FlairSequenceClassifier.predict</code>(**`text`**:`Union`\\[`List`\\[`Sentence`\\], `Sentence`, `List`\\[`str`\\], `str`\\], **`mini_batch_size`**:`int`=*`32`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Predict method for running inference using the pre-trained sequence classifier model\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`text`** : *`typing.Union[typing.List[flair.data.Sentence], flair.data.Sentence, typing.List[str], str]`*\t<p>Sentences to run inference on</p>\n",
       "\n",
       "\n",
       " - **`mini_batch_size`** : *`<class 'int'>`*, *optional*\t<p>Mini batch size</p>\n",
       "\n",
       "\n",
       " - **`kwargs`** : *`<class 'inspect._empty'>`*\n",
       "\n",
       "\n",
       "**Returns**:\n",
       "\t\n",
       " * *`typing.List[flair.data.Sentence]`*\t<p>A list of predicted `Sentence`s</p>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(FlairSequenceClassifier.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from adaptnlp.model_hub import HFModelHub, FlairModelHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EasySequenceClassifier:\n",
    "    \"Easy module for sequence classifiers\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.sequence_classifiers: Dict[AdaptiveModel] = defaultdict(bool)\n",
    "        self.hf_hub = HFModelHub()\n",
    "        self.flair_hub = FlairModelHub()\n",
    "\n",
    "    def tag_text(\n",
    "        self,\n",
    "        text: Union[List[Sentence], Sentence, List[str], str], # String, list of strings, `Sentence`, or list of `Sentence`s to be classified\n",
    "        model_name_or_path: Union[str, FlairModelResult, HFModelResult] = 'en-sentiment', # The model name key or model path\n",
    "        mini_batch_size: int = 32, # The mini batch size for running inference\n",
    "        detail_level:DetailLevel = DetailLevel.Low, # A level of detail to return\n",
    "        class_names:list = None, # A list of labels\n",
    "        **kwargs, # Keyword Arguments for Flair's `TextClassifier.predict()` method params\n",
    "    ) -> List[Sentence]: # A list of Flair's `Sentence`'s\n",
    "        \"Tags a text sequence with labels the sequence classification models have been trained on\"\n",
    "        # Load Text Classifier Model and Pytorch Module into tagger dict\n",
    "        name = getattr(model_name_or_path, 'name', model_name_or_path)\n",
    "        if not self.sequence_classifiers[name]:\n",
    "            \"\"\"\n",
    "            self.sequence_classifiers[name] = TextClassifier.load(\n",
    "                model_name_or_path\n",
    "            )\n",
    "            \"\"\"\n",
    "            if risinstance([FlairModelResult, HFModelResult], model_name_or_path):\n",
    "                try:\n",
    "                    self.sequence_classifiers[name] = FlairSequenceClassifier.load(name)\n",
    "                except:\n",
    "                    self.sequence_classifiers[name] = TransformersSequenceClassifier.load(name)\n",
    "                    \n",
    "            elif risinstance([str, Path], model_name_or_path) and (Path(model_name_or_path).exists() and Path(model_name_or_path).is_dir()):\n",
    "                # Load in previously existing model\n",
    "                try:\n",
    "                    self.sequence_classifiers[name] = FlairSequenceClassifier.load(name)\n",
    "                except:\n",
    "                    self.sequence_classifiers[name] = TransformersSequenceClassifier.load(name)\n",
    "                \n",
    "            else:\n",
    "                # Flair\n",
    "                res = self.flair_hub.search_model_by_name(name, user_uploaded=True)\n",
    "                if len(res) < 1:\n",
    "                    # No models found\n",
    "                    res = self.hf_hub.search_model_by_name(model_name_or_path, user_uploaded=True)\n",
    "                    if len(res) < 1:\n",
    "                        logger.info(\"Not a valid `model_name_or_path` param\")\n",
    "                        return [Sentence('')]\n",
    "                    else:\n",
    "                        name = res[0].name.replace('flairNLP', 'flair')\n",
    "                        self.sequence_classifiers[res[0].name] = TransformersSequenceClassifier.load(name)\n",
    "                else:\n",
    "                    name = res[0].name.replace('flairNLP/', '')\n",
    "                    self.sequence_classifiers[name] = FlairSequenceClassifier.load(name) # Returning the first should always be non-fast\n",
    "\n",
    "        classifier = self.sequence_classifiers[name]\n",
    "        out = classifier.predict(\n",
    "            text=text,\n",
    "            mini_batch_size=mini_batch_size,\n",
    "            **kwargs,\n",
    "        )\n",
    "        if detail_level is None: return out\n",
    "        res = SequenceResult(out, class_names)\n",
    "        return res.to_dict(detail_level)\n",
    "        \n",
    "\n",
    "    def tag_all(\n",
    "        self,\n",
    "        text: Union[List[Sentence], Sentence, List[str], str], # Text input, it can be a string or any of Flair's `Sentence` input formats\n",
    "        mini_batch_size: int = 32, # The mini batch size for running inference\n",
    "        detail_level:DetailLevel = DetailLevel.Low, # A level of detail to return\n",
    "        class_names:list = None, # A list of labels\n",
    "        **kwargs, # Keyword Arguments for Flair's `TextClassifier.predict()` method params\n",
    "    ) -> List[Sentence]: # A list of Flair's `Sentence`'s\n",
    "        \"Tags text with all labels from all sequence classification models\"\n",
    "        sentences = text\n",
    "        for tagger_name in self.sequence_classifiers.keys():\n",
    "            sentences = self.tag_text(\n",
    "                sentences,\n",
    "                model_name_or_path=tagger_name,\n",
    "                mini_batch_size=mini_batch_size,\n",
    "                detail_level = None\n",
    "                **kwargs,\n",
    "            )\n",
    "        res = SequenceResult(out, class_names)\n",
    "        return res.to_dict(detail_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-09 18:18:16,471 loading file nlptown/bert-base-multilingual-uncased-sentiment\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "hub = HFModelHub()\n",
    "model = hub.search_model_by_name(\"nlptown/bert-base\", user_uploaded=True)[0]\n",
    "classifier = EasySequenceClassifier()\n",
    "sentences = classifier.tag_text(text=example_text, \n",
    "                               model_name_or_path=model,\n",
    "                               mini_batch_size=1)\n",
    "for pred, truth in zip(preds, truth_lbls):\n",
    "    test_eq(pred.value, truth.value)\n",
    "    test_close(pred.score, truth.score, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EasySequenceClassifier.tag_text\" class=\"doc_header\"><code>EasySequenceClassifier.tag_text</code><a href=\"__main__.py#L10\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EasySequenceClassifier.tag_text</code>(**`text`**:`Union`\\[`List`\\[`Sentence`\\], `Sentence`, `List`\\[`str`\\], `str`\\], **`model_name_or_path`**:`Union`\\[`str`, [`FlairModelResult`](/adaptnlp/model_hub.html#FlairModelResult), [`HFModelResult`](/adaptnlp/model_hub.html#HFModelResult)\\]=*`'en-sentiment'`*, **`mini_batch_size`**:`int`=*`32`*, **`detail_level`**:`DetailLevel`=*`'low'`*, **`class_names`**:`list`=*`None`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Tags a text sequence with labels the sequence classification models have been trained on\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`text`** : *`typing.Union[typing.List[flair.data.Sentence], flair.data.Sentence, typing.List[str], str]`*\t<p>String, list of strings, `Sentence`, or list of `Sentence`s to be classified</p>\n",
       "\n",
       "\n",
       " - **`model_name_or_path`** : *`typing.Union[str, adaptnlp.model_hub.FlairModelResult, adaptnlp.model_hub.HFModelResult]`*, *optional*\t<p>The model name key or model path</p>\n",
       "\n",
       "\n",
       " - **`mini_batch_size`** : *`<class 'int'>`*, *optional*\t<p>The mini batch size for running inference</p>\n",
       "\n",
       "\n",
       " - **`detail_level`** : *`<class 'fastcore.basics.DetailLevel'>`*, *optional*\t<p>A level of detail to return</p>\n",
       "\n",
       "\n",
       " - **`class_names`** : *`<class 'list'>`*, *optional*\t<p>A list of labels</p>\n",
       "\n",
       "\n",
       " - **`kwargs`** : *`<class 'inspect._empty'>`*\n",
       "\n",
       "\n",
       "**Returns**:\n",
       "\t\n",
       " * *`typing.List[flair.data.Sentence]`*\t<p>A list of Flair's `Sentence`'s</p>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EasySequenceClassifier.tag_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EasySequenceClassifier.tag_all\" class=\"doc_header\"><code>EasySequenceClassifier.tag_all</code><a href=\"__main__.py#L68\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EasySequenceClassifier.tag_all</code>(**`text`**:`Union`\\[`List`\\[`Sentence`\\], `Sentence`, `List`\\[`str`\\], `str`\\], **`mini_batch_size`**:`int`=*`32`*, **`detail_level`**:`DetailLevel`=*`'low'`*, **`class_names`**:`list`=*`None`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Tags text with all labels from all sequence classification models\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`text`** : *`typing.Union[typing.List[flair.data.Sentence], flair.data.Sentence, typing.List[str], str]`*\t<p>Text input, it can be a string or any of Flair's `Sentence` input formats</p>\n",
       "\n",
       "\n",
       " - **`mini_batch_size`** : *`<class 'int'>`*, *optional*\t<p>The mini batch size for running inference</p>\n",
       "\n",
       "\n",
       " - **`detail_level`** : *`<class 'fastcore.basics.DetailLevel'>`*, *optional*\t<p>A level of detail to return</p>\n",
       "\n",
       "\n",
       " - **`class_names`** : *`<class 'list'>`*, *optional*\t<p>A list of labels</p>\n",
       "\n",
       "\n",
       " - **`kwargs`** : *`<class 'inspect._empty'>`*\n",
       "\n",
       "\n",
       "**Returns**:\n",
       "\t\n",
       " * *`typing.List[flair.data.Sentence]`*\t<p>A list of Flair's `Sentence`'s</p>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EasySequenceClassifier.tag_all)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
