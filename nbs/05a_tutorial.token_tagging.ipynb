{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial - Token Tagging with AdaptNLP\n",
    "> Using EasyTokenTagger to quickly perform POS tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll import the `adaptnlp` `EasyTokenTagger` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptnlp import EasyTokenTagger\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write some simple example text, and instantiate an `EasyTokenTagger`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = '''Novetta Solutions is the best. Albert Einstein used to be employed at Novetta Solutions. \n",
    "The Wright brothers loved to visit the JBF headquarters, and they would have a chat with Albert.'''\n",
    "tagger = EasyTokenTagger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will use some `Transformers` models, specifically `bert`.\n",
    "\n",
    "We'll search `HuggingFace` for the model we want, in this case we want to use `sshleifer`'s `tiny-dbmdz-bert` model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptnlp import HFModelHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model Name: sshleifer/tiny-dbmdz-bert-large-cased-finetuned-conll03-english, Tasks: [token-classification]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hub = HFModelHub()\n",
    "model = hub.search_model_by_name('sshleifer/tiny-dbmdz-bert', user_uploaded=True)[0]; model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll use our `tagger` to generate some sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-05 17:45:28,242 loading file /root/.flair/models/tiny-dbmdz-bert-large-cased-finetuned-conll03-english/1e2c09da4ad5b3257008353a87852a7148389cc8308b91cf837f066b95650a0d.595173de82e795b5e4022dca79d10d885137a50ed2ee3974f15a75d328c0cd0a\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentences = tagger.tag_text(text=example_text, model_name_or_path = model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then look at some of our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List string outputs of tags:\n",
      "\n",
      "[{'entity': 'I-LOC', 'score': 0.11716679483652115, 'word': '[CLS] Novetta'},\n",
      " {'entity': 'B-ORG', 'score': 0.11758644878864288, 'word': 'Solutions'},\n",
      " {'entity': 'I-LOC', 'score': 0.11716679483652115, 'word': 'is the'},\n",
      " {'entity': 'B-ORG', 'score': 0.11758644878864288, 'word': 'best'},\n",
      " {'entity': 'I-LOC',\n",
      "  'score': 0.11716679483652115,\n",
      "  'word': '. Albert Einstein used to be employed'},\n",
      " {'entity': 'B-ORG', 'score': 0.11758644878864288, 'word': 'at Nov'},\n",
      " {'entity': 'I-LOC',\n",
      "  'score': 0.11716679483652115,\n",
      "  'word': '##etta Solutions. The Wright brothers loved to visit'},\n",
      " {'entity': 'B-ORG', 'score': 0.11758644878864288, 'word': 'the'},\n",
      " {'entity': 'I-LOC', 'score': 0.11716679483652115, 'word': 'JBF'},\n",
      " {'entity': 'B-ORG', 'score': 0.11758644878864288, 'word': 'headquarters'},\n",
      " {'entity': 'I-LOC', 'score': 0.11716679483652115, 'word': ', and they'},\n",
      " {'entity': 'B-ORG', 'score': 0.11758644878864288, 'word': 'would'},\n",
      " {'entity': 'I-LOC',\n",
      "  'score': 0.11716679483652115,\n",
      "  'word': 'have a chat with Albert. [SEP]'}]\n"
     ]
    }
   ],
   "source": [
    "print(\"List string outputs of tags:\\n\")\n",
    "for sen in sentences['tags']:\n",
    "    pprint(sen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Flair "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Flair we can follow a similar setup to earlier, searching HuggingFace for valid `ner` models. In our case we'll use `Flair`'s `ner-english-ontonotes-fast` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model Name: flair/ner-english-ontonotes-fast, Tasks: [token-classification], Source: HuggingFace Model Hub"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from adaptnlp import FlairModelHub\n",
    "hub = FlairModelHub()\n",
    "model = hub.search_model_by_name('ontonotes-fast')[0]; model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll tag the string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-05 17:48:09,267 loading file /root/.flair/models/ner-english-ontonotes-fast/0d55dd3b912da9cf26e003035a0c269a0e9ab222f0be1e48a3bbba3a58c0fed0.c9907cd5fde3ce84b71a4172e7ca03841cd81ab71d13eb68aa08b259f57c00b6\n"
     ]
    }
   ],
   "source": [
    "sentences = tagger.tag_text(text = example_text, model_name_or_path = model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can get back a JSON of each word and its entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'confidence': 0.7553082704544067,\n",
      "  'end_pos': 17,\n",
      "  'labels': [ORG (0.7553)],\n",
      "  'start_pos': 0,\n",
      "  'text': 'Novetta Solutions',\n",
      "  'value': 'ORG'},\n",
      " {'confidence': 0.9927975535392761,\n",
      "  'end_pos': 46,\n",
      "  'labels': [PERSON (0.9928)],\n",
      "  'start_pos': 31,\n",
      "  'text': 'Albert Einstein',\n",
      "  'value': 'PERSON'},\n",
      " {'confidence': 0.7496212422847748,\n",
      "  'end_pos': 87,\n",
      "  'labels': [ORG (0.7496)],\n",
      "  'start_pos': 70,\n",
      "  'text': 'Novetta Solutions',\n",
      "  'value': 'ORG'},\n",
      " {'confidence': 0.9998451471328735,\n",
      "  'end_pos': 99,\n",
      "  'labels': [PERSON (0.9998)],\n",
      "  'start_pos': 93,\n",
      "  'text': 'Wright',\n",
      "  'value': 'PERSON'},\n",
      " {'confidence': 0.967128336429596,\n",
      "  'end_pos': 131,\n",
      "  'labels': [ORG (0.9671)],\n",
      "  'start_pos': 128,\n",
      "  'text': 'JBF',\n",
      "  'value': 'ORG'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(sentences[0]['entities'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parts of Speech\n",
    "\n",
    "Next we'll look at a parts-of-speech tagger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can simply pass in `\"pos\"`, but let's use our search API to find an english POS tagger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model Name: flair/pos-english-fast, Tasks: [token-classification], Source: HuggingFace Model Hub,\n",
       " Model Name: flair/pos-english, Tasks: [token-classification], Source: HuggingFace Model Hub,\n",
       " Model Name: flair/upos-english-fast, Tasks: [token-classification], Source: HuggingFace Model Hub,\n",
       " Model Name: flair/upos-english, Tasks: [token-classification], Source: HuggingFace Model Hub,\n",
       " Model Name: flair/upos-multi-fast, Tasks: [token-classification], Source: HuggingFace Model Hub,\n",
       " Model Name: flair/upos-multi, Tasks: [token-classification], Source: HuggingFace Model Hub,\n",
       " Model Name: flair/upos, Tasks: [token-classification], Source: Flair's Private Model Hub,\n",
       " Model Name: flair/upos-fast, Tasks: [token-classification], Source: Flair's Private Model Hub,\n",
       " Model Name: flair/pos, Tasks: [token-classification], Source: Flair's Private Model Hub,\n",
       " Model Name: flair/pos-fast, Tasks: [token-classification], Source: Flair's Private Model Hub,\n",
       " Model Name: flair/pos-multi, Tasks: [token-classification], Source: Flair's Private Model Hub,\n",
       " Model Name: flair/multi-pos, Tasks: [token-classification], Source: Flair's Private Model Hub,\n",
       " Model Name: flair/pos-multi-fast, Tasks: [token-classification], Source: Flair's Private Model Hub,\n",
       " Model Name: flair/multi-pos-fast, Tasks: [token-classification], Source: Flair's Private Model Hub,\n",
       " Model Name: flair/da-pos, Tasks: [token-classification], Source: Flair's Private Model Hub,\n",
       " Model Name: flair/de-pos, Tasks: [token-classification], Source: Flair's Private Model Hub,\n",
       " Model Name: flair/de-pos-tweets, Tasks: [token-classification], Source: Flair's Private Model Hub,\n",
       " Model Name: flair/ml-pos, Tasks: [token-classification], Source: Flair's Private Model Hub,\n",
       " Model Name: flair/ml-upos, Tasks: [token-classification], Source: Flair's Private Model Hub,\n",
       " Model Name: flair/pt-pos-clinical, Tasks: [token-classification], Source: Flair's Private Model Hub]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hub.search_model_by_task('pos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the `pos-english-fast` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model Name: flair/pos-english-fast, Tasks: [token-classification], Source: HuggingFace Model Hub"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = hub.search_model_by_name('pos-english-fast')[0]; model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-05 17:49:02,823 loading file /root/.flair/models/pos-english-fast/36f7923039eed4c66e4275927daaff6cd275997d61d238355fb1fe0338fe10a1.ff87e5b4e47fdb42a0c00237d9506c671db773e0a7932179ace82e584383a1b8\n"
     ]
    }
   ],
   "source": [
    "sentences = tagger.tag_text(text = example_text, model_name_or_path = model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then just as before, we get a JSON of our POS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'confidence': 0.998687207698822,\n",
      "  'end_pos': 7,\n",
      "  'labels': [NNP (0.9987)],\n",
      "  'start_pos': 0,\n",
      "  'text': 'Novetta',\n",
      "  'value': 'NNP'},\n",
      " {'confidence': 0.8011120557785034,\n",
      "  'end_pos': 17,\n",
      "  'labels': [NNPS (0.8011)],\n",
      "  'start_pos': 8,\n",
      "  'text': 'Solutions',\n",
      "  'value': 'NNPS'},\n",
      " {'confidence': 0.9999979734420776,\n",
      "  'end_pos': 20,\n",
      "  'labels': [VBZ (1.0)],\n",
      "  'start_pos': 18,\n",
      "  'text': 'is',\n",
      "  'value': 'VBZ'},\n",
      " {'confidence': 0.9999998807907104,\n",
      "  'end_pos': 24,\n",
      "  'labels': [DT (1.0)],\n",
      "  'start_pos': 21,\n",
      "  'text': 'the',\n",
      "  'value': 'DT'},\n",
      " {'confidence': 0.9101433157920837,\n",
      "  'end_pos': 29,\n",
      "  'labels': [JJS (0.9101)],\n",
      "  'start_pos': 25,\n",
      "  'text': 'best',\n",
      "  'value': 'JJS'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(sentences[0]['entities'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk\n",
    "\n",
    "As with everything before, `chunk` tasks operate the same way. You can either pass `chunk` to get the default `en-chunk` model, or we can search the model hub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model Name: flair/chunk-english-fast, Tasks: [token-classification], Source: HuggingFace Model Hub,\n",
       " Model Name: flair/chunk-english, Tasks: [token-classification], Source: HuggingFace Model Hub,\n",
       " Model Name: flair/chunk, Tasks: [token-classification], Source: Flair's Private Model Hub,\n",
       " Model Name: flair/chunk-fast, Tasks: [token-classification], Source: Flair's Private Model Hub]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = hub.search_model_by_task('chunk'); models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the `fast` model again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model Name: flair/chunk-english-fast, Tasks: [token-classification], Source: HuggingFace Model Hub"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models[0]; model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-05 17:49:05,772 loading file /root/.flair/models/chunk-english-fast/be3a207f4993dd6d174d5083341a717d371ec16f721358e7a4d72158ebab28a6.a7f897d05c83e618a8235bbb7ddfca5a79d2daefb8a97c776eb73f97dbaea508\n"
     ]
    }
   ],
   "source": [
    "sentences = tagger.tag_text(text = example_text, model_name_or_path = model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'confidence': 0.9879125952720642,\n",
      "  'end_pos': 17,\n",
      "  'labels': [NP (0.9879)],\n",
      "  'start_pos': 0,\n",
      "  'text': 'Novetta Solutions',\n",
      "  'value': 'NP'},\n",
      " {'confidence': 0.9999805688858032,\n",
      "  'end_pos': 20,\n",
      "  'labels': [VP (1.0)],\n",
      "  'start_pos': 18,\n",
      "  'text': 'is',\n",
      "  'value': 'VP'},\n",
      " {'confidence': 0.8664445877075195,\n",
      "  'end_pos': 29,\n",
      "  'labels': [NP (0.8664)],\n",
      "  'start_pos': 21,\n",
      "  'text': 'the best',\n",
      "  'value': 'NP'},\n",
      " {'confidence': 0.9803058207035065,\n",
      "  'end_pos': 46,\n",
      "  'labels': [NP (0.9803)],\n",
      "  'start_pos': 31,\n",
      "  'text': 'Albert Einstein',\n",
      "  'value': 'NP'},\n",
      " {'confidence': 0.931873619556427,\n",
      "  'end_pos': 66,\n",
      "  'labels': [VP (0.9319)],\n",
      "  'start_pos': 47,\n",
      "  'text': 'used to be employed',\n",
      "  'value': 'VP'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(sentences[0]['entities'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame\n",
    "\n",
    "We can either delegate the `\"frame\"` task and use the default `en-frame-ontonotes` model, or search the API for usable models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model Name: flair/frame-english-fast, Tasks: [token-classification], Source: HuggingFace Model Hub,\n",
       " Model Name: flair/frame-english, Tasks: [token-classification], Source: HuggingFace Model Hub,\n",
       " Model Name: flair/frame, Tasks: [token-classification], Source: Flair's Private Model Hub,\n",
       " Model Name: flair/frame-fast, Tasks: [token-classification], Source: Flair's Private Model Hub]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = hub.search_model_by_task(\"frame\"); models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we will use the \"fast\" model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model Name: flair/frame-english-fast, Tasks: [token-classification], Source: HuggingFace Model Hub"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models[0]; model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-05 17:49:14,076 loading file /root/.flair/models/frame-english-fast/b2f10f9bc52898d86d8e6f3bf20369d681cc1e9badcb71650aa274ac696433c7.643ca10453770684aca3f2e886a7243adb2979c67a68de6379e50ccf5dc248da\n"
     ]
    }
   ],
   "source": [
    "sentences = tagger.tag_text(text = example_text, model_name_or_path = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'confidence': 0.9969749450683594,\n",
      "  'end_pos': 20,\n",
      "  'labels': [be.01 (0.997)],\n",
      "  'start_pos': 18,\n",
      "  'text': 'is',\n",
      "  'value': 'be.01'},\n",
      " {'confidence': 0.8932156562805176,\n",
      "  'end_pos': 51,\n",
      "  'labels': [use.03 (0.8932)],\n",
      "  'start_pos': 47,\n",
      "  'text': 'used',\n",
      "  'value': 'use.03'},\n",
      " {'confidence': 0.9950985312461853,\n",
      "  'end_pos': 57,\n",
      "  'labels': [be.03 (0.9951)],\n",
      "  'start_pos': 55,\n",
      "  'text': 'be',\n",
      "  'value': 'be.03'},\n",
      " {'confidence': 0.6651257872581482,\n",
      "  'end_pos': 66,\n",
      "  'labels': [employ.01 (0.6651)],\n",
      "  'start_pos': 58,\n",
      "  'text': 'employed',\n",
      "  'value': 'employ.01'},\n",
      " {'confidence': 0.7210038900375366,\n",
      "  'end_pos': 114,\n",
      "  'labels': [love.01 (0.721)],\n",
      "  'start_pos': 109,\n",
      "  'text': 'loved',\n",
      "  'value': 'love.01'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(sentences[0]['entities'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Notice: Pay attention to the \"fast\" versus regular naming. \"fast\" models are designed to be extremely efficient on the CPU, and are worth checking out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag Tokens with All Loaded Models At Once\n",
    "\n",
    "As different taggers are loaded into memory, we can tag with all of them at once, for example we'll make a new `EasyTokenTagger` and load in a `ner` and `pos` tagger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-05 17:49:16,462 loading file /root/.flair/models/ner-english-ontonotes-fast/0d55dd3b912da9cf26e003035a0c269a0e9ab222f0be1e48a3bbba3a58c0fed0.c9907cd5fde3ce84b71a4172e7ca03841cd81ab71d13eb68aa08b259f57c00b6\n",
      "2021-10-05 17:49:21,049 loading file /root/.flair/models/pos-english-fast/36f7923039eed4c66e4275927daaff6cd275997d61d238355fb1fe0338fe10a1.ff87e5b4e47fdb42a0c00237d9506c671db773e0a7932179ace82e584383a1b8\n"
     ]
    }
   ],
   "source": [
    "tagger = EasyTokenTagger()\n",
    "_ = tagger.tag_text(text=example_text, model_name_or_path=\"flair/ner-english-ontonotes\")\n",
    "_ = tagger.tag_text(text=example_text, model_name_or_path=\"pos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before finally using both at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = tagger.tag_all(text=example_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can look at the entities tagged of each kind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Novetta Solutions',\n",
       "  'start_pos': 0,\n",
       "  'end_pos': 17,\n",
       "  'labels': [ORG (0.7553)],\n",
       "  'value': ['ORG'],\n",
       "  'confidence': [0.7553082704544067]},\n",
       " {'text': 'Albert Einstein',\n",
       "  'start_pos': 31,\n",
       "  'end_pos': 46,\n",
       "  'labels': [PERSON (0.9928)],\n",
       "  'value': ['PERSON'],\n",
       "  'confidence': [0.9927975535392761]},\n",
       " {'text': 'Novetta Solutions',\n",
       "  'start_pos': 70,\n",
       "  'end_pos': 87,\n",
       "  'labels': [ORG (0.7496)],\n",
       "  'value': ['ORG'],\n",
       "  'confidence': [0.7496212422847748]},\n",
       " {'text': 'Wright',\n",
       "  'start_pos': 93,\n",
       "  'end_pos': 99,\n",
       "  'labels': [PERSON (0.9998), NNP (0.996)],\n",
       "  'value': ['PERSON', 'NNP'],\n",
       "  'confidence': [0.9998451471328735, 0.9959734082221985]},\n",
       " {'text': 'JBF',\n",
       "  'start_pos': 128,\n",
       "  'end_pos': 131,\n",
       "  'labels': [ORG (0.9671), NNP (1.0)],\n",
       "  'value': ['ORG', 'NNP'],\n",
       "  'confidence': [0.967128336429596, 0.9999892711639404]}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0][:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
