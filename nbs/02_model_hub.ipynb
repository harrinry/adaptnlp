{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp model_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interacting with HuggingFace and Flair, Model Zoo\n",
    "> An interactive API for model lookup within HuggingFace and Flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbverbose.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastcore.basics import Self, merge\n",
    "from fastcore.utils import dict2obj, obj2dict, mk_class\n",
    "from fastai.torch_core import apply\n",
    "from huggingface_hub.hf_api import ModelInfo, HfApi\n",
    "\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "`HF_TASKS` and `FLAIR_TASKS` are namespace objects that can enable tab-completion when searching for specific tasks within the `HFModelHub` and `FlairModelHub`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "_hf_tasks = {\n",
    "    'FILL_MASK':'fill-mask',\n",
    "    'QUESTION_ANSWERING':'question-answering',\n",
    "    'SUMMARIZATION':'summarization',\n",
    "    'TABLE_QUESTION_ANSWERING':'table-question-answering',\n",
    "    'TEXT_CLASSIFICATION':'text-classification',\n",
    "    'TEXT_GENERATION':'text-generation',\n",
    "    'TEXT2TEXT_GENERATION':'text2text-generation',\n",
    "    'TOKEN_CLASSIFICATION':'token-classification',\n",
    "    'TRANSLATION':'translation',\n",
    "    'ZERO_SHOT_CLASSIFICATION':'zero-shot-classification',\n",
    "    'CONVERSATIONAL':'conversational',\n",
    "    'TEXT_TO_SPEECH':'text-to-speech',\n",
    "    'AUTOMATIC_SPEECH_RECOGNITION':'automatic-speech-recognition',\n",
    "    'AUDIO_SOURCE_SEPERATION':'audio-source-seperation',\n",
    "    'VOICE_ACTIVITY_DETECTION':'voice-activity-detection'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "mk_class('HF_TASKS', **_hf_tasks,\n",
    "        doc=\"A list of all HuggingFace tasks for valid API lookup as attribtues to get tab-completion and typo-proofing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_all_ = ['HF_TASKS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"HF_TASKS\" class=\"doc_header\"><code>class</code> <code>HF_TASKS</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>HF_TASKS</code>(**\\*`args`**, **\\*\\*`kwargs`**)\n",
       "\n",
       "A list of all HuggingFace tasks for valid API lookup as attribtues to get tab-completion and typo-proofing\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`args`** : *`<class 'inspect._empty'>`*\n",
       "\n",
       " - **`kwargs`** : *`<class 'inspect._empty'>`*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(HF_TASKS, title_level=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible tasks:\n",
      "* fill-mask\n",
      "* question-answering\n",
      "* summarization\n",
      "* table-question-answering\n",
      "* text-classification\n",
      "* text-generation\n",
      "* text2text-generation\n",
      "* token-classification\n",
      "* translation\n",
      "* zero-shot-classification\n",
      "* conversational\n",
      "* text-to-speech\n",
      "* automatic-speech-recognition\n",
      "* audio-source-seperation\n",
      "* voice-activity-detection\n"
     ]
    }
   ],
   "source": [
    "#hide_input\n",
    "print(f'Possible tasks:')\n",
    "for val in _hf_tasks.values():\n",
    "    print(f'* {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "_flair_tasks = {\n",
    "    'NAMED_ENTITY_RECOGNITION':'ner',\n",
    "    'PHRASE_CHUNKING':'chunk',\n",
    "    'VERB_DISAMBIGUATION':'frame',\n",
    "    'PART_OF_SPEECH_TAGGING':'pos',\n",
    "    'UNIVERSAL_PART_OF_SPEECH_TAGGING':'upos',\n",
    "    'EMBEDDINGS':'embeddings',\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "mk_class('FLAIR_TASKS', **_flair_tasks,\n",
    "        doc=\"A list of all Flair tasks for valid API lookup as attributes to get tab-completion and typo-proofing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_all_ = ['FLAIR_TASKS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"FLAIR_TASKS\" class=\"doc_header\"><code>class</code> <code>FLAIR_TASKS</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>FLAIR_TASKS</code>(**\\*`args`**, **\\*\\*`kwargs`**)\n",
       "\n",
       "A list of all Flair tasks for valid API lookup as attributes to get tab-completion and typo-proofing\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`args`** : *`<class 'inspect._empty'>`*\n",
       "\n",
       " - **`kwargs`** : *`<class 'inspect._empty'>`*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(FLAIR_TASKS, title_level=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible tasks:\n",
      "* ner\n",
      "* chunk\n",
      "* frame\n",
      "* pos\n",
      "* upos\n",
      "* embeddings\n"
     ]
    }
   ],
   "source": [
    "#hide_input\n",
    "print(f'Possible tasks:')\n",
    "for val in _flair_tasks.values():\n",
    "    print(f'* {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HFModelResult:\n",
    "    \"\"\"\n",
    "    A very basic class for storing a HuggingFace model returned through an API request\n",
    "    \n",
    "    They have 4 properties:\n",
    "      - `name`: The `modelId` from the `modelInfo`. This also includes the model author's name, such as \"IlyaGusev/mbart_ru_sum_gazeta\"\n",
    "      - `tags`: Any tags that were included in `HuggingFace` in relation to the model. \n",
    "      - `tasks`: These are the tasks dictated for the model.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        model_info: ModelInfo # `ModelInfo` object from HuggingFace model hub\n",
    "    ):\n",
    "        self.info = model_info\n",
    "        \n",
    "    def __repr__(self): return f'Model Name: {self.name}, Tasks: [' + ', '.join(self.tasks) + ']'\n",
    "    \n",
    "    @property\n",
    "    def name(self): return self.info.modelId\n",
    "\n",
    "    @property\n",
    "    def tags(self): return self.info.tags\n",
    "    \n",
    "    @property\n",
    "    def tasks(self): \n",
    "        if self.info.pipeline_tag:\n",
    "            all_tasks = [self.info.pipeline_tag]\n",
    "            for tag in self.tags:\n",
    "                if (tag in _hf_tasks.values()) and (tag not in all_tasks):\n",
    "                    all_tasks += [tag]\n",
    "        else: all_tasks = []\n",
    "        all_tasks.sort()\n",
    "        return all_tasks\n",
    "    \n",
    "    def to_dict(\n",
    "        self\n",
    "    ) -> dict: # Dictionary with keys `model_name`, `tags`, `tasks`, `model_info` \n",
    "        \"Returns `HFModelResult` as a dictionary\"\n",
    "        return {'model_name':self.name, 'tags':self.tags, 'tasks':self.tasks, 'model_info':self.info}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"HFModelResult\" class=\"doc_header\"><code>class</code> <code>HFModelResult</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>HFModelResult</code>(**`model_info`**:`ModelInfo`)\n",
       "\n",
       "A very basic class for storing a HuggingFace model returned through an API request\n",
       "\n",
       "They have 4 properties:\n",
       "  - `name`: The `modelId` from the `modelInfo`. This also includes the model author's name, such as \"IlyaGusev/mbart_ru_sum_gazeta\"\n",
       "  - `tags`: Any tags that were included in `HuggingFace` in relation to the model. \n",
       "  - `tasks`: These are the tasks dictated for the model.\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`model_info`** : *`<class 'huggingface_hub.hf_api.ModelInfo'>`*\t<p>`ModelInfo` object from HuggingFace model hub</p>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(HFModelResult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look inside of `modelInfo.pipeline_tag` as well as the `tags` for if there is any overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"HFModelResult.to_dict\" class=\"doc_header\"><code>HFModelResult.to_dict</code><a href=\"__main__.py#L36\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>HFModelResult.to_dict</code>()\n",
       "\n",
       "Returns [`HFModelResult`](/adaptnlp/model_hub.html#HFModelResult) as a dictionary\n",
       "\n",
       "\n",
       "\n",
       "**Returns**:\n",
       "\t\n",
       " * *`<class 'dict'>`*\t<p>Dictionary with keys `model_name`, `tags`, `tasks`, `model_info`</p>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(HFModelResult.to_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HFModelHub:\n",
    "    \"A class for interacting with the HF model hub API, and searching for models by name or task\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        username:str=None, # Your HuggingFace username\n",
    "        password:str=None # Your HuggingFace password\n",
    "    ):\n",
    "        self.api = HfApi()\n",
    "        if username and password:\n",
    "            self.token = self.api.login(username, password)\n",
    "        elif username or password:\n",
    "            print('Only a username or password was entered. You should include both to get authorized access')\n",
    "        \n",
    "    def _format_results(\n",
    "        self, \n",
    "        results:list, # A list of HuggingFace API results\n",
    "        as_dict:bool=False, # Whether to return as a dictionary or list\n",
    "        user_uploaded:bool=False # Whether to filter out user-uploaded results\n",
    "    ) -> (List[HFModelResult], Dict[str, HFModelResult]): # A list of `HFModelResult`s\n",
    "        \"Takes raw HuggingFace API results and makes them easier to read and work with\"\n",
    "        results = apply(HFModelResult, results)\n",
    "        if not user_uploaded:\n",
    "            results = [r for r in results if '/' not in r.name]\n",
    "        if as_dict:\n",
    "            dicts = apply(Self.to_dict(), results)\n",
    "            results = {m['model_name'] : m for m in dicts}\n",
    "        return results\n",
    "        \n",
    "    def search_model_by_task(\n",
    "        self, \n",
    "        task:str, # A valid task to search in the HuggingFace hub for\n",
    "        as_dict:bool=False, # Whether to return as a dictionary or list\n",
    "        user_uploaded:bool=False # Whether to filter out user-uploaded results\n",
    "    ) -> (List[HFModelResult], Dict[str, HFModelResult]): # A list of `HFModelResult`s\n",
    "        \"Searches HuggingFace Model API for all pretrained models relating to `task`\"\n",
    "        if task not in _hf_tasks.values():\n",
    "            raise ValueError(f'''`{task}` is not a valid task. \n",
    "            \n",
    "            Please choose a valid one available from HuggingFace: (https://huggingface.co/transformers/task_summary.html) \n",
    "            Or with the `HF_TASKS` object''')\n",
    "        models = self.api.list_models(task)\n",
    "        return self._format_results(models, as_dict, user_uploaded)\n",
    "    \n",
    "    def search_model_by_name(\n",
    "        self, \n",
    "        name:str, # A valid model name \n",
    "        as_dict:bool=False, # Whether to return as a dictionary or list\n",
    "        user_uploaded:bool=False # Whether to filter out user-uploaded results\n",
    "    ) -> (List[HFModelResult], Dict[str, HFModelResult]): # A list of `HFModelResult`s\n",
    "        \"Searches HuggingFace Model API for all pretrained models containing `name`\"\n",
    "        if user_uploaded:\n",
    "            models = self.api.list_models()\n",
    "            models = self._format_results(models, as_dict, user_uploaded)\n",
    "            models = [m for m in models if name in m.name]\n",
    "            \n",
    "        else:\n",
    "            models = self.api.list_models(name)\n",
    "            models = self._format_results(models, as_dict, user_uploaded)\n",
    "        return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model search hub creates a friendly end-user API when searching through HuggingFace (and Flair, as we will see later). Usage is extremely simple as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"HFModelHub.search_model_by_task\" class=\"doc_header\"><code>HFModelHub.search_model_by_task</code><a href=\"__main__.py#L31\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>HFModelHub.search_model_by_task</code>(**`task`**:`str`, **`as_dict`**:`bool`=*`False`*, **`user_uploaded`**:`bool`=*`False`*)\n",
       "\n",
       "Searches HuggingFace Model API for all pretrained models relating to `task`\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`task`** : *`<class 'str'>`*\t<p>A valid task to search in the HuggingFace hub for</p>\n",
       "\n",
       "\n",
       " - **`as_dict`** : *`<class 'bool'>`*, *optional*\t<p>Whether to return as a dictionary or list</p>\n",
       "\n",
       "\n",
       " - **`user_uploaded`** : *`<class 'bool'>`*, *optional*\t<p>Whether to filter out user-uploaded results</p>\n",
       "\n",
       "\n",
       "\n",
       "**Returns**:\n",
       "\t\n",
       " * *`(typing.List[__main__.HFModelResult], typing.Dict[str, __main__.HFModelResult])`*\t<p>A list of `HFModelResult`s</p>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(HFModelHub.search_model_by_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will return a list of models available for a particular class. A few usage examples are below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model Name: t5-11b, Tasks: [summarization, text2text-generation, translation],\n",
       " Model Name: t5-3b, Tasks: [summarization, text2text-generation, translation],\n",
       " Model Name: t5-base, Tasks: [summarization, text2text-generation, translation],\n",
       " Model Name: t5-large, Tasks: [summarization, text2text-generation, translation],\n",
       " Model Name: t5-small, Tasks: [summarization, text2text-generation, translation]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hub = HFModelHub()\n",
    "models = hub.search_model_by_task('summarization', user_uploaded=False, as_dict=False)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(models[0].name, 't5-11b')\n",
    "test_eq(models[0].tasks, ['summarization', 'text2text-generation', 'translation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also search for any user-uploaded models from the community too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model Name: t5-11b, Tasks: [summarization, text2text-generation, translation],\n",
       " Model Name: t5-3b, Tasks: [summarization, text2text-generation, translation],\n",
       " Model Name: t5-base, Tasks: [summarization, text2text-generation, translation],\n",
       " Model Name: t5-large, Tasks: [summarization, text2text-generation, translation],\n",
       " Model Name: t5-small, Tasks: [summarization, text2text-generation, translation],\n",
       " Model Name: Callidior/bert2bert-base-arxiv-titlegen, Tasks: [summarization, text2text-generation],\n",
       " Model Name: IlyaGusev/mbart_ru_sum_gazeta, Tasks: [summarization, text2text-generation],\n",
       " Model Name: IlyaGusev/rubert_telegram_headlines, Tasks: [summarization, text2text-generation],\n",
       " Model Name: LeoCordoba/beto2beto-ccnews-titles-es, Tasks: [summarization, text2text-generation],\n",
       " Model Name: LeoCordoba/beto2beto-mlsum, Tasks: [summarization, text2text-generation]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = hub.search_model_by_task('summarization', user_uploaded=True)\n",
    "models[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "model = models[5]\n",
    "author, name = model.name.split('/')\n",
    "test_eq(author, 'Callidior')\n",
    "test_eq(name, 'bert2bert-base-arxiv-titlegen')\n",
    "test_eq(model.tasks, ['summarization', 'text2text-generation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also cases where a `dict` may be easier to work with (perhaps utilizing a network API, or ease of use for some). We can instead return a dictionary of `HFModelResult` objects too by passing `as_dict=True` to any search call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 't5-11b',\n",
       " 'tags': ['pytorch',\n",
       "  'tf',\n",
       "  't5',\n",
       "  'lm-head',\n",
       "  'seq2seq',\n",
       "  'en',\n",
       "  'fr',\n",
       "  'ro',\n",
       "  'de',\n",
       "  'dataset:c4',\n",
       "  'arxiv:1910.10683',\n",
       "  'transformers',\n",
       "  'summarization',\n",
       "  'translation',\n",
       "  'license:apache-2.0',\n",
       "  'text2text-generation'],\n",
       " 'tasks': ['summarization', 'text2text-generation', 'translation'],\n",
       " 'model_info': ModelInfo: {\n",
       " \tmodelId: t5-11b\n",
       " \tsha: b8fabb39157e07006719ced3f9b9b91a4344317d\n",
       " \tlastModified: 2021-03-18T01:58:45.000Z\n",
       " \ttags: ['pytorch', 'tf', 't5', 'lm-head', 'seq2seq', 'en', 'fr', 'ro', 'de', 'dataset:c4', 'arxiv:1910.10683', 'transformers', 'summarization', 'translation', 'license:apache-2.0', 'text2text-generation']\n",
       " \tpipeline_tag: translation\n",
       " \tsiblings: [ModelFile(rfilename='.gitattributes'), ModelFile(rfilename='README.md'), ModelFile(rfilename='config.json'), ModelFile(rfilename='pytorch_model.bin'), ModelFile(rfilename='spiece.model'), ModelFile(rfilename='tf_model.h5'), ModelFile(rfilename='tokenizer.json')]\n",
       " \tconfig: None\n",
       " \tprivate: False\n",
       " \tdownloads: 1677\n",
       " \tlibrary_name: transformers\n",
       " }}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = hub.search_model_by_task('summarization', as_dict=True);\n",
    "models['t5-11b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(models.keys(), ['t5-11b', 't5-3b', 't5-base', 't5-large', 't5-small'])\n",
    "test_eq(models['t5-11b'].keys(), ['model_name', 'tags', 'tasks', 'model_info'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will return a dictionary of the name, the HuggingFace tags affiliated with the model, the dictated tasks, and an instance of `huggingface_hub`'s `ModelInfo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"HFModelHub.search_model_by_name\" class=\"doc_header\"><code>HFModelHub.search_model_by_name</code><a href=\"__main__.py#L46\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>HFModelHub.search_model_by_name</code>(**`name`**:`str`, **`as_dict`**:`bool`=*`False`*, **`user_uploaded`**:`bool`=*`False`*)\n",
       "\n",
       "Searches HuggingFace Model API for all pretrained models containing `name`\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`name`** : *`<class 'str'>`*\t<p>A valid model name</p>\n",
       "\n",
       "\n",
       " - **`as_dict`** : *`<class 'bool'>`*, *optional*\t<p>Whether to return as a dictionary or list</p>\n",
       "\n",
       "\n",
       " - **`user_uploaded`** : *`<class 'bool'>`*, *optional*\t<p>Whether to filter out user-uploaded results</p>\n",
       "\n",
       "\n",
       "\n",
       "**Returns**:\n",
       "\t\n",
       " * *`(typing.List[__main__.HFModelResult], typing.Dict[str, __main__.HFModelResult])`*\t<p>A list of `HFModelResult`s</p>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(HFModelHub.search_model_by_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `search_model_by_name` you're allowed a bit more freedom in what you wish to search for. `search_model_by_name` downloads the entire list of models from `HuggingFace` then performs partial string matching. As a result you can search for all models by a particular user by doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model Name: Callidior/bert2bert-base-arxiv-titlegen, Tasks: [summarization]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hub.search_model_by_name('Callidior', user_uploaded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or (as implied by the function name) any model type itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model Name: 850886470/xxy_gpt2_chinese, Tasks: [],\n",
       " Model Name: ComCom-Dev/gpt2-bible-test, Tasks: [],\n",
       " Model Name: DHBaek/gpt2-stackoverflow-question-contents-generator, Tasks: [text-generation],\n",
       " Model Name: DeepESP/gpt2-spanish, Tasks: [text-generation],\n",
       " Model Name: Fabby/gpt2-english-light-novel-titles, Tasks: []]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hub.search_model_by_name('gpt2', user_uploaded=True)[5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "# Flair models originating from:\n",
    "# https://github.com/flairNLP/flair/blob/master/flair/models/text_classification_model.py#L483\n",
    "# and: https://github.com/flairNLP/flair/blob/master/flair/models/sequence_tagger_model.py#L1053\n",
    "# and: https://github.com/flairNLP/flair/blob/master/flair/embeddings/token.py#L406\n",
    "_flair_models = {\n",
    "    'de-offensive-language' : ['text-classification'],\n",
    "    'sentiment' : ['text-classification'],\n",
    "    'en-sentiment' : ['text-classification'],\n",
    "    'sentiment-fast' : ['text-classification'],\n",
    "    'communicative-functions' : ['text-classification'],\n",
    "    'tars-base' : ['text-classification'],\n",
    "    # English Named Entity Recognition Models (NER)\n",
    "    'ner' : ['token-classification'],\n",
    "    'ner-pooled' : ['token-classification'],\n",
    "    'ner-fast' : ['token-classification'],\n",
    "    'ner-ontonotes' : ['token-classification'],\n",
    "    'ner-ontonotes-fast' : ['token-classification'],\n",
    "    # Multilingual NER models\n",
    "    'ner-multi' : ['token-classification'],\n",
    "    'multi-ner' : ['token-classification'],\n",
    "    'ner-multi-fast' : ['token-classification'],\n",
    "    # English POS models\n",
    "    'upos' : ['token-classification'],\n",
    "    'upos-fast' : ['token-classification'],\n",
    "    'pos' : ['token-classification'],\n",
    "    'pos-fast' : ['token-classification'],\n",
    "    # Multilingual POS models\n",
    "    'pos-multi' : ['token-classification'],\n",
    "    'multi-pos' : ['token-classification'],\n",
    "    'pos-multi-fast' : ['token-classification'],\n",
    "    'multi-pos-fast' : ['token-classification'],\n",
    "    # English SRL models\n",
    "    'frame' : ['token-classification'],\n",
    "    'frame-fast' : ['token-classification'],\n",
    "    # English chunking models\n",
    "    'chunk' : ['token-classification'],\n",
    "    'chunk-fast' : ['token-classification'],\n",
    "    # Danish models\n",
    "    'da-pos' : ['token-classification'],\n",
    "    'da-ner' : ['token-classification'],\n",
    "    # German models\n",
    "    'de-pos' : ['token-classification'],\n",
    "    'de-pos-tweets' : ['token-classification'],\n",
    "    'de-ner' : ['token-classification'],\n",
    "    'de-ner-germeval' : ['token-classification'],\n",
    "    'de-ler' : ['token-classification'],\n",
    "    'de-ner-legal' : ['token-classification'],\n",
    "    # French models\n",
    "    'fr-ner' : ['token-classification'],\n",
    "    # Dutch models\n",
    "    'nl-ner' : ['token-classification'],\n",
    "    'nl-ner-rnn' : ['token-classification'],\n",
    "    # Malayalam models\n",
    "    'ml-pos' : ['token-classification'],\n",
    "    'ml-upos' : ['token-classification'],\n",
    "    # Portuguese models\n",
    "    'pt-pos-clinical' : ['token-classification'],\n",
    "    # Keyphrase models\n",
    "    'keyphrase' : ['token-classification'],\n",
    "    'negation-speculation' : ['token-classification'],\n",
    "    # Biomedical\n",
    "    'hunflair-paper-cellline' : ['token-classification'],\n",
    "    'hunflair-paper-chemical' : ['token-classification'],\n",
    "    'hunflair-paper-disease' : ['token-classification'],\n",
    "    'hunflair-paper-gene' : ['token-classification'],\n",
    "    'hunflair-paper-species' : ['token-classification'],\n",
    "    'hunflair-cellline' : ['token-classification'],\n",
    "    'hunflair-chemical' : ['token-classification'],\n",
    "    'hunflair-disease' : ['token-classification'],\n",
    "    'hunflair-gene' : ['token-classification'],\n",
    "    'hunflair-species' : ['token-classification'],\n",
    "    # Embeddings\n",
    "    # multilingual models\n",
    "    \"multi-forward\":['embeddings'],\n",
    "    \"multi-backward\":['embeddings'],\n",
    "    \"multi-v0-forward\":['embeddings'],\n",
    "    \"multi-v0-backward\":['embeddings'],\n",
    "    \"multi-forward-fast\":['embeddings'],\n",
    "    \"multi-backward-fast\":['embeddings'],\n",
    "    # English models\n",
    "    \"en-forward\":['embeddings'],\n",
    "    \"en-backward\":['embeddings'],\n",
    "    \"en-forward-fast\":['embeddings'],\n",
    "    \"en-backward-fast\":['embeddings'],\n",
    "    \"news-forward\":['embeddings'],\n",
    "    \"news-backward\":['embeddings'],\n",
    "    \"news-forward-fast\":['embeddings'],\n",
    "    \"news-backward-fast\":['embeddings'],\n",
    "    \"mix-forward\":['embeddings'],\n",
    "    \"mix-backward\":['embeddings'],\n",
    "    # Arabic\n",
    "    \"ar-forward\":['embeddings'],\n",
    "    \"ar-backward\":['embeddings'],\n",
    "    # Bulgarian\n",
    "    \"bg-forward-fast\":['embeddings'],\n",
    "    \"bg-backward-fast\":['embeddings'],\n",
    "    \"bg-forward\":['embeddings'],\n",
    "    \"bg-backward\":['embeddings'],\n",
    "    # Czech\n",
    "    \"cs-forward\":['embeddings'],\n",
    "    \"cs-backward\":['embeddings'],\n",
    "    \"cs-v0-forward\":['embeddings'],\n",
    "    \"cs-v0-backward\":['embeddings'],\n",
    "    # Danish\n",
    "    \"da-forward\":['embeddings'],\n",
    "    \"da-backward\":['embeddings'],\n",
    "    # German\n",
    "    \"de-forward\":['embeddings'],\n",
    "    \"de-backward\":['embeddings'],\n",
    "    \"de-historic-ha-forward\":['embeddings'],\n",
    "    \"de-historic-ha-backward\":['embeddings'],\n",
    "    \"de-historic-wz-forward\":['embeddings'],\n",
    "    \"de-historic-wz-backward\":['embeddings'],\n",
    "    \"de-historic-rw-forward\":['embeddings'],\n",
    "    \"de-historic-rw-backward\":['embeddings'],\n",
    "    # Spanish\n",
    "    \"es-forward\":['embeddings'],\n",
    "    \"es-backward\":['embeddings'],\n",
    "    \"es-forward-fast\":['embeddings'],\n",
    "    \"es-backward-fast\":['embeddings'],\n",
    "    # Basque\n",
    "    \"eu-forward\":['embeddings'],\n",
    "    \"eu-backward\":['embeddings'],\n",
    "    \"eu-v1-forward\":['embeddings'],\n",
    "    \"eu-v1-backward\":['embeddings'],\n",
    "    \"eu-v0-forward\":['embeddings'],\n",
    "    \"eu-v0-backward\":['embeddings'],\n",
    "    # Persian\n",
    "    \"fa-forward\":['embeddings'],\n",
    "    \"fa-backward\":['embeddings'],\n",
    "    # Finnish\n",
    "    \"fi-forward\":['embeddings'],\n",
    "    \"fi-backward\":['embeddings'],\n",
    "    # French\n",
    "    \"fr-forward\":['embeddings'],\n",
    "    \"fr-backward\":['embeddings'],\n",
    "    # Hebrew\n",
    "    \"he-forward\":['embeddings'],\n",
    "    \"he-backward\":['embeddings'],\n",
    "    # Hindi\n",
    "    \"hi-forward\":['embeddings'],\n",
    "    \"hi-backward\":['embeddings'],\n",
    "    # Croatian\n",
    "    \"hr-forward\":['embeddings'],\n",
    "    \"hr-backward\":['embeddings'],\n",
    "    # Indonesian\n",
    "    \"id-forward\":['embeddings'],\n",
    "    \"id-backward\":['embeddings'],\n",
    "    # Italian\n",
    "    \"it-forward\":['embeddings'],\n",
    "    \"it-backward\":['embeddings'],\n",
    "    # Japanese\n",
    "    \"ja-forward\":['embeddings'],\n",
    "    \"ja-backward\":['embeddings'],\n",
    "    # Malayalam\n",
    "    \"ml-forward\":['embeddings'],\n",
    "    \"ml-backward\":['embeddings'],\n",
    "    # Dutch\n",
    "    \"nl-forward\":['embeddings'],\n",
    "    \"nl-backward\":['embeddings'],\n",
    "    \"nl-v0-forward\":['embeddings'],\n",
    "    \"nl-v0-backward\":['embeddings'],\n",
    "    # Norwegian\n",
    "    \"no-forward\":['embeddings'],\n",
    "    \"no-backward\":['embeddings'],\n",
    "    # Polish\n",
    "    \"pl-forward\":['embeddings'],\n",
    "    \"pl-backward\":['embeddings'],\n",
    "    \"pl-opus-forward\":['embeddings'],\n",
    "    \"pl-opus-backward\":['embeddings'],\n",
    "    # Portuguese\n",
    "    \"pt-forward\":['embeddings'],\n",
    "    \"pt-backward\":['embeddings'],\n",
    "    # Pubmed\n",
    "    \"pubmed-forward\":['embeddings'],\n",
    "    \"pubmed-backward\":['embeddings'],\n",
    "    \"pubmed-2015-forward\":['embeddings'],\n",
    "    \"pubmed-2015-backward\":['embeddings'],\n",
    "    # Slovenian\n",
    "    \"sl-forward\":['embeddings'],\n",
    "    \"sl-backward\":['embeddings'],\n",
    "    \"sl-v0-forward\":['embeddings'],\n",
    "    \"sl-v0-backward\":['embeddings'],\n",
    "    # Swedish\n",
    "    \"sv-forward\":['embeddings'],\n",
    "    \"sv-backward\":['embeddings'],\n",
    "    \"sv-v0-forward\":['embeddings'],\n",
    "    \"sv-v0-backward\":['embeddings'],\n",
    "    # Tamil\n",
    "    \"ta-forward\":['embeddings'],\n",
    "    \"ta-backward\":['embeddings'],\n",
    "    # CLEF HIPE Shared task\n",
    "    \"de-impresso-hipe-v1-forward\":['embeddings'],\n",
    "    \"de-impresso-hipe-v1-backward\":['embeddings'],\n",
    "    \"en-impresso-hipe-v1-forward\":['embeddings'],\n",
    "    \"en-impresso-hipe-v1-backward\":['embeddings'],\n",
    "    \"fr-impresso-hipe-v1-forward\":['embeddings'],\n",
    "    \"fr-impresso-hipe-v1-backward\":['embeddings']    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "FLAIR_MODELS = [ModelInfo(f'flairNLP/{key}', pipeline_tag=val[0]) for key,val in _flair_models.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flair has a series of extra models available for use that are not available through HuggingFace such as `sentiment`, `communicative-functions`, and more. `FLAIR_MODELS` is a convience holder for quick lookup of these models (as no such list is easily available currently). When shown as results on the API they will be given the same `flair` prefix for convience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FlairModelResult(HFModelResult):\n",
    "    \"\"\"\n",
    "    A version of `HFModelResult` for Flair specifically. \n",
    "    \n",
    "    Includes which backend the model was found (such as on HuggingFace or Flair's private model list)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        model_info: ModelInfo # ModelInfo object from HuggingFace model hub\n",
    "    ):\n",
    "        if 'flairNLP' in model_info.modelId:\n",
    "            self.from_hf = False\n",
    "        else:\n",
    "            self.from_hf = True\n",
    "        super().__init__(model_info)\n",
    "        \n",
    "    def __repr__(self): return f'Model Name: {self.name.replace(\"flairNLP\", \"flair\")}, Tasks: [' + ', '.join(self.tasks) + ']' + f', Source: {self.source}'\n",
    "    \n",
    "    @property\n",
    "    def source(self):\n",
    "        if self.from_hf: return \"HuggingFace Model Hub\"\n",
    "        else: return \"Flair's Private Model Hub\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FlairModelHub:\n",
    "    \"A class for interacting with the HF model hub API, and searching for Flair models by name or task\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        username:str=None, # HuggingFace username\n",
    "        password:str=None # HuggingFace password\n",
    "    ):\n",
    "        self.api = HfApi()\n",
    "        if username and password:\n",
    "            self.token = self.api.login(username, password)\n",
    "        elif username or password:\n",
    "            print('Only a username or password was entered. You should include both to get authorized access')\n",
    "        self.models = self.api.list_models('flair') + FLAIR_MODELS\n",
    "        \n",
    "    def _format_results(\n",
    "        self, \n",
    "        results:list, # A list of HuggingFace API results\n",
    "        as_dict:bool=False, # Whether to return as a dictionary or list\n",
    "        user_uploaded:bool=False # Whether to filter out user-uploaded results\n",
    "    ) -> (List[FlairModelResult], Dict[str, FlairModelResult]): # A list of `FlairModelResult`s\n",
    "        \"Takes raw HuggingFace API results and makes them easier to read and work with\"\n",
    "        results = apply(FlairModelResult, results)\n",
    "        if not user_uploaded:\n",
    "            results = [r for r in results if 'flair/' in r.name or 'flairNLP/' in r.name]\n",
    "        if as_dict:\n",
    "            dicts = apply(Self.to_dict(), results)\n",
    "            results = {m['model_name'] : m for m in dicts}\n",
    "        return results\n",
    "    \n",
    "    def search_model_by_name(\n",
    "        self, \n",
    "        name:str, # A valid model name \n",
    "        as_dict:bool=False, # Whether to return as a dictionary or list\n",
    "        user_uploaded:bool=False # Whether to filter out user-uploaded results\n",
    "    ) -> (List[FlairModelResult], Dict[str, FlairModelResult]): # A list of `FlairModelResult`s\n",
    "        \"Searches HuggingFace Model API for all flair models containing `name`\"\n",
    "        models = [m for m in self.models if name in m.modelId]\n",
    "        return self._format_results(models, as_dict, user_uploaded)\n",
    "    \n",
    "    def search_model_by_task(\n",
    "        self, \n",
    "        task:str, \n",
    "        as_dict=False, \n",
    "        user_uploaded=False\n",
    "    ) -> (List[FlairModelResult], Dict[str, FlairModelResult]): # A list of `FlairModelResult`s\n",
    "        \"Searches HuggingFace Model API for all flair models for `task`\"\n",
    "        if (task not in _flair_tasks.values()) and (task != ''):\n",
    "            raise ValueError(f'''`{task}` is not a valid task. \n",
    "            \n",
    "            Please choose a valid one available from Flair: (https://huggingface.co/flair) \n",
    "            Or with the `FLAIR_TASKS` object''')\n",
    "        models = [m for m in self.models if task in m.modelId or task == m.pipeline_tag]\n",
    "        return self._format_results(models, as_dict, user_uploaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"FlairModelHub\" class=\"doc_header\"><code>class</code> <code>FlairModelHub</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>FlairModelHub</code>(**`username`**:`str`=*`None`*, **`password`**:`str`=*`None`*)\n",
       "\n",
       "A class for interacting with the HF model hub API, and searching for Flair models by name or task\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`username`** : *`<class 'str'>`*, *optional*\t<p>HuggingFace username</p>\n",
       "\n",
       "\n",
       " - **`password`** : *`<class 'str'>`*, *optional*\t<p>HuggingFace password</p>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(FlairModelHub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`FlairModelHub` is extremely similar to `HFModelHub`, with the two differences being that it will **only** return `Flair` models, and it has access to the *other* Flair models available that can't be accessed through the HuggingFace model hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub = FlairModelHub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"FlairModelHub.search_model_by_name\" class=\"doc_header\"><code>FlairModelHub.search_model_by_name</code><a href=\"__main__.py#L32\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>FlairModelHub.search_model_by_name</code>(**`name`**:`str`, **`as_dict`**:`bool`=*`False`*, **`user_uploaded`**:`bool`=*`False`*)\n",
       "\n",
       "Searches HuggingFace Model API for all flair models containing `name`\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`name`** : *`<class 'str'>`*\t<p>A valid model name</p>\n",
       "\n",
       "\n",
       " - **`as_dict`** : *`<class 'bool'>`*, *optional*\t<p>Whether to return as a dictionary or list</p>\n",
       "\n",
       "\n",
       " - **`user_uploaded`** : *`<class 'bool'>`*, *optional*\t<p>Whether to filter out user-uploaded results</p>\n",
       "\n",
       "\n",
       "\n",
       "**Returns**:\n",
       "\t\n",
       " * *`(typing.List[__main__.FlairModelResult], typing.Dict[str, __main__.FlairModelResult])`*\t<p>A list of `FlairModelResult`s</p>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(FlairModelHub.search_model_by_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`seach_model_by_name` will also let you search for models without needing the `flair` prefix, such as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model Name: flair/sentiment, Tasks: [text-classification], Source: Flair's Private Model Hub,\n",
       " Model Name: flair/en-sentiment, Tasks: [text-classification], Source: Flair's Private Model Hub,\n",
       " Model Name: flair/sentiment-fast, Tasks: [text-classification], Source: Flair's Private Model Hub]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hub.search_model_by_name('sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(0, len(hub.search_model_by_name('gpt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"FlairModelHub.search_model_by_task\" class=\"doc_header\"><code>FlairModelHub.search_model_by_task</code><a href=\"__main__.py#L42\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>FlairModelHub.search_model_by_task</code>(**`task`**:`str`, **`as_dict`**=*`False`*, **`user_uploaded`**=*`False`*)\n",
       "\n",
       "Searches HuggingFace Model API for all flair models for `task`\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`task`** : *`<class 'str'>`*\n",
       "\n",
       " - **`as_dict`** : *`<class 'bool'>`*, *optional*\n",
       "\n",
       " - **`user_uploaded`** : *`<class 'bool'>`*, *optional*\n",
       "\n",
       "\n",
       "**Returns**:\n",
       "\t\n",
       " * *`(typing.List[__main__.FlairModelResult], typing.Dict[str, __main__.FlairModelResult])`*\t<p>A list of `FlairModelResult`s</p>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(FlairModelHub.search_model_by_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have a `FLAIR_TASKS` object declared earlier, we can utilize it when searching for models by a task. Similar to `search_model_by_name` you should not include `flair/` in your search results, and instead search through the task key such as `ner` or `FLAIR_TASKS.NAMED_ENTITY_RECOGNITION`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "models = hub.search_model_by_task('ner')\n",
    "models = [m for m in models if m.source == \"Flair's Private Model Hub\"]\n",
    "test_eq(len(models), 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
