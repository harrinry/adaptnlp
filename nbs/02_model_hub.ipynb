{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp model_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interacting with HuggingFace and Flair, Model Zoo\n",
    "> An interactive API for model lookup within HuggingFace and Flair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: For right now this is only available in the dev build of adaptnlp, which you can install with `pip install git+https://github.com/novetta/adaptnlp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import show_doc\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastcore.basics import Self, merge\n",
    "from fastcore.utils import dict2obj, obj2dict, mk_class\n",
    "from fastai_minima.utils import apply\n",
    "from huggingface_hub.hf_api import ModelInfo, HfApi\n",
    "\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "`HF_TASKS` and `FLAIR_TASKS` are namespace objects that can enable tab-completion when searching for specific tasks within the `HFModelHub` and `FlairModelHub`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "_hf_tasks = {\n",
    "    'FILL_MASK':'fill-mask',\n",
    "    'QUESTION_ANSWERING':'question-answering',\n",
    "    'SUMMARIZATION':'summarization',\n",
    "    'TABLE_QUESTION_ANSWERING':'table-question-answering',\n",
    "    'TEXT_CLASSIFICATION':'text-classification',\n",
    "    'TEXT_GENERATION':'text-generation',\n",
    "    'TEXT2TEXT_GENERATION':'text2text-generation',\n",
    "    'TOKEN_CLASSIFICATION':'token-classification',\n",
    "    'TRANSLATION':'translation',\n",
    "    'ZERO_SHOT_CLASSIFICATION':'zero-shot-classification',\n",
    "    'CONVERSATIONAL':'conversational',\n",
    "    'TEXT_TO_SPEECH':'text-to-speech',\n",
    "    'AUTOMATIC_SPEECH_RECOGNITION':'automatic-speech-recognition',\n",
    "    'AUDIO_SOURCE_SEPERATION':'audio-source-seperation',\n",
    "    'VOICE_ACTIVITY_DETECTION':'voice-activity-detection'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "mk_class('HF_TASKS', **_hf_tasks,\n",
    "        doc=\"A list of all HuggingFace tasks for valid API lookup as attribtues to get tab-completion and typo-proofing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_all_ = ['HF_TASKS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"HF_TASKS\" class=\"doc_header\"><code>class</code> <code>HF_TASKS</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>HF_TASKS</code>(**\\*`args`**, **\\*\\*`kwargs`**)\n",
       "\n",
       "A list of all HuggingFace tasks for valid API lookup as attribtues to get tab-completion and typo-proofing"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(HF_TASKS, title_level=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible tasks:\n",
      "* fill-mask\n",
      "* question-answering\n",
      "* summarization\n",
      "* table-question-answering\n",
      "* text-classification\n",
      "* text-generation\n",
      "* text2text-generation\n",
      "* token-classification\n",
      "* translation\n",
      "* zero-shot-classification\n",
      "* conversational\n",
      "* text-to-speech\n",
      "* automatic-speech-recognition\n",
      "* audio-source-seperation\n",
      "* voice-activity-detection\n"
     ]
    }
   ],
   "source": [
    "#hide_input\n",
    "print(f'Possible tasks:')\n",
    "for val in _hf_tasks.values():\n",
    "    print(f'* {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "_flair_tasks = {\n",
    "    'NAMED_ENTITY_RECOGNITION':'ner',\n",
    "    'PHRASE_CHUNKING':'chunk',\n",
    "    'VERB_DISAMBIGUATION':'frame',\n",
    "    'PART_OF_SPEECH_TAGGING':'pos',\n",
    "    'UNIVERSAL_PART_OF_SPEECH_TAGGING':'upos',\n",
    "    'EMBEDDINGS':'embeddings',\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "mk_class('FLAIR_TASKS', **_flair_tasks,\n",
    "        doc=\"A list of all Flair tasks for valid API lookup as attribtues to get tab-completion and typo-proofing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_all_ = ['FLAIR_TASKS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"FLAIR_TASKS\" class=\"doc_header\"><code>class</code> <code>FLAIR_TASKS</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>FLAIR_TASKS</code>(**\\*`args`**, **\\*\\*`kwargs`**)\n",
       "\n",
       "A list of all Flair tasks for valid API lookup as attribtues to get tab-completion and typo-proofing"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(FLAIR_TASKS, title_level=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible tasks:\n",
      "* ner\n",
      "* chunk\n",
      "* frame\n",
      "* pos\n",
      "* upos\n",
      "* embeddings\n"
     ]
    }
   ],
   "source": [
    "#hide_input\n",
    "print(f'Possible tasks:')\n",
    "for val in _flair_tasks.values():\n",
    "    print(f'* {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HFModelResult:\n",
    "    \"\"\"\n",
    "    A very basic class for storing a HuggingFace model returned through an API request\n",
    "    \n",
    "    They have 4 properties:\n",
    "      - `name`: The `modelId` from the `modelInfo`. This also includes the model author's name, such as \"IlyaGusev/mbart_ru_sum_gazeta\"\n",
    "      - `tags`: Any tags that were included in `HugginFace` in relation to the model. \n",
    "      - `tasks`: These are the tasks dictated for the model.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_info: ModelInfo):\n",
    "        self.info = model_info\n",
    "        \n",
    "    def __repr__(self): return f'Model Name: {self.name}, Tasks: [' + ', '.join(self.tasks) + ']'\n",
    "    \n",
    "    @property\n",
    "    def name(self): return self.info.modelId\n",
    "\n",
    "    @property\n",
    "    def tags(self): return self.info.tags\n",
    "    \n",
    "    @property\n",
    "    def tasks(self): \n",
    "        if self.info.pipeline_tag:\n",
    "            all_tasks = [self.info.pipeline_tag]\n",
    "            for tag in self.tags:\n",
    "                if (tag in _hf_tasks.values()) and (tag not in all_tasks):\n",
    "                    all_tasks += [tag]\n",
    "        else: all_tasks = []\n",
    "        all_tasks.sort()\n",
    "        return all_tasks\n",
    "    \n",
    "    def to_dict(self): \n",
    "        \"\"\"\n",
    "        Returns `HFModelResult` as a dictionary with the keys:\n",
    "          * `model_name`\n",
    "          * `tags`\n",
    "          * `tasks`\n",
    "          * `model_info`\n",
    "        \"\"\"\n",
    "        return {'model_name':self.name, 'tags':self.tags, 'tasks':self.tasks, 'model_info':self.info}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"HFModelResult\" class=\"doc_header\"><code>class</code> <code>HFModelResult</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>HFModelResult</code>(**`model_info`**:`ModelInfo`)\n",
       "\n",
       "A very basic class for storing a HuggingFace model returned through an API request\n",
       "\n",
       "They have 4 properties:\n",
       "  - `name`: The `modelId` from the `modelInfo`. This also includes the model author's name, such as \"IlyaGusev/mbart_ru_sum_gazeta\"\n",
       "  - `tags`: Any tags that were included in `HugginFace` in relation to the model. \n",
       "  - `tasks`: These are the tasks dictated for the model."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(HFModelResult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look inside of `modelInfo.pipeline_tag` as well as the `tags` for if there is any overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"HFModelResult.to_dict\" class=\"doc_header\"><code>HFModelResult.to_dict</code><a href=\"__main__.py#L35\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>HFModelResult.to_dict</code>()\n",
       "\n",
       "Returns [`HFModelResult`](/adaptnlpmodel_hub.html#HFModelResult) as a dictionary with the keys:\n",
       "  * `model_name`\n",
       "  * `tags`\n",
       "  * `tasks`\n",
       "  * `model_info`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(HFModelResult.to_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HFModelHub:\n",
    "    \"\"\"\n",
    "    A class for interacting with the HF model hub API, and searching for models by name or task\n",
    "    \n",
    "    Can optionally include your HuggingFace login for authorized access (but is not required)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, username=None, password=None):\n",
    "        self.api = HfApi()\n",
    "        if username and password:\n",
    "            self.token = self.api.login(username, password)\n",
    "        elif username or password:\n",
    "            print('Only a username or password was entered. You should include both to get authorized access')\n",
    "        \n",
    "    def _format_results(self, results:list, as_dict=False, user_uploaded=False) -> (List[HFModelResult], Dict[str, HFModelResult]):\n",
    "        \"\"\"\n",
    "        Takes raw HuggingFace API results and makes them easier to read and work with\n",
    "        \"\"\"\n",
    "        results = apply(HFModelResult, results)\n",
    "        if not user_uploaded:\n",
    "            results = [r for r in results if '/' not in r.name]\n",
    "        if as_dict:\n",
    "            dicts = apply(Self.to_dict(), results)\n",
    "            results = {m['model_name'] : m for m in dicts}\n",
    "        return results\n",
    "        \n",
    "    def search_model_by_task(self, task:str, as_dict=False, user_uploaded=False) -> (List[HFModelResult], Dict[str, HFModelResult]):\n",
    "        \"\"\"\n",
    "        Searches HuggingFace Model API for all pretrained models relating to `task` and returns a list of HFModelResults\n",
    "        \n",
    "        Optionally can return all models as a `dict` rather than a list\n",
    "        \n",
    "        If `user_uploaded` is False, will only return models originating in HuggingFace (such as distilgpt2)\n",
    "              \n",
    "        Usage:\n",
    "        ```python\n",
    "          hub = HFModelHubSearch()\n",
    "          hub.search_model_by_task('summarization')\n",
    "          # OR #\n",
    "          hub.search_model_by_task(HF_TASKS.SUMMARIZATION)\n",
    "      ```\n",
    "        \"\"\"\n",
    "        if task not in _hf_tasks.values():\n",
    "            raise ValueError(f'''`{task}` is not a valid task. \n",
    "            \n",
    "            Please choose a valid one available from HuggingFace: (https://huggingface.co/transformers/task_summary.html) \n",
    "            Or with the `HF_TASKS` object''')\n",
    "        models = self.api.list_models(task)\n",
    "        return self._format_results(models, as_dict, user_uploaded)\n",
    "    \n",
    "    def search_model_by_name(self, name:str, as_dict=False, user_uploaded=False) -> (List[HFModelResult], Dict[str, HFModelResult]):\n",
    "        \"\"\"\n",
    "        Searches HuggingFace Model API for all pretrained models containing `name` and returns a list of HFModelResults\n",
    "        \n",
    "        Optionally can return all models as `dict` rather than a list\n",
    "        \n",
    "        If `user_uploaded` is False, will only return models originating from HuggingFace (such as distilgpt2)\n",
    "        \n",
    "        Usage:\n",
    "          ```python\n",
    "          hub = HFModelHubSearch()\n",
    "          hub.search_model_by_name('gpt2')\n",
    "          ```\n",
    "        \"\"\"\n",
    "        if user_uploaded:\n",
    "            models = self.api.list_models()\n",
    "            models = self._format_results(models, as_dict, user_uploaded)\n",
    "            models = [m for m in models if name in m.name]\n",
    "            \n",
    "        else:\n",
    "            models = self.api.list_models(name)\n",
    "            models = self._format_results(models, as_dict, user_uploaded)\n",
    "        return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model search hub creates a friendly end-user API when searching through HuggingFace (and Flair, as we will see later). Usage is extremely simple as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"HFModelHub.search_model_by_task\" class=\"doc_header\"><code>HFModelHub.search_model_by_task</code><a href=\"__main__.py#L28\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>HFModelHub.search_model_by_task</code>(**`task`**:`str`, **`as_dict`**=*`False`*, **`user_uploaded`**=*`False`*)\n",
       "\n",
       "  Searches HuggingFace Model API for all pretrained models relating to `task` and returns a list of HFModelResults\n",
       "  \n",
       "  Optionally can return all models as a `dict` rather than a list\n",
       "  \n",
       "  If `user_uploaded` is False, will only return models originating in HuggingFace (such as distilgpt2)\n",
       "        \n",
       "  Usage:\n",
       "  ```python\n",
       "    hub = HFModelHubSearch()\n",
       "    hub.search_model_by_task('summarization')\n",
       "    # OR #\n",
       "    hub.search_model_by_task(HF_TASKS.SUMMARIZATION)\n",
       "```\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(HFModelHub.search_model_by_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will return a list of models available for a particular class. A few usage examples are below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model Name: t5-11b, Tasks: [summarization, text2text-generation, translation],\n",
       " Model Name: t5-3b, Tasks: [summarization, text2text-generation, translation],\n",
       " Model Name: t5-base, Tasks: [summarization, text2text-generation, translation],\n",
       " Model Name: t5-large, Tasks: [summarization, text2text-generation, translation],\n",
       " Model Name: t5-small, Tasks: [summarization, text2text-generation, translation]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hub = HFModelHub()\n",
    "models = hub.search_model_by_task('summarization', user_uploaded=False, as_dict=False)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(models[0].name, 't5-11b')\n",
    "test_eq(models[0].tasks, ['summarization', 'text2text-generation', 'translation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also search for any user-uploaded models from the community too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model Name: t5-11b, Tasks: [summarization, text2text-generation, translation],\n",
       " Model Name: t5-3b, Tasks: [summarization, text2text-generation, translation],\n",
       " Model Name: t5-base, Tasks: [summarization, text2text-generation, translation],\n",
       " Model Name: t5-large, Tasks: [summarization, text2text-generation, translation],\n",
       " Model Name: t5-small, Tasks: [summarization, text2text-generation, translation],\n",
       " Model Name: Callidior/bert2bert-base-arxiv-titlegen, Tasks: [summarization, text2text-generation],\n",
       " Model Name: IlyaGusev/mbart_ru_sum_gazeta, Tasks: [summarization, text2text-generation],\n",
       " Model Name: IlyaGusev/rubert_telegram_headlines, Tasks: [summarization, text2text-generation],\n",
       " Model Name: LeoCordoba/beto2beto-mlsum, Tasks: [summarization, text2text-generation],\n",
       " Model Name: LeoCordoba/mt5-small-mlsum, Tasks: [summarization, text2text-generation]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = hub.search_model_by_task('summarization', user_uploaded=True)\n",
    "models[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "model = models[5]\n",
    "author, name = model.name.split('/')\n",
    "test_eq(author, 'Callidior')\n",
    "test_eq(name, 'bert2bert-base-arxiv-titlegen')\n",
    "test_eq(model.tasks, ['summarization', 'text2text-generation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also cases where a `dict` may be easier to work with (perhaps utilizing a network API, or ease of use for some). We can instead return a dictionary of `HFModelResult` objects too by passing `as_dict=True` to any search call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 't5-11b',\n",
       " 'tags': ['pytorch',\n",
       "  'tf',\n",
       "  't5',\n",
       "  'lm-head',\n",
       "  'seq2seq',\n",
       "  'en',\n",
       "  'fr',\n",
       "  'ro',\n",
       "  'de',\n",
       "  'dataset:c4',\n",
       "  'arxiv:1910.10683',\n",
       "  'summarization',\n",
       "  'translation',\n",
       "  'license:apache-2.0',\n",
       "  'text2text-generation'],\n",
       " 'tasks': ['summarization', 'text2text-generation', 'translation'],\n",
       " 'model_info': <huggingface_hub.hf_api.ModelInfo at 0x7f8d37be44c0>}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = hub.search_model_by_task('summarization', as_dict=True);\n",
    "models['t5-11b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(models.keys(), ['t5-11b', 't5-3b', 't5-base', 't5-large', 't5-small'])\n",
    "test_eq(models['t5-11b'].keys(), ['model_name', 'tags', 'tasks', 'model_info'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will return a dictionary of the name, the HuggingFace tags affiliated with the model, the dictated tasks, and an instance of `huggingface_hub`'s `ModelInfo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"HFModelHub.search_model_by_name\" class=\"doc_header\"><code>HFModelHub.search_model_by_name</code><a href=\"__main__.py#L52\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>HFModelHub.search_model_by_name</code>(**`name`**:`str`, **`as_dict`**=*`False`*, **`user_uploaded`**=*`False`*)\n",
       "\n",
       "Searches HuggingFace Model API for all pretrained models containing `name` and returns a list of HFModelResults\n",
       "\n",
       "Optionally can return all models as `dict` rather than a list\n",
       "\n",
       "If `user_uploaded` is False, will only return models originating from HuggingFace (such as distilgpt2)\n",
       "\n",
       "Usage:\n",
       "  ```python\n",
       "  hub = HFModelHubSearch()\n",
       "  hub.search_model_by_name('gpt2')\n",
       "  ```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(HFModelHub.search_model_by_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `search_model_by_name` you're allowed a bit more freedom in what you wish to search for. `search_model_by_name` downloads the entire list of models from `HuggingFace` then performs partial string matching. As a result you can search for all models by a particular user by doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model Name: Callidior/bert2bert-base-arxiv-titlegen, Tasks: [summarization]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hub.search_model_by_name('Callidior', user_uploaded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or (as implied by the function name) any model type itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model Name: 850886470/xxy_gpt2_chinese, Tasks: [],\n",
       " Model Name: Fabby/gpt2-english-light-novel-titles, Tasks: [],\n",
       " Model Name: Ferch423/gpt2-small-portuguese-wikipediabio, Tasks: [text-generation],\n",
       " Model Name: GroNLP/gpt2-medium-dutch-embeddings, Tasks: [text-generation],\n",
       " Model Name: GroNLP/gpt2-medium-italian-embeddings, Tasks: [text-generation]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hub.search_model_by_name('gpt2', user_uploaded=True)[5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "# Flair models originating from:\n",
    "# https://github.com/flairNLP/flair/blob/master/flair/models/text_classification_model.py#L483\n",
    "# and: https://github.com/flairNLP/flair/blob/master/flair/models/sequence_tagger_model.py#L1053\n",
    "# and: https://github.com/flairNLP/flair/blob/master/flair/embeddings/token.py#L406\n",
    "_flair_models = {\n",
    "    'de-offensive-language' : ['text-classification'],\n",
    "    'sentiment' : ['text-classification'],\n",
    "    'en-sentiment' : ['text-classification'],\n",
    "    'sentiment-fast' : ['text-classification'],\n",
    "    'communicative-functions' : ['text-classification'],\n",
    "    'tars-base' : ['text-classification'],\n",
    "    # English Named Entity Recognition Models (NER)\n",
    "    'ner' : ['token-classification'],\n",
    "    'ner-pooled' : ['token-classification'],\n",
    "    'ner-fast' : ['token-classification'],\n",
    "    'ner-ontonotes' : ['token-classification'],\n",
    "    'ner-ontonotes-fast' : ['token-classification'],\n",
    "    # Multilingual NER models\n",
    "    'ner-multi' : ['token-classification'],\n",
    "    'multi-ner' : ['token-classification'],\n",
    "    'ner-multi-fast' : ['token-classification'],\n",
    "    # English POS models\n",
    "    'upos' : ['token-classification'],\n",
    "    'upos-fast' : ['token-classification'],\n",
    "    'pos' : ['token-classification'],\n",
    "    'pos-fast' : ['token-classification'],\n",
    "    # Multilingual POS models\n",
    "    'pos-multi' : ['token-classification'],\n",
    "    'multi-pos' : ['token-classification'],\n",
    "    'pos-multi-fast' : ['token-classification'],\n",
    "    'multi-pos-fast' : ['token-classification'],\n",
    "    # English SRL models\n",
    "    'frame' : ['token-classification'],\n",
    "    'frame-fast' : ['token-classification'],\n",
    "    # English chunking models\n",
    "    'chunk' : ['token-classification'],\n",
    "    'chunk-fast' : ['token-classification'],\n",
    "    # Danish models\n",
    "    'da-pos' : ['token-classification'],\n",
    "    'da-ner' : ['token-classification'],\n",
    "    # German models\n",
    "    'de-pos' : ['token-classification'],\n",
    "    'de-pos-tweets' : ['token-classification'],\n",
    "    'de-ner' : ['token-classification'],\n",
    "    'de-ner-germeval' : ['token-classification'],\n",
    "    'de-ler' : ['token-classification'],\n",
    "    'de-ner-legal' : ['token-classification'],\n",
    "    # French models\n",
    "    'fr-ner' : ['token-classification'],\n",
    "    # Dutch models\n",
    "    'nl-ner' : ['token-classification'],\n",
    "    'nl-ner-rnn' : ['token-classification'],\n",
    "    # Malayalam models\n",
    "    'ml-pos' : ['token-classification'],\n",
    "    'ml-upos' : ['token-classification'],\n",
    "    # Portuguese models\n",
    "    'pt-pos-clinical' : ['token-classification'],\n",
    "    # Keyphrase models\n",
    "    'keyphrase' : ['token-classification'],\n",
    "    'negation-speculation' : ['token-classification'],\n",
    "    # Biomedical\n",
    "    'hunflair-paper-cellline' : ['token-classification'],\n",
    "    'hunflair-paper-chemical' : ['token-classification'],\n",
    "    'hunflair-paper-disease' : ['token-classification'],\n",
    "    'hunflair-paper-gene' : ['token-classification'],\n",
    "    'hunflair-paper-species' : ['token-classification'],\n",
    "    'hunflair-cellline' : ['token-classification'],\n",
    "    'hunflair-chemical' : ['token-classification'],\n",
    "    'hunflair-disease' : ['token-classification'],\n",
    "    'hunflair-gene' : ['token-classification'],\n",
    "    'hunflair-species' : ['token-classification'],\n",
    "    # Embeddings\n",
    "    # multilingual models\n",
    "    \"multi-forward\":['embeddings'],\n",
    "    \"multi-backward\":['embeddings'],\n",
    "    \"multi-v0-forward\":['embeddings'],\n",
    "    \"multi-v0-backward\":['embeddings'],\n",
    "    \"multi-forward-fast\":['embeddings'],\n",
    "    \"multi-backward-fast\":['embeddings'],\n",
    "    # English models\n",
    "    \"en-forward\":['embeddings'],\n",
    "    \"en-backward\":['embeddings'],\n",
    "    \"en-forward-fast\":['embeddings'],\n",
    "    \"en-backward-fast\":['embeddings'],\n",
    "    \"news-forward\":['embeddings'],\n",
    "    \"news-backward\":['embeddings'],\n",
    "    \"news-forward-fast\":['embeddings'],\n",
    "    \"news-backward-fast\":['embeddings'],\n",
    "    \"mix-forward\":['embeddings'],\n",
    "    \"mix-backward\":['embeddings'],\n",
    "    # Arabic\n",
    "    \"ar-forward\":['embeddings'],\n",
    "    \"ar-backward\":['embeddings'],\n",
    "    # Bulgarian\n",
    "    \"bg-forward-fast\":['embeddings'],\n",
    "    \"bg-backward-fast\":['embeddings'],\n",
    "    \"bg-forward\":['embeddings'],\n",
    "    \"bg-backward\":['embeddings'],\n",
    "    # Czech\n",
    "    \"cs-forward\":['embeddings'],\n",
    "    \"cs-backward\":['embeddings'],\n",
    "    \"cs-v0-forward\":['embeddings'],\n",
    "    \"cs-v0-backward\":['embeddings'],\n",
    "    # Danish\n",
    "    \"da-forward\":['embeddings'],\n",
    "    \"da-backward\":['embeddings'],\n",
    "    # German\n",
    "    \"de-forward\":['embeddings'],\n",
    "    \"de-backward\":['embeddings'],\n",
    "    \"de-historic-ha-forward\":['embeddings'],\n",
    "    \"de-historic-ha-backward\":['embeddings'],\n",
    "    \"de-historic-wz-forward\":['embeddings'],\n",
    "    \"de-historic-wz-backward\":['embeddings'],\n",
    "    \"de-historic-rw-forward\":['embeddings'],\n",
    "    \"de-historic-rw-backward\":['embeddings'],\n",
    "    # Spanish\n",
    "    \"es-forward\":['embeddings'],\n",
    "    \"es-backward\":['embeddings'],\n",
    "    \"es-forward-fast\":['embeddings'],\n",
    "    \"es-backward-fast\":['embeddings'],\n",
    "    # Basque\n",
    "    \"eu-forward\":['embeddings'],\n",
    "    \"eu-backward\":['embeddings'],\n",
    "    \"eu-v1-forward\":['embeddings'],\n",
    "    \"eu-v1-backward\":['embeddings'],\n",
    "    \"eu-v0-forward\":['embeddings'],\n",
    "    \"eu-v0-backward\":['embeddings'],\n",
    "    # Persian\n",
    "    \"fa-forward\":['embeddings'],\n",
    "    \"fa-backward\":['embeddings'],\n",
    "    # Finnish\n",
    "    \"fi-forward\":['embeddings'],\n",
    "    \"fi-backward\":['embeddings'],\n",
    "    # French\n",
    "    \"fr-forward\":['embeddings'],\n",
    "    \"fr-backward\":['embeddings'],\n",
    "    # Hebrew\n",
    "    \"he-forward\":['embeddings'],\n",
    "    \"he-backward\":['embeddings'],\n",
    "    # Hindi\n",
    "    \"hi-forward\":['embeddings'],\n",
    "    \"hi-backward\":['embeddings'],\n",
    "    # Croatian\n",
    "    \"hr-forward\":['embeddings'],\n",
    "    \"hr-backward\":['embeddings'],\n",
    "    # Indonesian\n",
    "    \"id-forward\":['embeddings'],\n",
    "    \"id-backward\":['embeddings'],\n",
    "    # Italian\n",
    "    \"it-forward\":['embeddings'],\n",
    "    \"it-backward\":['embeddings'],\n",
    "    # Japanese\n",
    "    \"ja-forward\":['embeddings'],\n",
    "    \"ja-backward\":['embeddings'],\n",
    "    # Malayalam\n",
    "    \"ml-forward\":['embeddings'],\n",
    "    \"ml-backward\":['embeddings'],\n",
    "    # Dutch\n",
    "    \"nl-forward\":['embeddings'],\n",
    "    \"nl-backward\":['embeddings'],\n",
    "    \"nl-v0-forward\":['embeddings'],\n",
    "    \"nl-v0-backward\":['embeddings'],\n",
    "    # Norwegian\n",
    "    \"no-forward\":['embeddings'],\n",
    "    \"no-backward\":['embeddings'],\n",
    "    # Polish\n",
    "    \"pl-forward\":['embeddings'],\n",
    "    \"pl-backward\":['embeddings'],\n",
    "    \"pl-opus-forward\":['embeddings'],\n",
    "    \"pl-opus-backward\":['embeddings'],\n",
    "    # Portuguese\n",
    "    \"pt-forward\":['embeddings'],\n",
    "    \"pt-backward\":['embeddings'],\n",
    "    # Pubmed\n",
    "    \"pubmed-forward\":['embeddings'],\n",
    "    \"pubmed-backward\":['embeddings'],\n",
    "    \"pubmed-2015-forward\":['embeddings'],\n",
    "    \"pubmed-2015-backward\":['embeddings'],\n",
    "    # Slovenian\n",
    "    \"sl-forward\":['embeddings'],\n",
    "    \"sl-backward\":['embeddings'],\n",
    "    \"sl-v0-forward\":['embeddings'],\n",
    "    \"sl-v0-backward\":['embeddings'],\n",
    "    # Swedish\n",
    "    \"sv-forward\":['embeddings'],\n",
    "    \"sv-backward\":['embeddings'],\n",
    "    \"sv-v0-forward\":['embeddings'],\n",
    "    \"sv-v0-backward\":['embeddings'],\n",
    "    # Tamil\n",
    "    \"ta-forward\":['embeddings'],\n",
    "    \"ta-backward\":['embeddings'],\n",
    "    # CLEF HIPE Shared task\n",
    "    \"de-impresso-hipe-v1-forward\":['embeddings'],\n",
    "    \"de-impresso-hipe-v1-backward\":['embeddings'],\n",
    "    \"en-impresso-hipe-v1-forward\":['embeddings'],\n",
    "    \"en-impresso-hipe-v1-backward\":['embeddings'],\n",
    "    \"fr-impresso-hipe-v1-forward\":['embeddings'],\n",
    "    \"fr-impresso-hipe-v1-backward\":['embeddings']    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "FLAIR_MODELS = [ModelInfo(f'flairNLP/{key}', pipeline_tag=val[0]) for key,val in _flair_models.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flair has a series of extra models available for use that are not available through HuggingFace such as `sentiment`, `communicative-functions`, and more. `FLAIR_MODELS` is a convience holder for quick lookup of these models (as no such list is easily available currently). When shown as results on the API they will be given the same `flair` prefix for convience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FlairModelResult(HFModelResult):\n",
    "    \"\"\"\n",
    "    A version of `HFModelResult` for Flair specifically. \n",
    "    \n",
    "    Includes which backend the model was found (such as on HuggingFace or Flair's private model list)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_info: ModelInfo):\n",
    "        if 'flairNLP' in model_info.modelId:\n",
    "            self.from_hf = False\n",
    "        else:\n",
    "            self.from_hf = True\n",
    "        super().__init__(model_info)\n",
    "        \n",
    "    def __repr__(self): return f'Model Name: {self.name.replace(\"flairNLP\", \"flair\")}, Tasks: [' + ', '.join(self.tasks) + ']' + f', Source: {self.source}'\n",
    "    \n",
    "    @property\n",
    "    def source(self):\n",
    "        if self.from_hf: return \"HuggingFace Model Hub\"\n",
    "        else: return \"Flair's Private Model Hub\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FlairModelHub:\n",
    "    \"\"\"\n",
    "    A class for interacting with the HF model hub API, and searching for Flair models by name or task\n",
    "    \n",
    "    Can optionally include your HuggingFace login for authorized access (but is not required)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, username=None, password=None):\n",
    "        self.api = HfApi()\n",
    "        if username and password:\n",
    "            self.token = self.api.login(username, password)\n",
    "        elif username or password:\n",
    "            print('Only a username or password was entered. You should include both to get authorized access')\n",
    "        self.models = self.api.list_models('flair') + FLAIR_MODELS\n",
    "        \n",
    "    def _format_results(self, results:list, as_dict=False, user_uploaded=False) -> (List[HFModelResult], Dict[str, HFModelResult]):\n",
    "        \"\"\"\n",
    "        Takes raw HuggingFace API results and makes them easier to read and work with\n",
    "        \"\"\"\n",
    "        results = apply(FlairModelResult, results)\n",
    "        if not user_uploaded:\n",
    "            results = [r for r in results if 'flair/' in r.name or 'flairNLP/' in r.name]\n",
    "        if as_dict:\n",
    "            dicts = apply(Self.to_dict(), results)\n",
    "            results = {m['model_name'] : m for m in dicts}\n",
    "        return results\n",
    "    \n",
    "    def search_model_by_name(self, name:str, as_dict=False, user_uploaded=False) -> (List[HFModelResult], Dict[str, HFModelResult]):\n",
    "        \"\"\"\n",
    "        Searches HuggingFace Model API for all flair models containing `name` and returns a list of `HFModelResults`\n",
    "        \n",
    "        Optionally can return all models as `dict` rather than a list\n",
    "        \n",
    "        If `user_uploaded` is False, will only return models originating from Flair (such as flair/chunk-english-fast)\n",
    "        \n",
    "        Usage:\n",
    "          ```python\n",
    "          hub = FlairModelHubSearch()\n",
    "          hub.search_model_by_name('flair/chunk-english-fast')\n",
    "          ```\n",
    "        \"\"\"\n",
    "        models = [m for m in self.models if name in m.modelId]\n",
    "        return self._format_results(models, as_dict, user_uploaded)\n",
    "    \n",
    "    def search_model_by_task(self, task:str, as_dict=False, user_uploaded=False) -> (List[HFModelResult], Dict[str, HFModelResult]):\n",
    "        \"\"\"\n",
    "        Searches HuggingFace Model API for all flair models for `task` and returns a list of `HFModelResults`\n",
    "        \n",
    "        Optionally can return all models as `dict` rather than a list\n",
    "        \n",
    "        If `user_uploaded` is False, will only return models originating from Flair (such as flair/chunk-english-fast)\n",
    "        \n",
    "        Usage:\n",
    "        ```python\n",
    "            hub = FlairModelHubSearch()\n",
    "            hub.search_model_by_task('ner')\n",
    "            # OR: #\n",
    "            hub.search_model_by_task(FLAIR_TASKS.NAMED_ENTITY_RECOGNITION)\n",
    "        ```\n",
    "        \"\"\"\n",
    "        if (task not in _flair_tasks.values()) and (task != ''):\n",
    "            raise ValueError(f'''`{task}` is not a valid task. \n",
    "            \n",
    "            Please choose a valid one available from Flair: (https://huggingface.co/flair) \n",
    "            Or with the `FLAIR_TASKS` object''')\n",
    "        models = [m for m in self.models if task in m.modelId or task == m.pipeline_tag]\n",
    "        return self._format_results(models, as_dict, user_uploaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"FlairModelHub\" class=\"doc_header\"><code>class</code> <code>FlairModelHub</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>FlairModelHub</code>(**`username`**=*`None`*, **`password`**=*`None`*)\n",
       "\n",
       "A class for interacting with the HF model hub API, and searching for Flair models by name or task\n",
       "\n",
       "Can optionally include your HuggingFace login for authorized access (but is not required)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(FlairModelHub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`FlairModelHub` is extremely similar to `HFModelHub`, with the two differences being that it will **only** return `Flair` models, and it has access to the *other* Flair models available that can't be accessed through the HuggingFace model hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub = FlairModelHub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"FlairModelHub.search_model_by_name\" class=\"doc_header\"><code>FlairModelHub.search_model_by_name</code><a href=\"__main__.py#L29\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>FlairModelHub.search_model_by_name</code>(**`name`**:`str`, **`as_dict`**=*`False`*, **`user_uploaded`**=*`False`*)\n",
       "\n",
       "Searches HuggingFace Model API for all flair models containing `name` and returns a list of `HFModelResults`\n",
       "\n",
       "Optionally can return all models as `dict` rather than a list\n",
       "\n",
       "If `user_uploaded` is False, will only return models originating from Flair (such as flair/chunk-english-fast)\n",
       "\n",
       "Usage:\n",
       "  ```python\n",
       "  hub = FlairModelHubSearch()\n",
       "  hub.search_model_by_name('flair/chunk-english-fast')\n",
       "  ```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(FlairModelHub.search_model_by_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`seach_model_by_name` will also let you search for models without needing the `flair` prefix, such as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model Name: flair/sentiment, Tasks: [text-classification], Source: Flair's Private Model Hub,\n",
       " Model Name: flair/en-sentiment, Tasks: [text-classification], Source: Flair's Private Model Hub,\n",
       " Model Name: flair/sentiment-fast, Tasks: [text-classification], Source: Flair's Private Model Hub]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hub.search_model_by_name('sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(0, len(hub.search_model_by_name('gpt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"FlairModelHub.search_model_by_task\" class=\"doc_header\"><code>FlairModelHub.search_model_by_task</code><a href=\"__main__.py#L46\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>FlairModelHub.search_model_by_task</code>(**`task`**:`str`, **`as_dict`**=*`False`*, **`user_uploaded`**=*`False`*)\n",
       "\n",
       "Searches HuggingFace Model API for all flair models for `task` and returns a list of `HFModelResults`\n",
       "\n",
       "Optionally can return all models as `dict` rather than a list\n",
       "\n",
       "If `user_uploaded` is False, will only return models originating from Flair (such as flair/chunk-english-fast)\n",
       "\n",
       "Usage:\n",
       "```python\n",
       "    hub = FlairModelHubSearch()\n",
       "    hub.search_model_by_task('ner')\n",
       "    # OR: #\n",
       "    hub.search_model_by_task(FLAIR_TASKS.NAMED_ENTITY_RECOGNITION)\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(FlairModelHub.search_model_by_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have a `FLAIR_TASKS` object declared earlier, we can utilize it when searching for models by a task. Similar to `search_model_by_name` you should not include `flair/` in your search results, and instead search through the task key such as `ner` or `FLAIR_TASKS.NAMED_ENTITY_RECOGNITION`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "models = hub.search_model_by_task('ner')\n",
    "models = [m for m in models if m.source == \"Flair's Private Model Hub\"]\n",
    "test_eq(len(models), 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
