{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to AdaptNLP\n",
    "> A high level framework and library for running, training, and deploying state-of-the-art Natural Language Processing (NLP) models for end to end tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <a href=\"https://github.com/Novetta/adaptnlp\"> <img src=\"https://raw.githubusercontent.com/novetta/adaptnlp/master/docs/assets/images/company_logo.png\" width=\"400\"/></a>\n",
    "</p>\n",
    "\n",
    "![CI](https://github.com/Novetta/adaptnlp/workflows/CI/badge.svg) \n",
    "[![PyPI](https://img.shields.io/pypi/v/adaptnlp?color=blue&label=pypi%20version)](https://pypi.org/project/adaptnlp/#description)\n",
    "\n",
    "\n",
    "AdaptNLP allows users ranging from beginner python coders to experienced machine learning engineers to leverage\n",
    "state-of-the-art NLP models and training techniques in one easy-to-use python package.\n",
    "\n",
    "Built atop Zalando Research's Flair and Hugging Face's Transformers library, AdaptNLP provides Machine\n",
    "Learning Researchers and Scientists a modular and **adaptive** approach to a variety of NLP tasks with an\n",
    "**Easy** API for training, inference, and deploying NLP-based microservices.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "  - **[Full Guides and API Documentation](https://novetta.github.io/adaptnlp)**\n",
    "  - Built with [nbdev](https://github.com/fastai/nbdev)\n",
    "  - Jupyter Notebook [Cookbooks](https://novetta.github.io/adaptnlp/cookbook)\n",
    "  - Unified inference API for NLP Tasks with SOTA Pretrained Models (Adaptable with Flair and Transformer's Models)\n",
    "    - Token Tagging \n",
    "    - Sequence Classification\n",
    "    - Embeddings\n",
    "    - Question Answering\n",
    "    - Summarization\n",
    "    - Translation\n",
    "    - Text Generation\n",
    "    - <em> More in development </em>\n",
    "  - Training interface\n",
    "    - Integration with the `Datasets` and `fastai` library for an approachable data API as well as fine-tuning API, making use of state-of-the-art practices\n",
    "    - Integration with Transformer's Trainer Module for fast and easy transfer learning with custom datasets\n",
    "    - Fine-tuning Transformer's language models and task-specific predictive heads like Flair's `SequenceClassifier`\n",
    "  - Deployment interface:\n",
    "    - [Rapid NLP Model Deployment](https://github.com/Novetta/adaptnlp/tree/master/rest) with Sebastián's [FastAPI](https://github.com/tiangolo/fastapi) Framework\n",
    "    - Containerized FastAPI app\n",
    "    - Immediately deploy any custom trained Flair or AdaptNLP model\n",
    "  - [Dockerizing AdaptNLP with GPUs](https://hub.docker.com/r/novetta/adaptnlp)\n",
    "    - Easily build and run AdaptNLP containers leveraging NVIDIA GPUs with Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Start\n",
    "\n",
    "#### Virtual Environment\n",
    "To avoid dependency clustering and issues, it would be wise to install AdaptNLP in a virtual environment.\n",
    "To create a new python 3.7+ virtual environment, run this command and then activate it however your operating\n",
    "system specifies:\n",
    "\n",
    "```\n",
    "python -m venv venv-adaptnlp\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements and Installation for Windows\n",
    "\n",
    "#### PyTorch Install\n",
    "PyTorch needs to be manually installed on Windows environments. If it's not already installed, proceed to http://pytorch.org/get-started/locally to select your preferences and then run the given install command. Note that the current version of PyTorch we use relies on cuda 10.1.\n",
    "\n",
    "#### AdaptNLP Install\n",
    "Install using pip:\n",
    "```\n",
    "pip install adaptnlp\n",
    "```\n",
    "\n",
    "If you want to work on AdaptNLP, `pip install adaptnlp[dev]` will install its development tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples and General Use\n",
    "\n",
    "Once you have installed AdaptNLP, here are a few examples of what you can run with AdaptNLP modules:\n",
    "\n",
    "### Named Entity Recognition with `EasyTokenTagger`\n",
    "\n",
    "```python\n",
    "from adaptnlp import EasyTokenTagger\n",
    "\n",
    "## Example Text\n",
    "example_text = \"Novetta's headquarters is located in Mclean, Virginia.\"\n",
    "\n",
    "## Load the token tagger module and tag text with the NER model \n",
    "tagger = EasyTokenTagger()\n",
    "sentences = tagger.tag_text(text=example_text, model_name_or_path=\"ner\")\n",
    "\n",
    "## Output tagged token span results in Flair's Sentence object model\n",
    "for sentence in sentences:\n",
    "    for entity in sentence.get_spans(\"ner\"):\n",
    "        print(entity)\n",
    "\n",
    "```\n",
    "\n",
    "### English Sentiment Classifier `EasySequenceClassifier`\n",
    "\n",
    "```python\n",
    "from adaptnlp import EasySequenceClassifier \n",
    "from pprint import pprint\n",
    "\n",
    "## Example Text\n",
    "example_text = \"This didn't work at all\"\n",
    "\n",
    "## Load the sequence classifier module and classify sequence of text with the multi-lingual sentiment model \n",
    "classifier = EasySequenceClassifier()\n",
    "sentences = classifier.tag_text(\n",
    "    text=example_text,\n",
    "    model_name_or_path=\"nlptown/bert-base-multilingual-uncased-sentiment\",\n",
    "    mini_batch_size=1,\n",
    ")\n",
    "\n",
    "## Output labeled text results in Flair's Sentence object model\n",
    "print(\"Tag Score Outputs:\\n\")\n",
    "for sentence in sentences:\n",
    "    pprint({sentence.to_original_text(): sentence.labels})\n",
    "\n",
    "```\n",
    "\n",
    "### Span-based Question Answering `EasyQuestionAnswering`\n",
    "\n",
    "```python\n",
    "from adaptnlp import EasyQuestionAnswering \n",
    "from pprint import pprint\n",
    "\n",
    "## Example Query and Context \n",
    "query = \"What is the meaning of life?\"\n",
    "context = \"Machine Learning is the meaning of life.\"\n",
    "top_n = 5\n",
    "\n",
    "## Load the QA module and run inference on results \n",
    "qa = EasyQuestionAnswering()\n",
    "best_answer, best_n_answers = qa.predict_qa(query=query, context=context, n_best_size=top_n, mini_batch_size=1, model_name_or_path=\"distilbert-base-uncased-distilled-squad\")\n",
    "\n",
    "## Output top answer as well as top 5 answers\n",
    "print(best_answer)\n",
    "pprint(best_n_answers)\n",
    "```\n",
    "\n",
    "### Summarization `EasySummarizer`\n",
    "\n",
    "```python\n",
    "from adaptnlp import EasySummarizer\n",
    "\n",
    "# Text from encyclopedia Britannica on Einstein\n",
    "text = \"\"\"Einstein would write that two “wonders” deeply affected his early years. The first was his encounter with a compass at age five. \n",
    "          He was mystified that invisible forces could deflect the needle. This would lead to a lifelong fascination with invisible forces. \n",
    "          The second wonder came at age 12 when he discovered a book of geometry, which he devoured, calling it his 'sacred little geometry \n",
    "          book'. Einstein became deeply religious at age 12, even composing several songs in praise of God and chanting religious songs on \n",
    "          the way to school. This began to change, however, after he read science books that contradicted his religious beliefs. This challenge \n",
    "          to established authority left a deep and lasting impression. At the Luitpold Gymnasium, Einstein often felt out of place and victimized \n",
    "          by a Prussian-style educational system that seemed to stifle originality and creativity. One teacher even told him that he would \n",
    "          never amount to anything.\"\"\"\n",
    "\n",
    "summarizer = EasySummarizer()\n",
    "\n",
    "# Summarize\n",
    "summaries = summarizer.summarize(text = text, model_name_or_path=\"t5-small\", mini_batch_size=1, num_beams = 4, min_length=0, max_length=100, early_stopping=True)\n",
    "\n",
    "print(\"Summaries:\\n\")\n",
    "for s in summaries:\n",
    "    print(s, \"\\n\")\n",
    "```\n",
    "\n",
    "### Translation `EasyTranslator`\n",
    "```python\n",
    "from adaptnlp import EasyTranslator\n",
    "\n",
    "text = [\"Machine learning will take over the world very soon.\",\n",
    "        \"Machines can speak in many languages.\",]\n",
    "\n",
    "translator = EasyTranslator()\n",
    "\n",
    "# Translate\n",
    "translations = translator.translate(text = text, t5_prefix=\"translate English to German\", model_name_or_path=\"t5-small\", mini_batch_size=1, min_length=0, max_length=100, early_stopping=True)\n",
    "\n",
    "print(\"Translations:\\n\")\n",
    "for t in translations:\n",
    "    print(t, \"\\n\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorials\n",
    "\n",
    "Tutorials of the API are available in the cookbook section of the documentation [here](https://novetta.github.io/adaptnlp/cookbook)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REST Service \n",
    "\n",
    "We use FastAPI for standing up endpoints for serving state-of-the-art NLP models with AdaptNLP.\n",
    "\n",
    "![Swagger Example](https://raw.githubusercontent.com/novetta/adaptnlp/master/docs/assets/images/fastapi-docs.png)\n",
    "\n",
    "The [REST](https://github.com/Novetta/adaptnlp/tree/master/rest) directory contains more detail on deploying a REST API locally or with docker in a very easy and\n",
    "fast way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker\n",
    "\n",
    "AdaptNLP official docker images are up on [Docker Hub](https://hub.docker.com/r/novetta/adaptnlp).\n",
    "\n",
    "Images have AdaptNLP installed from source in developer mode with tutorial notebooks available, and will default to launching a jupyter server from where you can start \n",
    "running the tutorial and workshop notebooks.\n",
    "\n",
    "Images can build with GPU support if NVIDA-Docker is correctly installed.\n",
    "\n",
    "### Pull and Run AdaptNLP Immediately\n",
    "Simply run an image with AdaptNLP installed from source in developer mode by running:\n",
    "```\n",
    "docker run -itp 8888:8888 novetta/adaptnlp:latest\n",
    "```\n",
    "Run an image with AdaptNLP running on GPUs if you have nvidia drivers and nvidia-docker 19.03+ installed:\n",
    "```\n",
    "docker run -itp 8888:8888 --gpus all novetta/adaptnlp:latest\n",
    "```\n",
    "\n",
    "Check `localhost:8888` or `localhost:8888/lab` to access the container notebook servers.\n",
    "\n",
    "\n",
    "### Build\n",
    "\n",
    "Refer to the `docker/` directory and run the following to build and run adaptnlp from the available images.\n",
    "\n",
    "Note: A container with GPUs enabled requires Docker version 19.03+ and nvida-docker installed\n",
    "```\n",
    "# From the repo directory\n",
    "docker build -t novetta/adaptnlp:latest\n",
    "docker run -itp 8888:8888 novetta/adaptnlp:latest\n",
    "```\n",
    "If you want to use CUDA compatible GPUs \n",
    "```\n",
    "docker run -itp 8888:8888 --gpus all achangnovetta/adaptnlp:latest\n",
    "```\n",
    "\n",
    "Check `localhost:8888` or `localhost:8888/lab` to access the container notebook servers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contact\n",
    "\n",
    "Please contact the author Zachary Mueller at zmueller@novetta.com with questions or comments regarding AdaptNLP.\n",
    "\n",
    "Follow  us on Twitter at [@TheZachMueller](https://twitter.com/TheZachMueller) and [@AdaptNLP](https://twitter.com/AdaptNLP) for\n",
    "updates and NLP dialogue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License\n",
    "\n",
    "This project is licensed under the terms of the Apache 2.0 license."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
