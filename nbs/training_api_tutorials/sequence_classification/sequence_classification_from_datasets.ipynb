{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53946cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_slow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca157d7d",
   "metadata": {},
   "source": [
    "# Tutorial&#58; Fine-Tuning Sequence Classification on HuggingFace `Datasets` with MRPC\n",
    "> Tuning a Sequence Classification model on the Microsoft MRPC dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17d8af2",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this tutorial we will be showing an end-to-end example of fine-tuning a Transformer for sequence classification on a custom dataset in HuggingFace `Dataset` format.\n",
    "\n",
    "By the end of this you should be able to:\n",
    "\n",
    "1. Build a dataset with the `TaskDatasets` class, and their DataLoaders\n",
    "2. Build a `SequenceClassificationTuner` quickly, find a good learning rate, and train with the One-Cycle Policy\n",
    "3. Save that model away, to be used with deployment or other HuggingFace libraries\n",
    "4. Apply inference using both the `Tuner` available function as well as with the `EasySequenceClassifier` class within AdaptNLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a44baa5",
   "metadata": {},
   "source": [
    "## Installing the Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce03b17",
   "metadata": {},
   "source": [
    "This tutorial utilizies the latest AdaptNLP version, as well as parts of the `fastai` library. Please run the below code to install them:\n",
    "\n",
    "```python\n",
    "!pip install adaptnlp -U\n",
    "```\n",
    "(or `pip3`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VOwOHNTgyJzY",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbverbose.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86de58d7",
   "metadata": {},
   "source": [
    "## Getting the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a039f4f",
   "metadata": {},
   "source": [
    "First we need a dataset. We will use `dataset`'s `load_dataset` function to quickly generate a raw dataset straight from HuggingFace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8faf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb182fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ef7942",
   "metadata": {},
   "source": [
    "We now have a raw `datasets` dataset, which we can index into:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb649bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': 0,\n",
       " 'label': 1,\n",
       " 'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .',\n",
       " 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01caee30",
   "metadata": {},
   "source": [
    "Now that we have the data downloaded, let's decide on a model to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320caa02",
   "metadata": {},
   "source": [
    "## Picking a Model with the Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170b200d",
   "metadata": {},
   "source": [
    "AdaptNLP has a `HFModelHub` class that allows you to communicate with the HuggingFace Hub and pick a model from it, as well as a namespace `HF_TASKS` class with a list of valid tasks we can search by.\n",
    "\n",
    "Let's try and find one suitable for sequence classification.\n",
    "\n",
    "First we need to import the class and generate an instance of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c1f6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptnlp import HFModelHub, HF_TASKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9460e9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hub = HFModelHub()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce5e54e",
   "metadata": {},
   "source": [
    "Next we can search for a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ded037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = hub.search_model_by_task(HF_TASKS.TEXT_CLASSIFICATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fec0167",
   "metadata": {},
   "source": [
    "Let's look at a few:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17717851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model Name: distilbert-base-uncased-finetuned-sst-2-english, Tasks: [text-classification],\n",
       " Model Name: roberta-base-openai-detector, Tasks: [text-classification],\n",
       " Model Name: roberta-large-mnli, Tasks: [text-classification],\n",
       " Model Name: roberta-large-openai-detector, Tasks: [text-classification]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cc23ba",
   "metadata": {},
   "source": [
    "These are models specifically tagged with the `text-classification` tag, so you may not see a few models you would expect such as `bert_base_cased`.\n",
    "\n",
    "Let's search for that one for this problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7941ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = hub.search_model_by_name('bert-base-uncased', user_uploaded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e340d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model Name: bert-base-uncased, Tasks: [fill-mask],\n",
       " Model Name: distilbert-base-uncased-distilled-squad, Tasks: [question-answering],\n",
       " Model Name: distilbert-base-uncased-finetuned-sst-2-english, Tasks: [text-classification],\n",
       " Model Name: distilbert-base-uncased, Tasks: [fill-mask],\n",
       " Model Name: 123abhiALFLKFO/distilbert-base-uncased-finetuned-cola, Tasks: [text-classification]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56640897",
   "metadata": {},
   "source": [
    "We want the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b29d210",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a567732b",
   "metadata": {},
   "source": [
    "Now that we have picked a model, let's use the data API to prepare our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52c80c1",
   "metadata": {},
   "source": [
    "> Note: It should be mentioned that this is optional, you can always just pass in the string name of a model such as \"bert-base-cased\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b676253e",
   "metadata": {},
   "source": [
    "## Building `TaskDatasets`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faa7c29",
   "metadata": {},
   "source": [
    "All of the task-specific high-level data API's (such as `SequenceClassificationDatasets`) all wrap around the `TaskDatasets` class, which is a small wrapper around `datasets` highly efficient `Dataset` class.\n",
    "\n",
    "This integration was valuable because it provides a fast and memory-efficient way to use large datasets with minimal effort. \n",
    "\n",
    "First let's import the class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83994a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptnlp import TaskDatasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6965c387",
   "metadata": {},
   "source": [
    "The `TaskDatasets` class has no class constructors outside the normal one. The reason for this is it takes in raw `Datasets` and other tokenizer arguments to build from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0cfe3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"TaskDatasets\" class=\"doc_header\"><code>class</code> <code>TaskDatasets</code><a href=\"https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/core.py#L168\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>TaskDatasets</code>(**`train_dset`**, **`valid_dset`**, **`tokenizer_name`**:`str`=*`None`*, **`tokenize`**:`bool`=*`True`*, **`tokenize_func`**:`callable`=*`None`*, **`tokenize_kwargs`**:`dict`=*`{}`*, **`auto_kwargs`**:`dict`=*`{}`*, **`remove_cols`**:`Union`\\[`str`, `List`\\[`str`\\]\\]=*`None`*)\n",
       "\n",
       "A set of datasets for a particular task, with a simple API.\n",
       "\n",
       "Note: This is the base API, `items` should be a set of regular text and model-ready labels,\n",
       "      including label or one-hot encoding being applied.\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`train_dset`** : *`<class 'inspect._empty'>`*\t<p>A train `Dataset` object</p>\n",
       "\n",
       "\n",
       " - **`valid_dset`** : *`<class 'inspect._empty'>`*\t<p>A validation `Dataset` object</p>\n",
       "\n",
       "\n",
       " - **`tokenizer_name`** : *`<class 'str'>`*, *optional*\t<p>The string name of a `HuggingFace` tokenizer or model. If `None`, will not tokenize the dataset.</p>\n",
       "\n",
       "\n",
       " - **`tokenize`** : *`<class 'bool'>`*, *optional*\t<p>Whether to tokenize the dataset immediatly</p>\n",
       "\n",
       "\n",
       " - **`tokenize_func`** : *`<built-in function callable>`*, *optional*\t<p>A function to tokenize an item with</p>\n",
       "\n",
       "\n",
       " - **`tokenize_kwargs`** : *`<class 'dict'>`*, *optional*\t<p>Some kwargs for when we call the tokenizer</p>\n",
       "\n",
       "\n",
       " - **`auto_kwargs`** : *`<class 'dict'>`*, *optional*\t<p>Some kwargs when calling `AutoTokenizer.from_pretrained`</p>\n",
       "\n",
       "\n",
       " - **`remove_cols`** : *`typing.Union[str, typing.List[str]]`*, *optional*\t<p>What columns to remove</p>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from adaptnlp import TaskDatasets\n",
    "show_doc(TaskDatasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759f48f0",
   "metadata": {},
   "source": [
    "Anything you would normally pass to the tokenizer call (such as `max_length`, `padding`) should go in `tokenize_kwargs`, and anything going to the `AutoTokenizer.from_pretrained` constructor should be passed to the `auto_kwargs`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e8b0ef",
   "metadata": {},
   "source": [
    "## Custom Tokenization Function and Finishing our `TaskDatasets`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4a80d0",
   "metadata": {},
   "source": [
    "You may notice there is an extra step here: We need to pass in a `tokenize_func`. In the other tutorials we used a very basic tokenizing function, and this has a default for that as well.\n",
    "\n",
    "However given our dataset, we need to implement our own tokenization function.\n",
    "\n",
    "To do so, your function must take in an `item`, a `tokenizer`, and `tokenize_kwargs`. It should be noted that **you do not have to declare any of these**. All of them are attributes that the `TaskDatasets` has access to, and will be passed to this function implicitly.\n",
    "\n",
    "What you need to declare is *how* you want the tokenizer applied.\n",
    "\n",
    "In our case we have two separate sentences that need to be tokenized at once. These texts live in that dictionary we saw earlier at the keys `sentence1` and `sentence2`.\n",
    "\n",
    "Let's write that function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063a1e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tok_func(\n",
    "    item, # A single item in the dataset\n",
    "    tokenizer, # The implicit tokenizer that `TaskDatasets` has access to\n",
    "    tokenize_kwargs, # Key word arguments passed into the constructor of `TaskDatasets`\n",
    "):\n",
    "    \"A basic tokenization function for two items\"\n",
    "    return tokenizer(\n",
    "        item['sentence1'],\n",
    "        item['sentence2'],\n",
    "        **tokenize_kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2683bdf5",
   "metadata": {},
   "source": [
    "Along with building our own tokenize function, we need to tell `Datasets` what columns to drop when we pull an item from our dataset. \n",
    "\n",
    "These are synonymous with `Datasets` `remove_cols`.\n",
    "\n",
    "In our problem this includes the `sentence1`, `sentence2`, and `idx` keys, as our tokenized input gets put into a `text` key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4eb04ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_cols = ['sentence1', 'sentence2', 'idx']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa19b76d",
   "metadata": {},
   "source": [
    "Finally we'll declare some arguments for our tokenize function, specifically ensuring our max length is reasonable and that we should pad our samples to that length:\n",
    "\n",
    "> Note: These vary problem to problem. You should look at your specific model and dataset to judge what a proper max length and padding should be. AdaptNLP does its best to use a decent default, but it may not work for every problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a49354d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_kwargs = {'max_length':64, 'padding':True}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a224521a",
   "metadata": {},
   "source": [
    "Let's build our `TaskDatasets` now, passing in everything we built:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cafa7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c3a17a374e4e34a1ede20153852922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7f80e0ccc94acd994bfebbfb63b403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dsets = TaskDatasets(\n",
    "    train_dset = raw_datasets['train'], # Our training `Dataset`\n",
    "    valid_dset = raw_datasets['validation'], # Our validation `Dataset`\n",
    "    tokenizer_name = model.name, # The name of our model\n",
    "    tokenize_kwargs = tokenize_kwargs, # The tokenizer kwargs\n",
    "    tokenize_func = tok_func, # The tokenization function\n",
    "    remove_cols = remove_cols # The columns to remove after tokenizing our input\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17c3911",
   "metadata": {},
   "source": [
    "You may be wondering why we use the `TaskDatasets` class, this is a convience wrapper around much of the functions and tasks you need to call when using `datasets`'s `Dataset` class, and there are a few special behaviors to quickly build working `AdaptiveDataLoaders` as well.\n",
    "\n",
    "Let's build these `AdaptiveDataLoaders`, which are just fastai's `DataLoaders` class, but it overrides a few functions to have it work nicely with HuggingFace's `Dataset` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cc36db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TaskDatasets.dataloaders\" class=\"doc_header\"><code>TaskDatasets.dataloaders</code><a href=\"https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/core.py#L247\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TaskDatasets.dataloaders</code>(**`batch_size`**:`int`=*`8`*, **`shuffle_train`**:`bool`=*`True`*, **`collate_fn`**:`callable`=*`None`*, **`path`**=*`'.'`*, **`device`**=*`None`*)\n",
       "\n",
       "Creates `DataLoaders` from the dataset\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`batch_size`** : *`<class 'int'>`*, *optional*\t<p>A batch size</p>\n",
       "\n",
       "\n",
       " - **`shuffle_train`** : *`<class 'bool'>`*, *optional*\t<p>Whether to shuffle the training dataset</p>\n",
       "\n",
       "\n",
       " - **`collate_fn`** : *`<built-in function callable>`*, *optional*\t<p>A custom collation function</p>\n",
       "\n",
       "\n",
       " - **`path`** : *`<class 'str'>`*, *optional*\n",
       "\n",
       " - **`device`** : *`<class 'NoneType'>`*, *optional*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TaskDatasets.dataloaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d9de40",
   "metadata": {},
   "source": [
    "To build our `DataLoaders`, can call `.dataloaders`, specifying our batch size and a collate function to use. In our case we will collate with the `DataCollatorWithPadding` class out of `transformers`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0b86ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031a26b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dsets.dataloaders(\n",
    "    batch_size=8,\n",
    "    collate_fn=DataCollatorWithPadding(tokenizer=dsets.tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91df0c08",
   "metadata": {},
   "source": [
    "Finally, let's view a batch of data with the `show_batch` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965ad300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>germany, another opponent of the war currently on the u. n. security council, has moved closer to the united states, and did not insist on a timetable monday. germany, another opponent of the war currently on the u. n. security council, in recent weeks has moved closer to washington and did not insist on a timetable.</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the comment period was to have expired on monday. a public comment period on the proposed new taxes will end on monday.</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subsequently, some bondholders have filed suit to block the exchange offer. bondholders of mirant americas generation subsequently filed suit against mirant seeking to block the exchange offer.</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a judge ordered the child placed in state custody aug. 8. on aug. 8, juvenile court judge robert yeates ordered that parker be placed in protective custody.</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23348be",
   "metadata": {},
   "source": [
    "Since this isn't a pre-built `*TaskDatasets` object, the `show_batch` looks a little plain, but it gets across exactly what you would need to see. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5343c100",
   "metadata": {},
   "source": [
    "Next let's build a `Tuner` and train our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586172ad",
   "metadata": {},
   "source": [
    "## Building a `Tuner`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e2d9bf",
   "metadata": {},
   "source": [
    "Next we need to build a compatible `Tuner` for our problem. These tuners contain good defaults for our problem space, including loss functions and metrics.\n",
    "\n",
    "First let's import the `SequenceClassificationTuner` and view it's documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54d78db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptnlp import SequenceClassificationTuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WRxJWveszSmY",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"SequenceClassificationTuner\" class=\"doc_header\"><code>class</code> <code>SequenceClassificationTuner</code><a href=\"https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/sequence_classification.py#L222\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>SequenceClassificationTuner</code>(**`dls`**:`DataLoaders`, **`model_name`**:`str`, **`tokenizer`**=*`None`*, **`loss_func`**=*`CrossEntropyLoss()`*, **`metrics`**=*`[<function accuracy at 0x7f2e7f7a3430>, <fastai.metrics.AccumMetric object at 0x7f2e7f708040>]`*, **`opt_func`**=*`Adam`*, **`additional_cbs`**=*`None`*, **`expose_fastai_api`**=*`False`*, **`num_classes`**:`int`=*`None`*, **\\*\\*`kwargs`**) :: [`AdaptiveTuner`](/adaptnlp/training.core.html#AdaptiveTuner)\n",
       "\n",
       "An [`AdaptiveTuner`](/adaptnlp/training.core.html#AdaptiveTuner) with good defaults for Sequence Classification tasks\n",
       "\n",
       "**Valid kwargs and defaults:**\n",
       "  - `lr`:float = 0.001\n",
       "  - `splitter`:function = `trainable_params`\n",
       "  - `cbs`:list = None\n",
       "  - `path`:Path = None\n",
       "  - `model_dir`:Path = 'models'\n",
       "  - `wd`:float = None\n",
       "  - `wd_bn_bias`:bool = False\n",
       "  - `train_bn`:bool = True\n",
       "  - `moms`: tuple(float) = (0.95, 0.85, 0.95)\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`dls`** : *`<class 'fastai.data.core.DataLoaders'>`*\t<p>A set of DataLoaders</p>\n",
       "\n",
       "\n",
       " - **`model_name`** : *`<class 'str'>`*\t<p>A HuggingFace model</p>\n",
       "\n",
       "\n",
       " - **`tokenizer`** : *`<class 'NoneType'>`*, *optional*\t<p>A HuggingFace tokenizer</p>\n",
       "\n",
       "\n",
       " - **`loss_func`** : *`<class 'fastai.losses.CrossEntropyLossFlat'>`*, *optional*\t<p>A loss function</p>\n",
       "\n",
       "\n",
       " - **`metrics`** : *`<class 'list'>`*, *optional*\t<p>Metrics to monitor the training with</p>\n",
       "\n",
       "\n",
       " - **`opt_func`** : *`<class 'function'>`*, *optional*\t<p>A fastai or torch Optimizer</p>\n",
       "\n",
       "\n",
       " - **`additional_cbs`** : *`<class 'NoneType'>`*, *optional*\t<p>Additional Callbacks to have always tied to the Tuner,</p>\n",
       "\n",
       "\n",
       " - **`expose_fastai_api`** : *`<class 'bool'>`*, *optional*\t<p>Whether to expose the fastai API</p>\n",
       "\n",
       "\n",
       " - **`num_classes`** : *`<class 'int'>`*, *optional*\t<p>The number of classes</p>\n",
       "\n",
       "\n",
       " - **`kwargs`** : *`<class 'inspect._empty'>`*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from adaptnlp import SequenceClassificationTuner\n",
    "show_doc(SequenceClassificationTuner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UXvHCw5HzVil",
   "metadata": {},
   "source": [
    "Next we'll pass in our `DataLoaders`, the name of our model, and since we are using raw `Datasets`, the number of classes we have. In our case this is two."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efac2b5",
   "metadata": {},
   "source": [
    "> Note: If you are not using the data API (`TaskDatasets`, `SequenceClassificationDatasets`, etc), you need to pass in the tokenizer to the constructor as well with `tokenizer=tokenizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k-gczguJzSjM",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b388c21a7fe478ab3ad3004849a7c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tuner = SequenceClassificationTuner(dls, model.name, num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9rAi8TF5zfPz",
   "metadata": {},
   "source": [
    "By default we can see that it used `CrossEntropyLoss` as our loss function, and both `accuracy` and `F1Score` as our metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QTyxXImizjxC",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FlattenedLoss of CrossEntropyLoss()"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "x_PEmOXAzlAE",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "f1_score\n"
     ]
    }
   ],
   "source": [
    "_ = [print(m.name) for m in tuner.metrics]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57462869",
   "metadata": {},
   "source": [
    "It is also possible to define your own metrics, these stem from [fastai](https://docs.fast.ai/metrics).\n",
    "\n",
    "To do so, write a function that takes an input and an output, and performs an operation. For example, we will write our own `accuracy` metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2802910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ourAccuracy(inp, out):\n",
    "    \"A simplified accuracy metric that doesn't flatten\"\n",
    "    return (inp == targ).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deed3556",
   "metadata": {},
   "source": [
    "And then we pass it into the constructor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6be0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tuner = SequenceClassificationTuner(dls, model.name, num_classes=2, metrics=[ourAccuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e433d22",
   "metadata": {},
   "source": [
    "If we look at the metrics, you can see that now it is just `ourAccuracy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17457d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ourAccuracy'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.metrics[0].name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77117847",
   "metadata": {},
   "source": [
    "For this tutorial, we will revert it back to the defaults:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ee74c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tuner = SequenceClassificationTuner(dls, model.name, num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dl-tqB5uzq1k",
   "metadata": {},
   "source": [
    "Finally we just need to train our model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dd944d",
   "metadata": {},
   "source": [
    "## Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9ec17d",
   "metadata": {},
   "source": [
    "To fine-tune, AdaptNLP's tuner class provides only a few functions to work with. The important ones are the `tune` and `lr_find` class.\n",
    "\n",
    "As the `Tuner` uses `fastai` under the hood, `lr_find` calls fastai's Learning Rate Finder to help us pick a learning rate. Let's do that now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZTaeO5Vm0P-h",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"AdaptiveTuner.lr_find\" class=\"doc_header\"><code>AdaptiveTuner.lr_find</code><a href=\"https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/core.py#L389\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>AdaptiveTuner.lr_find</code>(**`start_lr`**=*`1e-07`*, **`end_lr`**=*`10`*, **`num_it`**=*`100`*, **`stop_div`**=*`True`*, **`show_plot`**=*`True`*, **`suggest_funcs`**=*`valley`*)\n",
       "\n",
       "Runs fastai's `LR Finder`\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`start_lr`** : *`<class 'float'>`*, *optional*\n",
       "\n",
       " - **`end_lr`** : *`<class 'int'>`*, *optional*\n",
       "\n",
       " - **`num_it`** : *`<class 'int'>`*, *optional*\n",
       "\n",
       " - **`stop_div`** : *`<class 'bool'>`*, *optional*\n",
       "\n",
       " - **`show_plot`** : *`<class 'bool'>`*, *optional*\n",
       "\n",
       " - **`suggest_funcs`** : *`<class 'function'>`*, *optional*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(SequenceClassificationTuner.lr_find)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2oWmrMic0H0z",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.8/site-packages/fastai/callback/schedule.py:270: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"ro\" (-> color='r'). The keyword argument will take precedence.\n",
      "  ax.plot(val, idx, 'ro', label=nm, c=color)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(valley=0.0003981071640737355)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuner.lr_find()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jxviy-Nj0Mly",
   "metadata": {},
   "source": [
    "It recommends a learning rate of around 2e-4, however a steeper slope can be found around 5e-5 so we will use that.\n",
    "\n",
    "> Note: Reading the LR Finder is somewhat of an art. The `valley` method is one of the most reliable ones, but also try and figure out an intuition towards finding a learning rate as you go as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20a2181",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bpl6Krkl0SLX",
   "metadata": {},
   "source": [
    "Let's look at the documentation for `tune`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CtnRVQOX0T0-",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"AdaptiveTuner.tune\" class=\"doc_header\"><code>AdaptiveTuner.tune</code><a href=\"https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/core.py#L375\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>AdaptiveTuner.tune</code>(**`epochs`**:`int`, **`lr`**:`float`=*`None`*, **`strategy`**:`Strategy`=*`'fit_one_cycle'`*, **`callbacks`**:`list`=*`[]`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Fine tune `self.model` for `epochs` with an `lr` and `strategy`\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`epochs`** : *`<class 'int'>`*\t<p>Number of iterations to train for</p>\n",
       "\n",
       "\n",
       " - **`lr`** : *`<class 'float'>`*, *optional*\t<p>If None, finds a new learning rate and uses suggestion_method</p>\n",
       "\n",
       "\n",
       " - **`strategy`** : *`<class 'fastcore.basics.Strategy'>`*, *optional*\t<p>A fitting method</p>\n",
       "\n",
       "\n",
       " - **`callbacks`** : *`<class 'list'>`*, *optional*\t<p>Extra fastai Callbacks</p>\n",
       "\n",
       "\n",
       " - **`kwargs`** : *`<class 'inspect._empty'>`*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(SequenceClassificationTuner.tune)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06gNa3Rk0U-_",
   "metadata": {},
   "source": [
    "We can pass in a number of epochs, a learning rate, a strategy, and additional fastai callbacks to call.\n",
    "\n",
    "Valid strategies live in the `Strategy` namespace class, and consist of:\n",
    "- OneCycle (Also called the [One-Cycle Policy](https://docs.fast.ai/callback.schedule.html#Learner.fit_one_cycle))\n",
    "- [CosineAnnealing](https://docs.fast.ai/callback.schedule.html#Learner.fit_flat_cos)\n",
    "- [SGDR](https://docs.fast.ai/callback.schedule.html#Learner.fit_sgdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5DK9Q-rd0gHN",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptnlp import Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Xgf9oa4H0nDI",
   "metadata": {},
   "source": [
    "In this tutorial we will train with the One-Cycle policy, as currently it is one of the best schedulers to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4214963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/3 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='459' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/459 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9720/1466054727.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mStrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOneCycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/jovyan/adaptnlp/adaptnlp/training/core.py\u001b[0m in \u001b[0;36mtune\u001b[0;34m(self, epochs, lr, strategy, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m'epochs,lr,cbs'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m         \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdelegates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_find\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.8/site-packages/fastai/callback/schedule.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    111\u001b[0m     scheds = {'lr': combined_cos(pct_start, lr_max/div, lr_max, lr_max/div_final),\n\u001b[1;32m    112\u001b[0m               'mom': combined_cos(pct_start, *(self.moms if moms is None else moms))}\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mParamScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_hypers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelFitException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_end_cleanup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_end_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_one_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'batch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelBatchException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jovyan/adaptnlp/adaptnlp/training/core.py\u001b[0m in \u001b[0;36m_do_one_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'before_backward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'step'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelStepException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.8/site-packages/fastai/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhyper\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhyper\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.8/site-packages/fastai/optimizer.py\u001b[0m in \u001b[0;36maverage_grad\u001b[0;34m(p, mom, dampening, grad_avg, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgrad_avg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgrad_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0mdamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmom\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdampening\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0mgrad_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'grad_avg'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgrad_avg\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "tuner.tune(3, lr, strategy=Strategy.OneCycle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dc3547",
   "metadata": {},
   "source": [
    "## Saving Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aebf7b2",
   "metadata": {},
   "source": [
    "Now that we have a trained model, let's save those weights away.\n",
    "\n",
    "Calling `tuner.save` will save both the model and the tokenizer in the same format as how HuggingFace does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01b6b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SequenceClassificationTuner.save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WHCmaQxp0_88",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.save('good_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf8dec2",
   "metadata": {},
   "source": [
    "## Performing Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce058be",
   "metadata": {},
   "source": [
    "There are two ways to get predictions, the first is with the `.predict` method in our `tuner`. This is great for if you just finished training and want to see how your model performs on some new data!\n",
    "The other method is with AdaptNLP's inference API, which we will show afterwards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "S_OxB8QN1PD2",
   "metadata": {},
   "source": [
    "### In Tuner\n",
    "\n",
    "First let's write a sentence to test with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d011be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence . Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jHP8lv2P1kKf",
   "metadata": {},
   "source": [
    "And then predict with it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KRdOk9bt1lSy",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SequenceClassificationTuner.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wPhkn9fp1mi6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.predict(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac20c59",
   "metadata": {},
   "source": [
    "You'll notice it says `LABEL_1`. We did not build with the `Datasets` wrapper API's, so currently they do not have a vocabulary to work off of. \n",
    "\n",
    "Let's pass in a vocabulary of `not_equivalent` and `equivalent` to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f11211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['not_equivalent', 'equivalent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9d3bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sentences': ['Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence . Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .'],\n",
       " 'predictions': ['not_equivalent'],\n",
       " 'probs': tensor([[0.6317, 0.3683]])}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.predict(sentence, class_names=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ebc3ae",
   "metadata": {},
   "source": [
    "You can see it gave us much more readable results!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaihrDr1taH",
   "metadata": {},
   "source": [
    "### With the Inference API\n",
    "\n",
    "Next we will use the `EasySequenceClassifier` class, which AdaptNLP offers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "S2TyPxzh10Tx",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptnlp import EasySequenceClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2_5JihBk12kA",
   "metadata": {},
   "source": [
    "We simply construct the class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Wa2mnVPY10QR",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = EasySequenceClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Vf_HrdWy1_-Q",
   "metadata": {},
   "source": [
    "And call the `tag_text` method, passing in the sentence, the location of our saved model, and some names for our classes.\n",
    "\n",
    "Similarly here, we can pass in our own vocabulary to use. Let's do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UX_sdJkL10JA",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-02 19:42:29,864 loading file good_model\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sentences': ['Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence . Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .'],\n",
       " 'predictions': ['not_equivalent'],\n",
       " 'probs': tensor([[0.6317, 0.3683]])}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.tag_text(\n",
    "    sentence,\n",
    "    model_name_or_path='good_model',\n",
    "    class_names=names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qXsMgmQC2Qmt",
   "metadata": {},
   "source": [
    "And we got the exact same output and probabilities!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wUyr63752UQo",
   "metadata": {},
   "source": [
    "There are also different levels of predictions we can return (which is also the same with our earlier `predict` call).\n",
    "\n",
    "These live in a namespace `DetailLevel` class, with a few examples below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jWYd1N4110EK",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptnlp import DetailLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xuFd4z7c2adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'low'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DetailLevel.Low"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YcnqBH6b2c8D",
   "metadata": {},
   "source": [
    "While some Easy modules will not return different items at each level, most will return only a few specific outputs at the Low level, and everything possible at the High level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-6SxPpTT2nhp",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sentences': ['Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence . Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .'],\n",
       " 'predictions': ['not_equivalent'],\n",
       " 'probs': tensor([[0.6317, 0.3683]])}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.tag_text(\n",
    "    sentence,\n",
    "    model_name_or_path = 'good_model',\n",
    "    detail_level=DetailLevel.Low,\n",
    "    class_names=names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IBWnrnWH2pQ4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sentences': ['Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence . Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .'],\n",
       " 'predictions': ['not_equivalent'],\n",
       " 'probs': tensor([[0.6317, 0.3683]]),\n",
       " 'pairings': OrderedDict([('Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence . Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .',\n",
       "               tensor([0.6317, 0.3683]))]),\n",
       " 'classes': ['LABEL_0', 'LABEL_1']}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.tag_text(\n",
    "    sentence,\n",
    "    model_name_or_path = 'good_model',\n",
    "    detail_level=DetailLevel.Medium,\n",
    "    class_names=names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s5-Z8qhH2zbZ",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sentences': [Sentence: \"Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence . Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .\"   [− Tokens: 39  − Sentence-Labels: {'sc': [LABEL_0 (0.6317), LABEL_1 (0.3683)]}]],\n",
       " 'predictions': ['not_equivalent'],\n",
       " 'probs': tensor([[0.6317, 0.3683]]),\n",
       " 'pairings': OrderedDict([('Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence . Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .',\n",
       "               tensor([0.6317, 0.3683]))]),\n",
       " 'classes': ['LABEL_0', 'LABEL_1']}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.tag_text(\n",
    "    sentence,\n",
    "    model_name_or_path = 'good_model',\n",
    "    detail_level=DetailLevel.High,\n",
    "    class_names=names\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
