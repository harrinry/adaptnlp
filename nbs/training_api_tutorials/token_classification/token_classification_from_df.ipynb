{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53946cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_slow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca157d7d",
   "metadata": {},
   "source": [
    "# Tutorial: Fine-Tuning Token Classification on DataFrames with CoNLL 2003\n",
    "> Tuning a Token Classification (Named Entity Recognition) model on the CoNLL 2003 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36868fd4",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this tutorial we will be showing an end-to-end example of fine-tuning a Transformer for token classification on a custom dataset in DataFrame format.\n",
    "\n",
    "By the end of this you should be able to:\n",
    "\n",
    "1. Build a dataset with the `TokenClassificationDatasets` class, and its DataLoaders\n",
    "2. Build a `TokenClassificationTuner` quickly, find a good learning rate, and train with the One-Cycle Policy\n",
    "3. Save that model away, to be used with deployment or other HuggingFace libraries\n",
    "4. Apply inference using both the `Tuner`'s available function as well as with the `EasyTokenTagger` class within AdaptNLP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a44baa5",
   "metadata": {},
   "source": [
    "## Installing the Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce03b17",
   "metadata": {},
   "source": [
    "This tutorial utilizies the latest AdaptNLP version, as well as parts of the `fastai` library. Please run the below code to install them:\n",
    "\n",
    "```python\n",
    "!pip install adaptnlp -U\n",
    "```\n",
    "(or `pip3`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "injured-longitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbverbose.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86de58d7",
   "metadata": {},
   "source": [
    "## Getting the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a039f4f",
   "metadata": {},
   "source": [
    "First we need a dataset. We will use the `HuggingFace` library to download the `conll2003` dataset and convert it to a `pandas` DataFrame. This may seem counterintuitive, but it works for demonstrational purposes. In practice you would use a custom `pandas` DataFrame.\n",
    "\n",
    "`CoNLL 2003` is a named entity recognition (NER) dataset which contains the following named entities: persons, locations, organizations, and names of miscellaneous entities that do not belong to the previous three groups. It follows the IOB2 tagging scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82a2612b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset conll2003 (/home/ubuntu/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/40e7cb6bcc374f7c349c83acd1e9352a4f09474eb691f64f364ee62eb65d0ca6)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dsets = load_dataset('conll2003')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-energy",
   "metadata": {},
   "source": [
    "For the purpose of example, we'll take the train subset, convert it to a `pandas` DataFrame, and grab the `tokens` and `ner_tags` columns, which will serve as our tokens and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "expensive-cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = dsets['train']\n",
    "dset.set_format(type='pandas')\n",
    "df = dset[:]\n",
    "df = df[['tokens', 'ner_tags']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-sullivan",
   "metadata": {},
   "source": [
    "Let's look at our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "moral-detroit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[EU, rejects, German, call, to, boycott, Briti...</td>\n",
       "      <td>[3, 0, 7, 0, 0, 0, 7, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Peter, Blackburn]</td>\n",
       "      <td>[1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[BRUSSELS, 1996-08-22]</td>\n",
       "      <td>[5, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[The, European, Commission, said, on, Thursday...</td>\n",
       "      <td>[0, 3, 4, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Germany, 's, representative, to, the, Europea...</td>\n",
       "      <td>[5, 0, 0, 0, 0, 3, 4, 0, 0, 0, 1, 2, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [EU, rejects, German, call, to, boycott, Briti...   \n",
       "1                                 [Peter, Blackburn]   \n",
       "2                             [BRUSSELS, 1996-08-22]   \n",
       "3  [The, European, Commission, said, on, Thursday...   \n",
       "4  [Germany, 's, representative, to, the, Europea...   \n",
       "\n",
       "                                            ner_tags  \n",
       "0                        [3, 0, 7, 0, 0, 0, 7, 0, 0]  \n",
       "1                                             [1, 2]  \n",
       "2                                             [5, 0]  \n",
       "3  [0, 3, 4, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, ...  \n",
       "4  [5, 0, 0, 0, 0, 3, 4, 0, 0, 0, 1, 2, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-window",
   "metadata": {},
   "source": [
    "Now that we've downloaded some data, let's pick a viable model to train with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320caa02",
   "metadata": {},
   "source": [
    "## Picking a Model with the Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170b200d",
   "metadata": {},
   "source": [
    "AdaptNLP has a `HFModelHub` class that allows you to communicate with the HuggingFace Hub and pick a model from it, as well as a namespace `HF_TASKS` class with a list of valid tasks we can search by.\n",
    "\n",
    "Let's try and find one suitable for token classification.\n",
    "\n",
    "First we need to import the class and generate an instance of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b85eb95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptnlp import HFModelHub, HF_TASKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "tropical-nursing",
   "metadata": {},
   "outputs": [],
   "source": [
    "hub = HFModelHub()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-alberta",
   "metadata": {},
   "source": [
    "Next we can search for a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "invalid-survival",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = hub.search_model_by_task(HF_TASKS.TOKEN_CLASSIFICATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-scanning",
   "metadata": {},
   "source": [
    "Let's look at a few:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "hourly-airfare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model Name: xlm-roberta-large-finetuned-conll03-english, Tasks: [token-classification],\n",
       " Model Name: xlm-roberta-large-finetuned-conll03-german, Tasks: [token-classification]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-legislation",
   "metadata": {},
   "source": [
    "These are models specifically tagged with the `token-classification` tag, so you may not see a few models you would expect such as `bert_base_cased`.\n",
    "\n",
    "Since both of these models have already been fine-tuned on the `CoNLL 2003` dataset, let's choose a basic pre-trained model `distilbert-base-uncased`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "failing-questionnaire",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'distilbert-base-uncased'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-peoples",
   "metadata": {},
   "source": [
    "In general, if you don't need to go through the `HFModelHub` if you know which model you'd like to use already. You can always just pass in the string name of a model such as \"bert-base-cased\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b676253e",
   "metadata": {},
   "source": [
    "## Building `TaskDatasets` with `TokenClassificationDatasets`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faa7c29",
   "metadata": {},
   "source": [
    "Each task has a high-level data wrapper around the `TaskDatasets` class. In our case this is the `TokenClassificationDatasets` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83994a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptnlp import TokenClassificationDatasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-carol",
   "metadata": {},
   "source": [
    "There are multiple different constructors for the `TokenClassificationDatasets` class, and you should never call the main constructor directly.\n",
    "\n",
    "We will be using `from_dfs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-kenya",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TokenClassificationDatasets.from_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-craps",
   "metadata": {},
   "source": [
    "Anything you would normally pass to the tokenizer call (such as `max_length`, `padding`) should go in `tokenize_kwargs`, and anything going to the `AutoTokenizer.from_pretrained` constructor should be passed to the `auto_kwargs`.\n",
    "\n",
    "**Important**: Because our dataset is already tokenized, when we try to encode the tokens, we may end up with sub-tokens. This will cause our labels to no longer align with the number of tokens. In order to take this into account, the following arguments should be passed to the tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bottom-abortion",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_kwargs = {\n",
    "    'truncation':True, \n",
    "    'is_split_into_words':True, \n",
    "    'padding':'max_length', \n",
    "    'return_offsets_mapping':True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-humanity",
   "metadata": {},
   "source": [
    "We will also need to provide a mapping between the labels and the entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "swiss-society",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_mapping = {\n",
    "    0: 'O',\n",
    "    1: 'B-PER',\n",
    "    2: 'I-PER',\n",
    "    3: 'B-ORG',\n",
    "    4: 'I-ORG',\n",
    "    5: 'B-LOC',\n",
    "    6: 'I-LOC',\n",
    "    7: 'B-MISC',\n",
    "    8: 'I-MISC'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-gossip",
   "metadata": {},
   "source": [
    "In our case we only have a `train_df`, so we should specify what percent to split into train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-venezuela",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = TokenClassificationDatasets.from_dfs(\n",
    "    df,\n",
    "    'tokens',\n",
    "    'ner_tags',\n",
    "    entity_mapping,\n",
    "    tokenizer_name = model_name,\n",
    "    tokenize=True,\n",
    "    tokenize_kwargs = tokenize_kwargs,\n",
    "    split_pct=.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-explosion",
   "metadata": {},
   "source": [
    "> Note: If you have a training and validation `DataFrame`, simply pass in the validation `DataFrame` as `valid_df=validation_dataframe` and do not pass in any `split_func` or `split_pct`. Everything else is the exact same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-slide",
   "metadata": {},
   "source": [
    "And finally turn it into some `AdaptiveDataLoaders`.\n",
    "\n",
    "These are just fastai's `DataLoaders` class, but it overrides a few functions to have it work nicely with HuggingFace's `Dataset` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-valuation",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TokenClassificationDatasets.dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dsets.dataloaders(batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjustable-cornwall",
   "metadata": {},
   "source": [
    "Finally, let's view a batch of data with the `show_batch` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-enzyme",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586172ad",
   "metadata": {},
   "source": [
    "## Building `Tuner`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e2d9bf",
   "metadata": {},
   "source": [
    "Next we need to build a compatible `Tuner` for our problem. These tuners contain good defaults for our problem space, including loss functions and metrics.\n",
    "\n",
    "First let's import the `TokenClassificationTuner` and view it's documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c54d78db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptnlp import TokenClassificationTuner\n",
    "show_doc(TokenClassificationTuner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-valentine",
   "metadata": {},
   "source": [
    "Next we'll pass in our `DataLoaders` and the name of our model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-capacity",
   "metadata": {},
   "source": [
    "> Note: If you are not using the data API (`TaskDatasets`, `SequenceClassificationDatasets`, etc), you need to pass in the tokenizer to the constructor as well withÂ `tokenizer=tokenizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-breakfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = TokenClassificationTuner(dls, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-shade",
   "metadata": {},
   "source": [
    "By default we can see that it used `CrossEntropyLoss` as our loss function, and both `accuracy` and `F1` as our metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-documentary",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-volume",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = [print(m.name) for m in tuner.metrics]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-pursuit",
   "metadata": {},
   "source": [
    "**Important**: By default, the `TokenClassificationTuner` class does not use `fastai` metrics (unlike the other `Tuner` classes). Instead it uses `HuggingFace`'s `seqeval` metric to compute accuracy, precision, recall, and/or F1 scores based on the requirements of multi-label classification. As a result, you will need to have [seqeval](https://github.com/chakki-works/seqeval) installed in order to use the `TokenClassificationTuner`.\n",
    "\n",
    "If you would like to use `fastai` metrics, you can enter them by name. It is also possible to define your own custom metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incomplete-introduction",
   "metadata": {},
   "source": [
    "In this tutorial, we will use the metrics built into `TokenClassificationTuner`. To differentiate these from `fastai` metrics, make sure to include quotes around the names.\n",
    "\n",
    "While `accuracy` and `f1` are already defaults, we will specify all the available built-in metrics for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-nicaragua",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = TokenClassificationTuner(dls, model_name, metrics=['accuracy',\n",
    "                                                           'precision',\n",
    "                                                           'recall',\n",
    "                                                           'f1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-keyboard",
   "metadata": {},
   "source": [
    "Finally we just need to train our model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dd944d",
   "metadata": {},
   "source": [
    "## Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9ec17d",
   "metadata": {},
   "source": [
    "And all that's left is to `tune`. There are only 4 or 5 functions you can call on our `tuner` currently, and this is by design to make it simplistic. In case you don't want to be boxed in however, if you pass in `expose_fastai_api=True` to our earlier call, it will expose the entirety of `Learner` to you, so you can call `fit_one_cycle`, `lr_find`, and everything else as `Tuner` uses `fastai` under the hood. \n",
    "\n",
    "First, let's call `lr_find`, which uses fastai's Learning Rate Finder to help us pick a learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4214963",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TokenClassificationTuner.lr_find)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-louisiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = tuner.lr_find()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-standard",
   "metadata": {},
   "source": [
    "It recommends a learning rate of around 1e-4, so we will use that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-newton",
   "metadata": {},
   "source": [
    "Let's look at the documentation for `tune`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-future",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TokenClassificationTuner.tune)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-marks",
   "metadata": {},
   "source": [
    "We can pass in a number of epochs, a learning rate, a strategy, and additional fastai callbacks to call.\n",
    "\n",
    "Valid strategies live in the `Strategy` namespace class, and consist of:\n",
    "- OneCycle (Also called the [One-Cycle Policy](https://docs.fast.ai/callback.schedule.html#Learner.fit_one_cycle))\n",
    "- [CosineAnnealing](https://docs.fast.ai/callback.schedule.html#Learner.fit_flat_cos)\n",
    "- [SGDR](https://docs.fast.ai/callback.schedule.html#Learner.fit_sgdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "after-glory",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptnlp import Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-state",
   "metadata": {},
   "source": [
    "In this tutorial we will train with the One-Cycle policy, as currently it is one of the best schedulers to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-preservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.tune(3, lr, strategy=Strategy.OneCycle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dc3547",
   "metadata": {},
   "source": [
    "## Saving Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aebf7b2",
   "metadata": {},
   "source": [
    "Now that we have a trained model, let's save those weights away.\n",
    "\n",
    "Calling `tuner.save` will save both the model and the tokenizer in the same format as how HuggingFace does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a01b6b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TokenClassificationTuner.save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.save('good_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf8dec2",
   "metadata": {},
   "source": [
    "## Performing Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce058be",
   "metadata": {},
   "source": [
    "There are two ways to get predictions, the first is with the `.predict` method in our `tuner`. This is great for if you just finished training and want to see how your model performs on some new data!\n",
    "The other method is with AdaptNLP's inference API, which we will show afterwards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-daniel",
   "metadata": {},
   "source": [
    "### In Tuner\n",
    "\n",
    "First let's write a sentence to test with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-penalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The company Novetta is based in McLean, Virgina.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-return",
   "metadata": {},
   "source": [
    "And then predict with it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-mechanism",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TokenClassificationTuner.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.predict(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-hostel",
   "metadata": {},
   "source": [
    "### With the Inference API\n",
    "\n",
    "Next we will use the `EasyTokenTagger` class, which AdaptNLP offers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "rational-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptnlp import EasyTokenTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-copper",
   "metadata": {},
   "source": [
    "We simply construct the class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "interpreted-mailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = EasyTokenTagger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-shareware",
   "metadata": {},
   "source": [
    "And call the `tag_text` method, passing in the sentence, the location of our saved model, and some names for our classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-burlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.tag_text(\n",
    "    sentence,\n",
    "    model_name_or_path='good_model',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-ecology",
   "metadata": {},
   "source": [
    "And we got the exact same output and probabilities!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-smith",
   "metadata": {},
   "source": [
    "There are also different levels of predictions we can return (which is also the same with our earlier `predict` call).\n",
    "\n",
    "These live in a namespace `DetailLevel` class, with a few examples below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "smart-accident",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptnlp import DetailLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "excess-center",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'low'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DetailLevel.Low"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-factor",
   "metadata": {},
   "source": [
    "While some Easy modules will not return different items at each level, most will return only a few specific outputs at the Low level, and everything possible at the High level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-worship",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.tag_text(\n",
    "    sentence,\n",
    "    model_name_or_path = 'good_model',\n",
    "    detail_level=DetailLevel.Low\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-buddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.tag_text(\n",
    "    sentence,\n",
    "    model_name_or_path = 'good_model',\n",
    "    detail_level=DetailLevel.Medium\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-investigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.tag_text(\n",
    "    sentence,\n",
    "    model_name_or_path = 'good_model',\n",
    "    detail_level=DetailLevel.High\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff6d3dc",
   "metadata": {},
   "source": [
    "## Code Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f345ccf1",
   "metadata": {},
   "source": [
    "A quick one-cell code chunk with all the code used in this notebook, so the reader can quickly copy/paste this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cbbc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from adaptnlp import TokenClassificationDatasets\n",
    "from adaptnlp import TokenClassificationTuner\n",
    "from adaptnlp import Strategy\n",
    "\n",
    "dsets = load_dataset('conll2003')\n",
    "\n",
    "dset = dsets['train']\n",
    "dset.set_format(type='pandas')\n",
    "df = dset[:]\n",
    "df = df[['tokens', 'ner_tags']]\n",
    "\n",
    "model_name = 'distilbert-base-uncased'\n",
    "\n",
    "tokenize_kwargs = {\n",
    "    'truncation':True, \n",
    "    'is_split_into_words':True, \n",
    "    'padding':'max_length', \n",
    "    'return_offsets_mapping':True\n",
    "}\n",
    "\n",
    "entity_mapping = {\n",
    "    0: 'O',\n",
    "    1: 'B-PER',\n",
    "    2: 'I-PER',\n",
    "    3: 'B-ORG',\n",
    "    4: 'I-ORG',\n",
    "    5: 'B-LOC',\n",
    "    6: 'I-LOC',\n",
    "    7: 'B-MISC',\n",
    "    8: 'I-MISC'\n",
    "}\n",
    "\n",
    "dsets = TokenClassificationDatasets.from_dfs(\n",
    "    df,\n",
    "    'tokens',\n",
    "    'ner_tags',\n",
    "    entity_mapping,\n",
    "    tokenizer_name = model_name,\n",
    "    tokenize=True,\n",
    "    tokenize_kwargs = tokenize_kwargs,\n",
    "    split_pct=.8\n",
    ")\n",
    "\n",
    "dls = dsets.dataloaders(batch_size=8)\n",
    "\n",
    "tuner = TokenClassificationTuner(dls, model_name)\n",
    "\n",
    "tuner = TokenClassificationTuner(dls, model_name, metrics=['accuracy',\n",
    "                                                           'precision',\n",
    "                                                           'recall',\n",
    "                                                           'f1'])\n",
    "\n",
    "lr = tuner.lr_find()\n",
    "\n",
    "tuner.tune(3, lr, strategy=Strategy.OneCycle)\n",
    "\n",
    "tuner.save('good_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
