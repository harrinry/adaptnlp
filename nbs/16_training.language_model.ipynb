{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb49e100",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp training.language_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ab3def",
   "metadata": {},
   "source": [
    "# Language Model Tuning\n",
    "> Data and Tuning API for Language Model Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f2a76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc604f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from transformers import DataCollatorForLanguageModeling, default_data_collator\n",
    "\n",
    "from adaptnlp.training.core import *\n",
    "\n",
    "from fastai.data.core import DataLoaders\n",
    "\n",
    "import pandas as pd\n",
    "from fastcore.meta import delegates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2995f2f0",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3be962",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def _group_texts(examples, block_size):\n",
    "    # Concatenate all texts, based on code by Transformers\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "    # customize this part to your needs.\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7946bded",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LanguageModelDatasets(TaskDatasets):\n",
    "    \"\"\"\n",
    "    A set of datasets designed for language model fine-tuning\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        items, # Some items we can pull x's and y's from\n",
    "        get_x = ColReader('text'), # A function taking in one item and extracting the text\n",
    "        block_size:int = 512, # A block size to split up the data with. Note: this is different than `max_len`\n",
    "        masked_lm:bool=False, # Whether this is a Masked Language Model\n",
    "        splits = None, # Indexs to split the data from\n",
    "        tokenizer_name:str = None, # The string name of a `HuggingFace` tokenizer or model. If `None`, will not tokenize the dataset.\n",
    "        tokenize:bool = True, # Whether to tokenize the dataset immediatly\n",
    "        tokenize_kwargs:dict = {}, # Some kwargs for when we call the tokenizer\n",
    "        auto_kwargs:dict = {}, # Some kwargs when calling `AutoTokenizer.from_pretrained`\n",
    "    ):\n",
    "        xs = L(L(items).map(get_x)[0].values, use_list=True)\n",
    "        train_xs = xs[splits[0]]\n",
    "        valid_xs = xs[splits[1]]\n",
    "        \n",
    "        train_dset = Dataset.from_dict({\n",
    "            'text':train_xs.items\n",
    "        })\n",
    "        \n",
    "        valid_dset = Dataset.from_dict({\n",
    "            'text':valid_xs.items\n",
    "        })\n",
    "        \n",
    "        super().__init__(train_dset, valid_dset, tokenizer_name, tokenize, tokenize_kwargs, auto_kwargs)\n",
    "        self.masked_lm = masked_lm\n",
    "        self.block_size = block_size\n",
    "        f = partial(_group_texts, block_size=self.block_size)\n",
    "        self.train = self.train.map(f, batched=True)\n",
    "        self.valid = self.valid.map(f, batched=True)\n",
    "        \n",
    "    @classmethod\n",
    "    def from_df(\n",
    "        cls,\n",
    "        df:pd.DataFrame, # A Pandas Dataframe or Path to a DataFrame\n",
    "        text_col:str = 'text', # Name of the column the text is stored\n",
    "        splits = None, # Indexes to split the data with\n",
    "        block_size:int = 512, # A block size to split up the data with. Note: this is different than `max_len`\n",
    "        masked_lm:bool=False, # Whether this is a Masked Language Model\n",
    "        tokenizer_name:str = None, # The string name of a `HuggingFace` tokenizer or model. If `None`, will not tokenize the dataset.\n",
    "        tokenize:bool = True, # Whether to tokenize the dataset immediatly\n",
    "        tokenize_kwargs:dict = {}, # Some kwargs for when we call the tokenizer\n",
    "        auto_kwargs:dict = {}, # Some kwargs when calling `AutoTokenizer.from_pretrained`\n",
    "    ):\n",
    "        \"Builds `SequenceClassificationDatasets` from a `DataFrame` or file path\"\n",
    "        get_x = ColReader(text_col)\n",
    "        if splits is None: splits = RandomSplitter(0.2)(range_of(df))\n",
    "        return cls(df, get_x, block_size, masked_lm, splits, tokenizer_name, tokenize, tokenize_kwargs, auto_kwargs)\n",
    "    \n",
    "    @delegates(DataLoaders)\n",
    "    def dataloaders(\n",
    "        self, \n",
    "        batch_size=8, # A batch size\n",
    "        shuffle_train=True, # Whether to shuffle the training dataset\n",
    "        collate_fn = default_data_collator, # A custom collation function\n",
    "        mlm_probability:float = 0.15, # Token masking probablity for Masked Language Models\n",
    "        **kwargs): # Torch DataLoader kwargs\n",
    "        if self.masked_lm: collate_fn = DataCollatorForLanguageModeling(tokenizer=self.tokenizer, mlm_probability=mlm_probability)\n",
    "        return super().dataloaders(batch_size, shuffle_train, collate_fn, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88a4038",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
