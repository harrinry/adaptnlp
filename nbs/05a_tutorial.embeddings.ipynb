{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptnlp import EasyWordEmbeddings, EasyStackedEmbeddings, EasyDocumentEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Easy Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained keys are available in Transformer's documentation or Flair's tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of producing embeddings using NovettaWordEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = \"This is Albert.  My last name is Einstein.  I like physics and atoms.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate embeddings tagger\n",
    "embeddings = EasyWordEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2Model were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0530, -0.0137, -0.2393,  ..., -1.2358, -0.9708,  0.6150],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Get GPT2 embeddings of example text\n",
    "# A list of flair Sentence objects are generated\n",
    "sentences = embeddings.embed_text(example_text, model_name_or_path=\"gpt2\")\n",
    "# Iterate through first Sentence to access the embeddings\n",
    "for token in sentences[0]:\n",
    "    print(token.get_embedding())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.5918, -0.4142,  1.0203,  ...,  0.4004, -0.1586,  1.0107],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Same thing but with BERT embeddings\n",
    "sentences = embeddings.embed_text(example_text, model_name_or_path=\"bert-base-cased\")\n",
    "# Iterate through first Sentence to access the embeddings\n",
    "for token in sentences[0]:\n",
    "    print(token.get_embedding())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "099c686d6a8140579cab240893bc4446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501200538.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Same thing but roBERTa embeddings\n",
    "sentences = embeddings.embed_text(example_text, model_name_or_path=\"roberta-base\")\n",
    "# Iterate through first Sentence to access the embeddings\n",
    "for token in sentences[0]:\n",
    "    print(token.get_embedding())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Producing stacked embeddings with NovettaStackedEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "May need a couple moments to instantiate...\n"
     ]
    }
   ],
   "source": [
    "# Instantiate stacked embeddings with a variable number of language models\n",
    "embeddings = EasyStackedEmbeddings(\"bert-base-cased\", \"distilbert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.5918, -0.4142,  1.0203,  ...,  1.0985, -1.8035, -1.5887],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Get stacked/concatenated word embeddings\n",
    "sentences = embeddings.embed_text(example_text)\n",
    "# Iterate through first Sentence to access the embeddings\n",
    "for token in sentences[0]:\n",
    "    print(token.get_embedding())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Embeddings with NovettaDocumentEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "May need a couple moments to instantiate...\n",
      "Pooled embedding loaded\n",
      "RNN embeddings loaded\n"
     ]
    }
   ],
   "source": [
    "# Instantiate with variable number of language models\n",
    "embeddings = EasyDocumentEmbeddings(\"bert-base-cased\", \"distilbert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.4740,  0.0244,  0.3428,  ..., -0.0057, -0.1208, -0.0247],\n",
      "       device='cuda:0', grad_fn=<CatBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Document Pool embedding\n",
    "sentences = embeddings.embed_pool(example_text)\n",
    "# Get the text/document embedding\n",
    "for sentence in sentences:\n",
    "    print(sentence.get_embedding())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 8.6051e-01,  9.9875e-01, -5.1653e-01,  4.4028e-01, -2.6489e-01,\n",
      "         8.1826e-01,  4.1479e-01,  9.7935e-01, -9.1401e-01, -5.3021e-01,\n",
      "        -8.2195e-01,  6.7288e-01, -1.2646e-02,  8.5230e-01,  6.4977e-01,\n",
      "        -9.6448e-01,  7.8760e-01,  9.4110e-01, -9.8675e-01,  4.4215e-01,\n",
      "        -9.9318e-01,  4.2201e-01, -5.9397e-01, -4.1114e-01, -8.9010e-01,\n",
      "        -2.6712e-02,  9.9513e-01, -7.9625e-01, -9.8152e-01, -3.6621e-01,\n",
      "         8.4872e-01,  4.9597e-01,  4.6508e-01,  9.7859e-01,  3.7736e-01,\n",
      "         3.5898e-01, -5.4604e-01, -4.8421e-01,  8.7586e-01,  6.1857e-01,\n",
      "         8.5983e-01,  3.9903e-01,  5.5581e-01, -1.7296e-01, -8.6435e-01,\n",
      "         9.9972e-02,  6.2743e-01,  9.3582e-01,  8.5841e-01,  7.8694e-02,\n",
      "        -8.6842e-01, -8.7992e-01, -9.7008e-01, -5.9344e-01,  6.0902e-01,\n",
      "        -9.7268e-01,  5.6673e-01, -5.6100e-01, -9.3629e-01,  7.8566e-01,\n",
      "         3.7182e-01,  9.2551e-01,  7.4267e-01,  3.6521e-01, -1.0547e-02,\n",
      "         9.1705e-01,  9.9012e-01, -1.1793e-01,  9.9375e-01,  4.2064e-01,\n",
      "         3.6456e-01,  9.7508e-01, -6.0039e-02,  7.3309e-01, -3.3579e-01,\n",
      "        -6.6825e-01, -8.6343e-01, -9.7744e-01, -2.7804e-01,  5.9262e-01,\n",
      "        -9.8552e-01, -9.9285e-01,  9.9364e-01, -9.7539e-01,  9.9709e-01,\n",
      "         9.9848e-01,  1.2876e-01,  1.5984e-01,  7.6399e-02, -5.6783e-01,\n",
      "        -9.8632e-01,  4.4459e-01,  6.1388e-01, -1.2599e-01, -7.1622e-01,\n",
      "         9.3701e-01, -5.5801e-01,  9.9979e-01,  5.5200e-01, -9.1340e-01,\n",
      "        -9.9065e-01,  6.0508e-01, -2.6782e-01,  9.7997e-01, -9.8017e-01,\n",
      "        -8.3110e-01, -3.8525e-01, -9.6031e-01, -3.1013e-01, -5.2053e-01,\n",
      "        -8.1424e-01, -4.7721e-01,  8.2647e-02, -9.8140e-01,  4.9565e-01,\n",
      "        -7.3048e-01, -9.9970e-01,  4.6072e-01, -8.8343e-01, -9.3434e-01,\n",
      "         5.6623e-01, -9.5446e-02, -5.8594e-02,  7.6817e-01, -6.8103e-01,\n",
      "         5.1345e-01, -4.7767e-01,  9.8486e-01,  6.5830e-01,  8.3005e-01,\n",
      "        -6.0703e-02, -5.1078e-01,  4.1954e-02,  9.7840e-01,  9.8621e-01,\n",
      "         5.1244e-01, -9.7619e-01,  8.7281e-01,  9.2167e-01,  9.0943e-01,\n",
      "         1.7134e-01,  9.5988e-01, -7.6642e-01,  3.8014e-01, -7.2784e-01,\n",
      "         5.9338e-01,  7.9817e-01, -9.8295e-01, -7.9262e-01, -4.8642e-01,\n",
      "         9.9895e-01, -4.8532e-01,  9.8532e-01,  8.1304e-01, -3.6276e-01,\n",
      "         6.4854e-01,  8.1006e-01, -3.6130e-01,  1.6865e-01, -5.1197e-01,\n",
      "         9.9997e-01, -1.2493e-02,  7.8326e-01, -9.3607e-01, -1.8569e-01,\n",
      "         9.9154e-01, -4.4354e-01, -9.9822e-01, -4.8340e-01, -9.0843e-01,\n",
      "        -6.1604e-01, -3.5744e-01,  9.7696e-01, -9.9974e-01, -3.2151e-01,\n",
      "        -8.7152e-01, -3.5296e-01,  9.7049e-01, -4.1310e-01, -6.1858e-01,\n",
      "         1.0379e-01,  9.3830e-01, -9.1351e-01,  4.6419e-01,  6.3137e-01,\n",
      "         8.1265e-01,  7.0055e-01,  7.4178e-01,  9.9576e-01, -9.8983e-01,\n",
      "        -9.3845e-01, -1.9035e-01,  5.1232e-01, -6.5279e-01, -1.5912e-01,\n",
      "        -9.6740e-01, -5.5199e-02, -7.0714e-01, -3.9139e-01,  8.9581e-02,\n",
      "        -4.0755e-01,  8.0035e-01, -2.5555e-02, -5.5013e-01, -6.6356e-01,\n",
      "        -4.3204e-01, -6.3950e-01,  8.4631e-01, -9.4990e-01, -2.1333e-03,\n",
      "        -8.5928e-01,  8.5495e-01, -9.9329e-01,  5.4131e-01,  8.9044e-01,\n",
      "         7.3073e-01,  6.4623e-01, -8.6325e-01,  2.8917e-01,  7.6200e-01,\n",
      "         8.0063e-01, -2.0229e-02, -9.9529e-01, -4.0102e-01, -4.4103e-02,\n",
      "        -9.0240e-02,  2.6856e-01,  2.6105e-01, -8.7443e-01, -4.0656e-01,\n",
      "        -4.3418e-01,  4.0351e-01, -2.5010e-01,  3.8742e-01,  4.8987e-01,\n",
      "        -7.5133e-01,  9.6790e-01,  4.6092e-02,  9.8253e-01,  2.2253e-01,\n",
      "         1.1501e-01, -2.0315e-01,  2.1727e-01, -9.8078e-01, -3.3270e-02,\n",
      "         7.9286e-01, -9.6249e-01,  3.6558e-01,  9.7739e-01, -4.8858e-01,\n",
      "        -9.8713e-01,  2.0204e-01, -3.6911e-01,  8.3849e-01,  8.3932e-01,\n",
      "        -2.6427e-01, -7.9209e-01,  7.6611e-01,  6.6967e-01, -6.4046e-01,\n",
      "        -5.1133e-01,  4.4094e-01,  2.1586e-01,  9.9053e-01,  2.9241e-01,\n",
      "        -5.6289e-01,  8.6984e-01,  2.7165e-01, -4.3478e-01, -5.7724e-01,\n",
      "        -1.6836e-01, -9.9156e-01,  9.7410e-01,  1.7959e-01,  9.7371e-03,\n",
      "        -5.8882e-01,  7.7015e-01, -1.7833e-01, -9.1176e-01, -8.0002e-01,\n",
      "         9.5302e-01,  3.1187e-01,  4.9149e-02, -7.4259e-01,  6.8744e-01,\n",
      "        -4.9231e-01,  5.0384e-01,  5.6890e-01, -6.8822e-01, -6.2605e-01,\n",
      "         1.3808e-01, -5.9058e-01,  5.1612e-01, -8.9425e-01, -1.7548e-01,\n",
      "         2.1209e-01, -1.1021e-01,  8.7547e-01,  8.7759e-01,  5.3731e-01,\n",
      "         9.7401e-01, -9.9421e-01,  1.3912e-01,  1.9356e-01,  1.6100e-01,\n",
      "        -6.5800e-01,  4.8448e-01,  8.3030e-01, -2.0040e-01,  8.4640e-02,\n",
      "        -8.3402e-02,  8.1679e-01,  5.0688e-01,  9.1403e-01,  1.6951e-01,\n",
      "         9.3644e-01, -6.7323e-01, -9.8411e-01,  7.8202e-01, -5.2924e-02,\n",
      "        -3.7320e-01,  9.9938e-01,  9.8469e-01, -1.0302e-01,  9.8186e-01,\n",
      "        -5.8109e-01,  9.9942e-01, -9.9136e-01,  8.4404e-01,  5.0815e-02,\n",
      "        -3.5947e-01,  9.3447e-01,  8.5399e-01,  9.9445e-01,  9.5551e-01,\n",
      "        -6.5417e-02,  1.8199e-01,  8.3600e-01,  9.0780e-01, -3.0552e-01,\n",
      "         3.4340e-01, -2.5721e-01, -3.7440e-04,  1.9073e-01,  5.6972e-01,\n",
      "         3.1191e-02,  6.0074e-01, -7.4588e-01, -2.2752e-01,  8.5662e-01,\n",
      "         9.6011e-01, -8.4552e-01, -9.6890e-01,  8.3486e-01,  1.2192e-01,\n",
      "        -7.8338e-02,  5.4135e-03, -8.6584e-02,  9.3836e-01,  9.4850e-01,\n",
      "         8.3059e-01, -2.1287e-01, -8.8042e-02, -4.0109e-01,  7.7939e-01,\n",
      "        -7.2403e-01,  9.7331e-04,  8.9055e-01,  7.2143e-02, -9.1124e-01,\n",
      "        -9.5893e-02,  2.6683e-01,  2.4153e-01,  8.9783e-01, -8.9234e-01,\n",
      "        -5.0480e-01,  2.5276e-01,  3.4591e-01,  2.7219e-01,  9.9552e-01,\n",
      "        -1.3053e-01,  2.3460e-01, -1.1740e-01,  9.5649e-01, -8.5799e-01,\n",
      "        -2.5242e-01, -8.7543e-01,  2.7912e-01, -4.2896e-01, -8.6141e-01,\n",
      "        -8.5554e-01,  7.5567e-01, -7.4705e-01, -9.1727e-01,  9.9273e-01,\n",
      "         5.3884e-01,  8.2877e-01,  7.2887e-01, -9.8088e-01, -1.6695e-01,\n",
      "         4.9411e-01,  5.9350e-02,  6.1618e-01,  9.1622e-01,  9.9837e-01,\n",
      "        -1.5887e-01, -3.9693e-01, -7.5806e-01,  9.7488e-02,  5.8234e-01,\n",
      "        -9.2561e-01,  8.0861e-01,  4.2323e-01,  9.9502e-01, -9.3126e-01,\n",
      "        -5.4488e-01, -6.5225e-01, -7.4400e-02,  8.6421e-01, -9.9197e-01,\n",
      "        -7.4119e-01,  6.9042e-01,  3.2453e-01,  9.4328e-02,  4.7330e-01,\n",
      "        -9.3980e-01, -6.7815e-01, -9.1390e-01,  9.8453e-01, -5.8811e-02,\n",
      "        -4.3789e-01,  8.1372e-01, -9.3841e-01, -3.9701e-01,  9.1077e-01,\n",
      "        -8.6713e-01, -4.0815e-01, -6.8526e-01, -7.6460e-01,  9.9239e-01,\n",
      "         3.1836e-01,  7.3643e-01, -2.4860e-01, -1.0404e-01, -6.9095e-01,\n",
      "         6.5083e-01,  3.8687e-01,  7.2234e-01,  9.4096e-01,  1.2658e-01,\n",
      "        -2.6418e-01, -2.1538e-02,  9.8405e-01,  9.9689e-01,  1.0293e-01,\n",
      "         9.6801e-01,  9.9998e-01,  3.5993e-02, -3.5377e-01, -9.6027e-01,\n",
      "        -2.5031e-01,  8.7479e-01, -5.9904e-01, -9.0336e-02, -8.7144e-01,\n",
      "         8.7319e-01, -9.9921e-01, -5.0730e-02,  9.9996e-01,  8.8972e-01,\n",
      "         4.3033e-02, -9.7407e-01, -1.6207e-01,  9.8422e-01,  5.6447e-01,\n",
      "        -8.7933e-01,  9.9252e-01,  9.8405e-01, -2.4941e-01, -2.2157e-02,\n",
      "        -9.4900e-01, -9.9991e-01, -9.9916e-01,  4.9400e-01,  9.7133e-01,\n",
      "        -8.4567e-01,  8.6638e-01,  8.1956e-01,  5.9632e-01, -3.5884e-01,\n",
      "        -1.2217e-01,  1.9126e-01,  9.9406e-01,  9.6796e-01, -1.4706e-01,\n",
      "         4.5201e-01,  6.9581e-01, -8.0025e-01,  4.0202e-01,  4.8209e-01,\n",
      "         9.6843e-01,  8.8376e-01,  9.8764e-01,  5.6078e-01, -6.7059e-01,\n",
      "        -9.9997e-01,  9.4490e-01,  9.6927e-01,  9.0229e-01,  9.8589e-01,\n",
      "         6.4186e-01, -8.6449e-01], device='cuda:0', grad_fn=<CatBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Now again but with Document RNN embedding\n",
    "sentences = embeddings.embed_rnn(example_text)\n",
    "# Get the text/document embedding\n",
    "for sentence in sentences:\n",
    "    print(sentence.get_embedding())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
