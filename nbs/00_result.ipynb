{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14006509",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36f65c2",
   "metadata": {},
   "source": [
    "# Results\n",
    "> Base `Result` classes for all model types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d3eb4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbverbose.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a43194bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from flair.data import Sentence\n",
    "from typing import List\n",
    "import torch\n",
    "\n",
    "_all_ = ['DetailLevel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17a437e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastcore.basics import mk_class\n",
    "\n",
    "mk_class('DetailLevel', **{o:o.lower() for o in 'High,Medium,Low'.split(',')},\n",
    "         doc=\"All possible naming conventions for DetailLevel with typo-proofing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "303d640f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SentenceResult:\n",
    "    \"\"\"\n",
    "    A result class designed around Flair `Sentences`\n",
    "    \n",
    "    The base class has `tokenized_inputs` and `inputs`\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        sentences:List[Sentence] # A list of `Sentence` objects\n",
    "    ):\n",
    "        self._sentences = sentences\n",
    "        \n",
    "    @property\n",
    "    def tokenized_inputs(\n",
    "        self\n",
    "    ) -> List[str]:\n",
    "        \"The original tokenized inputs\"\n",
    "        return [s.to_tokenized_string() for s in self._sentences]\n",
    "    \n",
    "    @property\n",
    "    def inputs(\n",
    "        self\n",
    "    ) -> List[str]:\n",
    "        \"The original text inputs\"\n",
    "        return [s.to_original_text() for s in self._sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d66d0d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"SentenceResult.tokenized_inputs\" class=\"doc_header\"><code>SentenceResult.tokenized_inputs</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "The original tokenized inputs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(SentenceResult.tokenized_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85e4e09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"SentenceResult.inputs\" class=\"doc_header\"><code>SentenceResult.inputs</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "The original text inputs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(SentenceResult.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c02205",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
