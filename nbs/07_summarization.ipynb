{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp inference.summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization\n",
    "> Performing summarization within the AdaptNLP library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbverbose.showdoc import *\n",
    "from fastcore.test import test_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import logging\n",
    "from typing import List, Dict, Union\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    PreTrainedTokenizer,\n",
    "    PreTrainedModel,\n",
    "    T5ForConditionalGeneration,\n",
    "    BartForConditionalGeneration,\n",
    ")\n",
    "\n",
    "from adaptnlp.callback import GeneratorCallback\n",
    "from adaptnlp.model import AdaptiveModel\n",
    "from adaptnlp.model_hub import HFModelResult, FlairModelResult\n",
    "\n",
    "from fastcore.basics import store_attr\n",
    "from fastcore.meta import delegates\n",
    "\n",
    "from fastai.callback.core import Callback, CancelBatchException\n",
    "from fastai.torch_core import apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TransformersSummarizer(AdaptiveModel):\n",
    "    \"Adaptive model for Transformer's Conditional Generation or Language Models (Transformer's T5 and Bart conditiional generation models have a language modeling head)\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        tokenizer: PreTrainedTokenizer, # A tokenizer object from Huggingface's transformers (TODO)and tokenizers\n",
    "        model: PreTrainedModel # A transformers Conditional Generation (Bart or T5) or Language model\n",
    "    ):\n",
    "        # Load up tokenizer\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        super().__init__()\n",
    "        # Sets internal model\n",
    "        super().set_model(model)\n",
    "\n",
    "        # Set inputs to come in as `dict`\n",
    "        super().set_as_dict(True)\n",
    "\n",
    "    @classmethod\n",
    "    def load(\n",
    "        cls, \n",
    "        model_name_or_path: str # A key string of one of Transformer's pre-trained Summarizer Model\n",
    "    ) -> AdaptiveModel:\n",
    "        \"Class method for loading and constructing this classifier\"\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path)\n",
    "        summarizer = cls(tokenizer, model)\n",
    "        return summarizer\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        text: Union[List[str], str], # Sentences to run inference on\n",
    "        mini_batch_size: int = 32, # Mini batch size\n",
    "        num_beams: int = 4, # Number of beams for beam search. Must be between 1 and infinity. 1 means no beam search.  \n",
    "        min_length: int = 0, # The min length of the sequence to be generated\n",
    "        max_length: int = 128, # The max length of the sequence to be generated. Between min_length and infinity\n",
    "        early_stopping: bool = True, # If set to True beam search is stopped when at least num_beams sentences finished per batch\n",
    "        **kwargs, # Optional arguments for the Transformers `PreTrainedModel.generate()` method\n",
    "    ) -> List[str]: # A list of predicted summarizations\n",
    "        \"Predict method for running inference using the pre-trained sequence classifier model\"\n",
    "\n",
    "        # Make all inputs list\n",
    "        if isinstance(text, str):\n",
    "            text = [text]\n",
    "\n",
    "        # T5 requires 'summarize: ' precursor text for pre-trained summarizer\n",
    "        if isinstance(self.model, T5ForConditionalGeneration):\n",
    "            text = [f'summarize: {t}' for t in text]\n",
    "\n",
    "        dataset = self._tokenize(text)\n",
    "        dl = DataLoader(dataset, batch_size=mini_batch_size)\n",
    "\n",
    "        summaries = []\n",
    "\n",
    "        logger.info(f'Running summarizer on {len(dataset)} text sequences')\n",
    "        logger.info(f'Batch size = {mini_batch_size}')\n",
    "\n",
    "        cb = GeneratorCallback(num_beams, min_length, max_length, early_stopping, **kwargs)\n",
    "\n",
    "        preds,_ = super().get_preds(dl=dl, cbs=[cb])\n",
    "\n",
    "        preds = apply(lambda x: x.squeeze(0), preds)\n",
    "\n",
    "        for o in preds:\n",
    "            summaries.append(\n",
    "                [\n",
    "                    self.tokenizer.decode(\n",
    "                        o,\n",
    "                        skip_special_tokens=True,\n",
    "                        clean_up_tokenization_spaces=False,\n",
    "                    )\n",
    "                ].pop()\n",
    "            )\n",
    "\n",
    "        return {'summaries':summaries}\n",
    "\n",
    "    def _tokenize(self, text: Union[List[str], str]) -> TensorDataset:\n",
    "        \"Batch tokenizes text and produces a `TensorDataset` with text\"\n",
    "\n",
    "        # Pre-trained Bart summarization model has a max length fo 1024 tokens for input\n",
    "        if isinstance(self.model, BartForConditionalGeneration):\n",
    "            tokenized_text = self.tokenizer.batch_encode_plus(\n",
    "                text,\n",
    "                return_tensors=\"pt\",\n",
    "                max_length=1024,\n",
    "                add_special_tokens=True,\n",
    "                padding=\"max_length\",\n",
    "            )\n",
    "        else:\n",
    "            tokenized_text = self.tokenizer.batch_encode_plus(\n",
    "                text,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=\"max_length\",\n",
    "                add_special_tokens=True,\n",
    "            )\n",
    "\n",
    "        # Bart doesn't use `token_type_ids`\n",
    "        dataset = TensorDataset(\n",
    "            tokenized_text[\"input_ids\"],\n",
    "            tokenized_text[\"attention_mask\"],\n",
    "        )\n",
    "\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TransformersSummarizer.load\" class=\"doc_header\"><code>TransformersSummarizer.load</code><a href=\"__main__.py#L19\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TransformersSummarizer.load</code>(**`model_name_or_path`**:`str`)\n",
       "\n",
       "Class method for loading and constructing this classifier\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`model_name_or_path`** : *`<class 'str'>`*\t<p>A key string of one of Transformer's pre-trained Summarizer Model</p>\n",
       "\n",
       "\n",
       "\n",
       "**Returns**:\n",
       "\t\n",
       " * *`<class 'adaptnlp.model.AdaptiveModel'>`*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TransformersSummarizer.load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TransformersSummarizer.predict\" class=\"doc_header\"><code>TransformersSummarizer.predict</code><a href=\"__main__.py#L30\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TransformersSummarizer.predict</code>(**`text`**:`Union`\\[`List`\\[`str`\\], `str`\\], **`mini_batch_size`**:`int`=*`32`*, **`num_beams`**:`int`=*`4`*, **`min_length`**:`int`=*`0`*, **`max_length`**:`int`=*`128`*, **`early_stopping`**:`bool`=*`True`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Predict method for running inference using the pre-trained sequence classifier model\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`text`** : *`typing.Union[typing.List[str], str]`*\t<p>Sentences to run inference on</p>\n",
       "\n",
       "\n",
       " - **`mini_batch_size`** : *`<class 'int'>`*, *optional*\t<p>Mini batch size</p>\n",
       "\n",
       "\n",
       " - **`num_beams`** : *`<class 'int'>`*, *optional*\t<p>Number of beams for beam search. Must be between 1 and infinity. 1 means no beam search.</p>\n",
       "\n",
       "\n",
       " - **`min_length`** : *`<class 'int'>`*, *optional*\t<p>The min length of the sequence to be generated</p>\n",
       "\n",
       "\n",
       " - **`max_length`** : *`<class 'int'>`*, *optional*\t<p>The max length of the sequence to be generated. Between min_length and infinity</p>\n",
       "\n",
       "\n",
       " - **`early_stopping`** : *`<class 'bool'>`*, *optional*\t<p>If set to True beam search is stopped when at least num_beams sentences finished per batch</p>\n",
       "\n",
       "\n",
       " - **`kwargs`** : *`<class 'inspect._empty'>`*\n",
       "\n",
       "\n",
       "**Returns**:\n",
       "\t\n",
       " * *`typing.List[str]`*\t<p>A list of predicted summarizations</p>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TransformersSummarizer.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EasySummarizer:\n",
    "    \"Summarization Module\"\n",
    "    def __init__(self):\n",
    "        self.summarizers: Dict[AdaptiveModel] = defaultdict(bool)\n",
    "\n",
    "    def summarize(\n",
    "        self,\n",
    "        text: Union[List[str], str], # Sentences to run inference on\n",
    "        model_name_or_path: Union[str, HFModelResult] = \"t5-small\", # A model id or path to a pre-trained model repository or custom trained model directory\n",
    "        mini_batch_size: int = 32, # Mini batch size\n",
    "        num_beams: int = 4, # Number of beams for beam search. Must be between 1 and infinity. 1 means no beam search\n",
    "        min_length: int = 0, # The max length of the sequence to be generated. Between min_length and infinity\n",
    "        max_length: int = 128, # The max length of the sequence to be generated. Between min_length and infinity\n",
    "        early_stopping: bool = True, # If set to True beam search is stopped when at least num_beams sentences finished per batch\n",
    "        **kwargs, # Optional arguments for the Transformers `PreTrainedModel.generate()` method\n",
    "    ) -> List[str]: # A list of predicted summaries\n",
    "        \"Predict method for running inference using the pre-trained sequence classifier model\"\n",
    "        name = getattr(model_name_or_path, 'name', model_name_or_path)\n",
    "        if not self.summarizers[name]:\n",
    "            self.summarizers[name] = TransformersSummarizer.load(\n",
    "                name\n",
    "            )\n",
    "\n",
    "        summarizer = self.summarizers[name]\n",
    "        return summarizer.predict(\n",
    "            text=text,\n",
    "            mini_batch_size=mini_batch_size,\n",
    "            num_beams=num_beams,\n",
    "            min_length=min_length,\n",
    "            max_length=max_length,\n",
    "            early_stopping=early_stopping,\n",
    "            **kwargs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5765864911584ef69e003b41a2160a61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1197.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09adecaff0114c269a868024c811a3db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=791656.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd71e54d458749418358ac172f4183eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1389353.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebf725e7ff6948e4b8cf8d15676fa8dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=242065649.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "# Text from encyclopedia Britannica on Einstein\n",
    "text = [\"\"\"Einstein’s education was disrupted by his father’s repeated failures at business. In 1894, after his company failed to get an important \n",
    "          contract to electrify the city of Munich, Hermann Einstein moved to Milan to work with a relative. Einstein was left at a boardinghouse in \n",
    "          Munich and expected to finish his education. Alone, miserable, and repelled by the looming prospect of military duty when he turned 16, Einstein \n",
    "          ran away six months later and landed on the doorstep of his surprised parents. His parents realized the enormous problems that he faced as a \n",
    "          school dropout and draft dodger with no employable skills. His prospects did not look promising.\n",
    "          Fortunately, Einstein could apply directly to the Eidgenössische Polytechnische Schule (“Swiss Federal Polytechnic School”; in 1911, \n",
    "          following expansion in 1909 to full university status, it was renamed the Eidgenössische Technische Hochschule, or “Swiss Federal \n",
    "          Institute of Technology”) in Zürich without the equivalent of a high school diploma if he passed its stiff entrance examinations. His marks \n",
    "          showed that he excelled in mathematics and physics, but he failed at French, chemistry, and biology. Because of his exceptional math scores, \n",
    "          he was allowed into the polytechnic on the condition that he first finish his formal schooling. He went to a special high school run by \n",
    "          Jost Winteler in Aarau, Switzerland, and graduated in 1896. He also renounced his German citizenship at that time. (He was stateless until 1901, \n",
    "          when he was granted Swiss citizenship.) He became lifelong friends with the Winteler family, with whom he had been boarding. (Winteler’s \n",
    "          daughter, Marie, was Einstein’s first love; Einstein’s sister, Maja, would eventually marry Winteler’s son Paul; and his close friend Michele \n",
    "          Besso would marry their eldest daughter, Anna.)\"\"\",\n",
    "       \"\"\"Einstein would write that two “wonders” deeply affected his early years. The first was his encounter with a compass at age five. \n",
    "          He was mystified that invisible forces could deflect the needle. This would lead to a lifelong fascination with invisible forces. \n",
    "          The second wonder came at age 12 when he discovered a book of geometry, which he devoured, calling it his 'sacred little geometry \n",
    "          book'. Einstein became deeply religious at age 12, even composing several songs in praise of God and chanting religious songs on \n",
    "          the way to school. This began to change, however, after he read science books that contradicted his religious beliefs. This challenge \n",
    "          to established authority left a deep and lasting impression. At the Luitpold Gymnasium, Einstein often felt out of place and victimized \n",
    "          by a Prussian-style educational system that seemed to stifle originality and creativity. One teacher even told him that he would \n",
    "          never amount to anything.\"\"\"]\n",
    "\n",
    "summarizer = EasySummarizer()\n",
    "summaries = summarizer.summarize(text = text, model_name_or_path=\"t5-small\", mini_batch_size=1, num_beams = 4, min_length=0, max_length=100, early_stopping=True)\n",
    "test_eq(summaries['summaries'], ['Hermann Einstein was left at a boardinghouse and expected to finish his education . he ran away six months later and landed on the doorstep of his surprised parents . he could apply directly to the Eidgenössische Polytechnische Schule without the equivalent of a high school diploma .',\n",
    " 'Einstein was mystified that invisible forces could deflect the needle . the second wonder came at age 12 when he discovered a book of geometry . he became deeply religious at age 12 .'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EasySummarizer.summarize\" class=\"doc_header\"><code>EasySummarizer.summarize</code><a href=\"__main__.py#L7\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EasySummarizer.summarize</code>(**`text`**:`Union`\\[`List`\\[`str`\\], `str`\\], **`model_name_or_path`**:`Union`\\[`str`, [`HFModelResult`](/adaptnlp/model_hub.html#HFModelResult)\\]=*`'t5-small'`*, **`mini_batch_size`**:`int`=*`32`*, **`num_beams`**:`int`=*`4`*, **`min_length`**:`int`=*`0`*, **`max_length`**:`int`=*`128`*, **`early_stopping`**:`bool`=*`True`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Predict method for running inference using the pre-trained sequence classifier model\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`text`** : *`typing.Union[typing.List[str], str]`*\t<p>Sentences to run inference on</p>\n",
       "\n",
       "\n",
       " - **`model_name_or_path`** : *`typing.Union[str, adaptnlp.model_hub.HFModelResult]`*, *optional*\t<p>A model id or path to a pre-trained model repository or custom trained model directory</p>\n",
       "\n",
       "\n",
       " - **`mini_batch_size`** : *`<class 'int'>`*, *optional*\t<p>Mini batch size</p>\n",
       "\n",
       "\n",
       " - **`num_beams`** : *`<class 'int'>`*, *optional*\t<p>Number of beams for beam search. Must be between 1 and infinity. 1 means no beam search</p>\n",
       "\n",
       "\n",
       " - **`min_length`** : *`<class 'int'>`*, *optional*\t<p>The max length of the sequence to be generated. Between min_length and infinity</p>\n",
       "\n",
       "\n",
       " - **`max_length`** : *`<class 'int'>`*, *optional*\t<p>The max length of the sequence to be generated. Between min_length and infinity</p>\n",
       "\n",
       "\n",
       " - **`early_stopping`** : *`<class 'bool'>`*, *optional*\t<p>If set to True beam search is stopped when at least num_beams sentences finished per batch</p>\n",
       "\n",
       "\n",
       " - **`kwargs`** : *`<class 'inspect._empty'>`*\n",
       "\n",
       "\n",
       "**Returns**:\n",
       "\t\n",
       " * *`typing.List[str]`*\t<p>A list of predicted summaries</p>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EasySummarizer.summarize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "summaries = summarizer.summarize(text = text, model_name_or_path=\"facebook/bart-large-cnn\", mini_batch_size=1, num_beams = 2, min_length=40, max_length=300, early_stopping=True)\n",
    "test_eq(summaries['summaries'], ['Einstein’s education was disrupted by his father’S repeated failures at business. In 1894, after his company failed to get an important contract, Einstein moved to Milan to work with a relative. Einstein was left at a boardinghouse in Munich and expected to finish his education.',\n",
    " 'Einstein would write that two ‘wonders’ deeply affected his early years. The first was his encounter with a compass at age five. The second wonder came at age 12 when he discovered a book of geometry.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "from adaptnlp.model_hub import HFModelHub\n",
    "hub = HFModelHub()\n",
    "models = hub.search_model_by_task('summarization')\n",
    "model = models[-1]\n",
    "summaries = summarizer.summarize(text = text, model_name_or_path=model, mini_batch_size=1, num_beams = 2, min_length=40, max_length=300, early_stopping=True)\n",
    "test_eq(summaries['summaries'], ['Swiss Federal Poly Polytechnic on the condition thatXtechnic and:”; in 1911, following expansion in 1909 to full university status, it wasX de eventually marry Winteler in Aarau, Switzerland, and graduated in 18X son Paul; and his close friend Michele Besso would marry their marry theirX de marry their their marry, Anna.))esteldest daughterX',\n",
    " 'would wonder came at this age 12 when de The second wonder came came at age 12Xul early years. The first was his encounter withacompass at age five. He was mys with invisible forces could deflect the needle. This would lead toa lifelong fascination with invisibleX: EinsteinX'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
