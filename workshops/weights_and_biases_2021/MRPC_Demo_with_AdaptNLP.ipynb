{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6adaf93",
   "metadata": {},
   "source": [
    "# Fine-Tuning on the MRPC Dataset with `AdaptNLP`\n",
    "\n",
    "In this notebook we will be following along with the HuggingFace course and `Tuning` Bert on the MRPC dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85f9333",
   "metadata": {},
   "source": [
    "## Installing What We Need\n",
    "\n",
    "First we need to install the basic libraries we need for `AdaptNLP` to run, this will include `transformers`, `datasets`, but also `fastai` and we'll use a custom version of `nbdev` too (more on this later):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcb8f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/novetta/adaptnlp /tmp/pip-req-build-ylvhli2e\n",
      "  Running command git checkout -b dev --track origin/dev\n",
      "  Switched to a new branch 'dev'\n",
      "  Branch 'dev' set up to track remote branch 'dev' from 'origin'.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
      "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "  Running command git clone -q https://github.com/muellerzr/nbdev /tmp/pip-req-build-je7gswrn\n"
     ]
    }
   ],
   "source": [
    "# !pip install git+https://github.com/novetta/adaptnlp@dev >> /dev/null\n",
    "# !pip install git+https://github.com/muellerzr/nbdev >> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dc168b",
   "metadata": {},
   "source": [
    "## Setting Up The Data\n",
    "\n",
    "Following the HuggingFace tutorial, let's download the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a041ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9608dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb115f7fa185461eb6ea4391cc504bf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=7777.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f093d5315545bb84a2a081a0b0e21f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=4473.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading and preparing dataset glue/mrpc (download: 1.43 MiB, generated: 1.43 MiB, post-processed: Unknown size, total: 2.85 MiB) to /root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "852906101fc34af2b345ed07e70e62e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Downloading', max=1.0, style=ProgressSt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6a48aa144da43639005e128002be8f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Downloading', max=1.0, style=ProgressSt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d35be3218e844beaec6a75af1a1d1a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Downloading', max=1.0, style=ProgressSt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89713d7583bf4d10a1f828414dfcf09b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4afdb50c270348b29dfdc1d5bbd31748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a20165c53124802afadf02384c182ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Dataset glue downloaded and prepared to /root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26959b71",
   "metadata": {},
   "source": [
    "Next we'll need to build some of `AdaptNLP`'s `TaskDatasets`\n",
    "\n",
    "`TaskDatasets` is the mid-level data api `AdaptNLP` provides. Since we're using a raw `HuggingFace` dataset, setting one up is extremely simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f7fa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptnlp import TaskDatasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affd0bc0",
   "metadata": {},
   "source": [
    "First let's note our model name (`bert-base-uncased`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb89dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-base-uncased'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20068b64",
   "metadata": {},
   "source": [
    "In the tutorial, they showed a custom `tokenization` function that we should use. To do so, we'll write a custom tokenization function that takes in an `item`, a `tokenizer`, and some `tokenize_kwargs`\n",
    "\n",
    "> Note: You don't need to worry about `tokenizer` and `tokenizer_kwargs`, these are class attributes the dataset API will have access to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90504e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tok_func(item, tokenizer, tokenize_kwargs):return tokenizer(item['sentence1'], item['sentence2'], **tokenize_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633f6318",
   "metadata": {},
   "source": [
    "And now we can build our datasets! Let's look at what it needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea50ee39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"TaskDatasets\" class=\"doc_header\"><code>class</code> <code>TaskDatasets</code><a href=\"https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/core.py#L137\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>TaskDatasets</code>(**`train_dset`**, **`valid_dset`**, **`tokenizer_name`**:`str`=*`None`*, **`tokenize`**:`bool`=*`True`*, **`tokenize_func`**:`callable`=*`None`*, **`tokenize_kwargs`**:`dict`=*`{}`*, **`auto_kwargs`**:`dict`=*`{}`*, **`remove_cols`**:`Union`\\[`str`, `List`\\[`str`\\]\\]=*`None`*)\n",
       "\n",
       "A set of datasets for a particular task, with a simple API.\n",
       "\n",
       "Note: This is the base API, `items` should be a set of regular text and model-ready labels,\n",
       "      including label or one-hot encoding being applied.\n",
       "\n",
       "**Function Arguments**:\n",
       "* `train_dset`: A train `Dataset` object\n",
       "* `valid_dset`: A validation `Dataset` object\n",
       "* `tokenizer_name` (`str `): The string name of a `HuggingFace` tokenizer or model. If `None`, will not tokenize the dataset.\n",
       "* `tokenize` (`bool `): Whether to tokenize the dataset immediatly\n",
       "* `tokenize_func` (`callable `): A function to tokenize an item with\n",
       "* `tokenize_kwargs` (`dict `): Some kwargs for when we call the tokenizer\n",
       "* `auto_kwargs` (`dict `): Some kwargs when calling `AutoTokenizer.from_pretrained`\n",
       "* `remove_cols` (`Union[str,List[str]] `): What columns to remove\n",
       "* `tokenizer_name` (`str`): A string name of a `HuggingFace` tokenizer or model\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nbdev.showdoc import *\n",
    "show_doc(TaskDatasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8824cc4d",
   "metadata": {},
   "source": [
    "We have our datasets, we have our tokenizer name, but we still need to specify some `tokenize_kwargs` and match up our `remove_cols` with how they do and make sure our model only gets the inputs it expects. Let's define that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ad2e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_cols=['sentence1', 'sentence2', 'idx']\n",
    "tokenize_kwargs = {'max_length':64, 'padding':True}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477bbcab",
   "metadata": {},
   "source": [
    "Now that everything is in place, let's build some `TaskDatasets`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972b36d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f47775d5bdad4b95937bd0b881b43ab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f8254f3c0d94d1ebf8ec9fbc97b2019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec20e9a428ca4e4a9784d6692a59c420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a00d0a01345840bf99bcbda4a5284f5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "378fedc72ebf401294d2502c4de83681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36675c1a00134e3a8d82e2924c9d59ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dsets = TaskDatasets(\n",
    "    raw_datasets['train'], raw_datasets['validation'],\n",
    "    tokenizer_name = model_name,\n",
    "    tokenize_kwargs = tokenize_kwargs,\n",
    "    tokenize_func = tok_func,\n",
    "    remove_cols = remove_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e330a6fb",
   "metadata": {},
   "source": [
    "All that's left is to build some `DataLoaders`! We'll still use the `DataCollatorWithPadding` that `transformers` provides:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7f3869",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffd630d",
   "metadata": {},
   "source": [
    "And similar to the fastai API, we can call `.dataloaders`, specifying our batch size and the collate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0964ae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dsets.dataloaders(\n",
    "    batch_size=8, \n",
    "    collate_fn=DataCollatorWithPadding(tokenizer=dsets.tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98juNbRAIZBC",
   "metadata": {},
   "source": [
    "We can also look at a batch via the `show_batch`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Sx4PLS2jIcPn",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>although mr sorbello was taken to hospital for a check - up, he was later released. mr sorbello was taken to hospital for a check - up and later released, while mr pennisi thinks he may have cracked ribs.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the dow jones industrial average was up 0. 3 per cent at 9, 886. 75, while the nasdaq composite index was 0. 4 per cent higher at 1, 986. 97. on wall street, the dow jones industrial average rose 0. 5 per cent at 9, 905. 8 and the nasdaq composite added 0. 7 per cent at 1, 995. 1.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aspen technology's shares dropped 74 cents, or 23 percent, to close at $ 2. 48 on the nasdaq. in afternoon trading, aspen's shares were off 89 cents or more than 27 percent at $ 2. 33 per share.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>but they are split over whether the fed will acknowledge risks are tilted toward weakness, or say they are balanced. wall street is debating whether the central bank will say risks are tilted toward weakness or balanced with inflation.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4ad5e4",
   "metadata": {},
   "source": [
    "## Fine-Tuning\n",
    "\n",
    "Finally we can fine-tune. We'll use the `SequenceClassificationTuner`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d9c2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptnlp import SequenceClassificationTuner, Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da67f52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"SequenceClassificationTuner\" class=\"doc_header\"><code>class</code> <code>SequenceClassificationTuner</code><a href=\"https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/sequence_classification.py#L92\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>SequenceClassificationTuner</code>(**`dls`**:`DataLoaders`, **`model_name`**:`str`, **`tokenizer`**=*`None`*, **`loss_func`**=*`CrossEntropyLoss()`*, **`metrics`**=*`[<function accuracy at 0x7fc9a765fe60>, <fastai.metrics.AccumMetric object at 0x7fc9a75b9790>]`*, **`opt_func`**=*`Adam`*, **`additional_cbs`**=*`None`*, **`expose_fastai_api`**=*`False`*, **`num_classes`**:`int`=*`None`*, **\\*\\*`kwargs`**) :: `AdaptiveTuner`\n",
       "\n",
       "An `AdaptiveTuner` with good defaults for Sequence Classification tasks\n",
       "\n",
       "**Valid kwargs and defaults:**\n",
       "  - `lr`:float = 0.001\n",
       "  - `splitter`:function = `trainable_params`\n",
       "  - `cbs`:list = None\n",
       "  - `path`:Path = None\n",
       "  - `model_dir`:Path = 'models'\n",
       "  - `wd`:float = None\n",
       "  - `wd_bn_bias`:bool = False\n",
       "  - `train_bn`:bool = True\n",
       "  - `moms`: tuple(float) = (0.95, 0.85, 0.95)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(SequenceClassificationTuner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030b66d7",
   "metadata": {},
   "source": [
    "As we can see, we pass in the `dls` we made earlier, our `model_name`, the tokenizer we just made from our dataset, and the number of classes to use. The rest have good defaults for us to work with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f408fe2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tuner = SequenceClassificationTuner(dls, model_name, dsets.tokenizer, num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a79fcc7",
   "metadata": {},
   "source": [
    "And all that's left is to `tune`. There are only 4 or 5 functions you can call on our `tuner` currently, and this is by design to make it simplistic. In case you don't want to be boxed in however, if you pass in `expose_fastai_api=True` to our earlier call, it will expose the entirety of `Learner` to you, so you can call `fit_one_cycle`, `lr_find`, and everything else.\n",
    "> Note: Not everything will *work* out of the box however"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b0b929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"AdaptiveTuner.tune\" class=\"doc_header\"><code>AdaptiveTuner.tune</code><a href=\"https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/core.py#L321\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>AdaptiveTuner.tune</code>(**`epochs`**:`int`, **`lr`**:`float`=*`None`*, **`strategy`**:`Strategy`=*`'fit_one_cycle'`*, **`callbacks`**:`list`=*`[]`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Fine tune `self.model` for `epochs` with an `lr` and `strategy`\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(SequenceClassificationTuner.tune)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458f8aac",
   "metadata": {},
   "source": [
    "This looks extremely familiar to fastai's `fit` API, because we use that internally. Rather than doing `tuner.fit_one_cycle`, we can pass in either a `Strategy` namespace, or the string representation of the fit method we want to call. \n",
    "\n",
    "We'll train with the One-Cycle Policy, at the same learning rate as the lesson (5e-5) for 3 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4471a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.545525</td>\n",
       "      <td>0.464447</td>\n",
       "      <td>0.786765</td>\n",
       "      <td>0.847636</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.351754</td>\n",
       "      <td>0.323562</td>\n",
       "      <td>0.860294</td>\n",
       "      <td>0.898757</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.183519</td>\n",
       "      <td>0.346475</td>\n",
       "      <td>0.860294</td>\n",
       "      <td>0.901554</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuner.tune(3, 5e-5, strategy=Strategy.OneCycle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eef5e14",
   "metadata": {},
   "source": [
    "Not too bad! We can save our model and tokenizer away now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6e167d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fine_tuned_model'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.save('fine_tuned_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d051caa",
   "metadata": {},
   "source": [
    "## Getting Predictions\n",
    "\n",
    "There are two ways to get predictions, the first is with the `.predict` method in our `tuner`. This is great for if you just finished training and want to see how your model performs on some new data!\n",
    "\n",
    "The other method is with AdaptNLP's infernece API, which we will show afterwards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf44beb",
   "metadata": {},
   "source": [
    "### In Tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6334c0fb",
   "metadata": {},
   "source": [
    "First let's write a sentence for us to test with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c22408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': 0,\n",
       " 'label': 1,\n",
       " 'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .',\n",
       " 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8887a6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence . Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff90fe73",
   "metadata": {},
   "source": [
    "And then predict with it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7451e678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"SequenceClassificationTuner.predict\" class=\"doc_header\"><code>SequenceClassificationTuner.predict</code><a href=\"https://github.com/novetta/adaptnlp/tree/master/adaptnlp/training/sequence_classification.py#L182\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>SequenceClassificationTuner.predict</code>(**`text`**:`Union`\\[`List`\\[`str`\\], `str`\\], **`bs`**:`int`=*`64`*, **`detail_level`**:`DetailLevel`=*`'low'`*)\n",
       "\n",
       "Predict some `text` for sequence classification with the currently loaded model\n",
       "\n",
       "**Function Arguments**:\n",
       "* `text` (`Union[List[str], str]`): Some text or list of texts to do inference with\n",
       "* `bs` (`int`): A batch size to use for multiple texts\n",
       "* `detail_level` (`DetailLevel `): A detail level to return on the predictions\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(SequenceClassificationTuner.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85baeea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'predictions': ['LABEL_1'],\n",
       " 'probs': tensor([[0.4284, 0.5716]]),\n",
       " 'sentences': ['Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence . Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .']}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.predict(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2097c290",
   "metadata": {},
   "source": [
    "You'll notice it's great at getting our probablity and predictions, but it has some issues with getting our labels. This is because we never actually passed in a vocabulary for it to use. Currently we can override `dls.categorize.classes` to set a vocab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1051aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.dls.categorize = type('', (), {'classes':['not_equivalent', 'equivalent']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4070ac",
   "metadata": {},
   "source": [
    "> Note: this just creates a blank object with a single attribute `classes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65145de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'predictions': ['not_equivalent'],\n",
       " 'probs': tensor([[0.5082, 0.4918]]),\n",
       " 'sentences': ['Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence . Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .']}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.predict(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae979df2",
   "metadata": {},
   "source": [
    "### With the AdaptNLP Inference API\n",
    "\n",
    "Next we'll look at using the `EasySequenceClassifier` class, which AdaptNLP offers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a658e027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptnlp import EasySequenceClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c307ac",
   "metadata": {},
   "source": [
    "We simply construct the class, and call `.tag_text`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0ad206",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = EasySequenceClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688f2dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-25 17:52:06,923 loading file fine_tuned_model\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'predictions': ['equivalent'],\n",
       " 'probs': tensor([[0.4284, 0.5716]]),\n",
       " 'sentences': ['Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence . Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .']}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.tag_text(\n",
    "    sentence,\n",
    "    model_name_or_path = 'fine_tuned_model',\n",
    "    class_names = ['not_equivalent', 'equivalent']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CXXF833taScr",
   "metadata": {},
   "source": [
    "There are also different levels of predictions we can return (which is also the same with our earlier `predict` call).\n",
    "\n",
    "These live in a namespace `DetailLevel` class, with a few examples below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8IPxa24PaXIA",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptnlp import DetailLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HogLbxd5avjQ",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'low'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DetailLevel.Low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "L56EzH1SaecK",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'predictions': ['equivalent'],\n",
       " 'probs': tensor([[0.4284, 0.5716]]),\n",
       " 'sentences': ['Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence . Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .']}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.tag_text(\n",
    "    sentence,\n",
    "    model_name_or_path = 'fine_tuned_model',\n",
    "    class_names = ['not_equivalent', 'equivalent'],\n",
    "    detail_level=DetailLevel.Low\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0vnHejwWarG6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'classes': ['LABEL_0', 'LABEL_1'],\n",
       " 'pairings': OrderedDict([('Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence . Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .',\n",
       "               tensor([0.4284, 0.5716]))]),\n",
       " 'predictions': ['equivalent'],\n",
       " 'probs': tensor([[0.4284, 0.5716]]),\n",
       " 'sentences': ['Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence . Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .']}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.tag_text(\n",
    "    sentence,\n",
    "    model_name_or_path = 'fine_tuned_model',\n",
    "    class_names = ['not_equivalent', 'equivalent'],\n",
    "    detail_level=DetailLevel.Medium\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sb_6xT4GaynJ",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'classes': ['LABEL_0', 'LABEL_1'],\n",
       " 'pairings': OrderedDict([('Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence . Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .',\n",
       "               tensor([0.4284, 0.5716]))]),\n",
       " 'predictions': ['equivalent'],\n",
       " 'probs': tensor([[0.4284, 0.5716]]),\n",
       " 'sentences': [Sentence: \"Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence . Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .\"   [− Tokens: 39  − Sentence-Labels: {'sc': [LABEL_0 (0.4284), LABEL_1 (0.5716)]}]]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.tag_text(\n",
    "    sentence,\n",
    "    model_name_or_path = 'fine_tuned_model',\n",
    "    class_names = ['not_equivalent', 'equivalent'],\n",
    "    detail_level=DetailLevel.High\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "J30a1lYQa1s_",
   "metadata": {},
   "source": [
    "In some cases the pairings will actually wind up being the same, this is because there is only so much information we can return."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
