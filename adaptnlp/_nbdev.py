# AUTOGENERATED BY NBDEV! DO NOT EDIT!

__all__ = ["index", "modules", "custom_doc_links", "git_url"]

index = {"logger": "13_transformers.finetuning.ipynb",
         "TransformersTokenTagger": "00_token_classification.ipynb",
         "FlairTokenTagger": "00_token_classification.ipynb",
         "EasyTokenTagger": "00_token_classification.ipynb",
         "TransformersSequenceClassifier": "01_sequence_classification.ipynb",
         "FlairSequenceClassifier": "01_sequence_classification.ipynb",
         "EasySequenceClassifier": "01_sequence_classification.ipynb",
         "GatherInputsCallback": "02_callback.ipynb",
         "SetInputsCallback": "02_callback.ipynb",
         "GeneratorCallback": "02_callback.ipynb",
         "DataLoader.one_batch": "03_model.ipynb",
         "GatherPredsCallback.after_validate": "03_model.ipynb",
         "AdaptiveModel": "03_model.ipynb",
         "TransformersSummarizer": "04_summarization.ipynb",
         "EasySummarizer": "04_summarization.ipynb",
         "FLAIR_PRETRAINED_MODEL_NAMES": "05_embeddings.ipynb",
         "EasyWordEmbeddings": "05_embeddings.ipynb",
         "EasyStackedEmbeddings": "05_embeddings.ipynb",
         "EasyDocumentEmbeddings": "05_embeddings.ipynb",
         "CACHE_ROOT": "06_file_utils.ipynb",
         "CACHE_DIRECTORY": "06_file_utils.ipynb",
         "url_to_filename": "06_file_utils.ipynb",
         "filename_to_url": "06_file_utils.ipynb",
         "cached_path": "06_file_utils.ipynb",
         "is_url_or_existing_file": "06_file_utils.ipynb",
         "split_s3_path": "06_file_utils.ipynb",
         "s3_request": "06_file_utils.ipynb",
         "get_s3_resource": "06_file_utils.ipynb",
         "s3_etag": "06_file_utils.ipynb",
         "s3_get": "06_file_utils.ipynb",
         "session_with_backoff": "06_file_utils.ipynb",
         "http_get": "06_file_utils.ipynb",
         "get_from_cache": "06_file_utils.ipynb",
         "read_set_from_file": "06_file_utils.ipynb",
         "get_file_extension": "06_file_utils.ipynb",
         "Tqdm": "06_file_utils.ipynb",
         "TransformersTranslator": "07_translation.ipynb",
         "EasyTranslator": "07_translation.ipynb",
         "SequenceClassifierTrainer": "08_training.ipynb",
         "TransformersTextGenerator": "09_text_generation.ipynb",
         "EasyTextGenerator": "09_text_generation.ipynb",
         "LMFineTuner": "10_language_model.ipynb",
         "QACallback": "11_question_answering.ipynb",
         "TransformersQuestionAnswering": "11_question_answering.ipynb",
         "EasyQuestionAnswering": "11_question_answering.ipynb",
         "normalize_answer": "14_transformers.utils_squad_evaluate.ipynb",
         "get_tokens": "14_transformers.utils_squad_evaluate.ipynb",
         "compute_exact": "14_transformers.utils_squad_evaluate.ipynb",
         "compute_f1": "14_transformers.utils_squad_evaluate.ipynb",
         "get_raw_scores": "14_transformers.utils_squad_evaluate.ipynb",
         "apply_no_ans_threshold": "14_transformers.utils_squad_evaluate.ipynb",
         "make_eval_dict": "14_transformers.utils_squad_evaluate.ipynb",
         "merge_eval": "14_transformers.utils_squad_evaluate.ipynb",
         "find_best_thresh_v2": "14_transformers.utils_squad_evaluate.ipynb",
         "find_all_best_thresh_v2": "14_transformers.utils_squad_evaluate.ipynb",
         "find_best_thresh": "14_transformers.utils_squad_evaluate.ipynb",
         "find_all_best_thresh": "14_transformers.utils_squad_evaluate.ipynb",
         "squad_evaluate": "12_transformers.squad_metrics.ipynb",
         "get_final_text": "12_transformers.squad_metrics.ipynb",
         "compute_predictions_logits": "12_transformers.squad_metrics.ipynb",
         "compute_predictions_log_probs": "12_transformers.squad_metrics.ipynb",
         "tqdm": "13_transformers.finetuning.ipynb",
         "TextDataset": "13_transformers.finetuning.ipynb",
         "LMFineTunerManual": "13_transformers.finetuning.ipynb",
         "EVAL_OPTS": "14_transformers.utils_squad_evaluate.ipynb",
         "OPTS": "14_transformers.utils_squad_evaluate.ipynb",
         "parse_args": "14_transformers.utils_squad_evaluate.ipynb",
         "make_qid_to_has_ans": "14_transformers.utils_squad_evaluate.ipynb",
         "plot_pr_curve": "14_transformers.utils_squad_evaluate.ipynb",
         "make_precision_recall_eval": "14_transformers.utils_squad_evaluate.ipynb",
         "run_precision_recall_analysis": "14_transformers.utils_squad_evaluate.ipynb",
         "histogram_na_prob": "14_transformers.utils_squad_evaluate.ipynb",
         "main": "14_transformers.utils_squad_evaluate.ipynb",
         "HF_TASKS": "15_model_hub.ipynb",
         "HF_TASKS.__doc__": "15_model_hub.ipynb",
         "HFModelResult": "15_model_hub.ipynb",
         "HFModelSearchHub": "15_model_hub.ipynb",
         "FLAIR_TASKS": "15_model_hub.ipynb",
         "FLAIR_TASKS.__doc__": "15_model_hub.ipynb",
         "FLAIR_MODELS": "15_model_hub.ipynb",
         "FlairModelSearchHub": "15_model_hub.ipynb"}

modules = ["token_classification.py",
           "sequence_classification.py",
           "callback.py",
           "model.py",
           "summarization.py",
           "embeddings.py",
           "file_utils.py",
           "translation.py",
           "training.py",
           "text_generation.py",
           "language_model.py",
           "question_answering.py",
           "transformers/squad_metrics.py",
           "transformers/finetuning.py",
           "transformers/utils_squad_evaluate.py",
           "model_hub.py"]

doc_url = "https://nbdev.github.io/adaptnlp/adaptnlp/"

git_url = "https://github.com/novetta/adaptnlp/tree/master/"

def custom_doc_links(name): return None
